2019-01-13 21:17:23,534 - root - INFO - Use Cuda.
2019-01-13 21:17:23,535 - root - INFO - Namespace(balance_data=False, base_net='models/inception_v3_google-1a9a5a14.pth', base_net_lr=None, batch_size=24, checkpoint_folder='models/', dataset_type='voc', datasets=['/home/deeplyunreal/data/VOC0712/VOC2007', '/home/deeplyunreal/data/VOC0712/VOC2012'], debug_steps=100, extra_layers_lr=None, freeze_base_net=False, freeze_net=False, gamma=0.1, lr=0.001, mb2_width_mult=1.0, milestones='120,160', momentum=0.9, net='inception', num_epochs=200, num_workers=4, pretrained_ssd=None, resume=None, scheduler='multi-step', t_max=120, use_cuda=True, validation_dataset='/home/deeplyunreal/data/VOC0712/test/VOC2007/', validation_epochs=5, weight_decay=0.0005)
2019-01-13 21:17:23,536 - root - INFO - Prepare training datasets.
2019-01-13 21:17:23,543 - root - INFO - Stored labels into file models/voc-model-labels.txt.
2019-01-13 21:17:23,543 - root - INFO - Train dataset size: 16551
2019-01-13 21:17:23,543 - root - INFO - Prepare Validation datasets.
2019-01-13 21:17:23,545 - root - INFO - validation dataset size: 4952
2019-01-13 21:17:23,545 - root - INFO - Build network.
2019-01-13 21:17:26,170 - root - INFO - Init from base net models/inception_v3_google-1a9a5a14.pth
2019-01-13 21:17:26,270 - root - INFO - Took 0.10 seconds to load the model.
2019-01-13 21:17:29,289 - root - INFO - Learning rate: 0.001, Base net learning rate: 0.001, Extra Layers learning rate: 0.001.
2019-01-13 21:17:29,289 - root - INFO - Uses MultiStepLR scheduler.
2019-01-13 21:17:29,289 - root - INFO - Start training from epoch 0.
/home/deeplyunreal/anaconda3/envs/qcs231n/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
2019-01-13 21:18:00,612 - root - INFO - Epoch: 0, Step: 100, Average Loss: 16.2249, Average Regression Loss 3.0748, Average Classification Loss: 13.1500
2019-01-13 21:18:27,865 - root - INFO - Epoch: 0, Step: 200, Average Loss: 9.5686, Average Regression Loss 2.8183, Average Classification Loss: 6.7503
2019-01-13 21:18:55,239 - root - INFO - Epoch: 0, Step: 300, Average Loss: 8.2299, Average Regression Loss 2.7044, Average Classification Loss: 5.5256
2019-01-13 21:19:23,262 - root - INFO - Epoch: 0, Step: 400, Average Loss: 8.0121, Average Regression Loss 2.6149, Average Classification Loss: 5.3972
2019-01-13 21:19:51,779 - root - INFO - Epoch: 0, Step: 500, Average Loss: 7.8410, Average Regression Loss 2.5815, Average Classification Loss: 5.2596
2019-01-13 21:20:20,361 - root - INFO - Epoch: 0, Step: 600, Average Loss: 7.8500, Average Regression Loss 2.5700, Average Classification Loss: 5.2800
2019-01-13 21:21:08,606 - root - INFO - Epoch: 0, Validation Loss: 7.4240, Validation Regression Loss 2.4599, Validation Classification Loss: 4.9641
2019-01-13 21:21:08,815 - root - INFO - Saved model models/inception-Epoch-0-Loss-7.4240067615601175.pth
2019-01-13 21:21:38,556 - root - INFO - Epoch: 1, Step: 100, Average Loss: 7.7034, Average Regression Loss 2.5214, Average Classification Loss: 5.1820
2019-01-13 21:22:07,194 - root - INFO - Epoch: 1, Step: 200, Average Loss: 7.5445, Average Regression Loss 2.4539, Average Classification Loss: 5.0906
2019-01-13 21:22:35,805 - root - INFO - Epoch: 1, Step: 300, Average Loss: 7.5540, Average Regression Loss 2.4584, Average Classification Loss: 5.0956
2019-01-13 21:23:04,479 - root - INFO - Epoch: 1, Step: 400, Average Loss: 7.4875, Average Regression Loss 2.4564, Average Classification Loss: 5.0311
2019-01-13 21:23:33,070 - root - INFO - Epoch: 1, Step: 500, Average Loss: 7.4373, Average Regression Loss 2.4431, Average Classification Loss: 4.9942
2019-01-13 21:24:01,748 - root - INFO - Epoch: 1, Step: 600, Average Loss: 7.4467, Average Regression Loss 2.4061, Average Classification Loss: 5.0406
2019-01-13 21:24:56,753 - root - INFO - Epoch: 2, Step: 100, Average Loss: 7.3631, Average Regression Loss 2.3908, Average Classification Loss: 4.9723
2019-01-13 21:25:25,338 - root - INFO - Epoch: 2, Step: 200, Average Loss: 7.3127, Average Regression Loss 2.3563, Average Classification Loss: 4.9564
2019-01-13 21:25:53,937 - root - INFO - Epoch: 2, Step: 300, Average Loss: 7.3044, Average Regression Loss 2.3280, Average Classification Loss: 4.9764
2019-01-13 21:26:22,518 - root - INFO - Epoch: 2, Step: 400, Average Loss: 7.2629, Average Regression Loss 2.3307, Average Classification Loss: 4.9322
2019-01-13 21:26:51,192 - root - INFO - Epoch: 2, Step: 500, Average Loss: 7.2625, Average Regression Loss 2.3365, Average Classification Loss: 4.9259
2019-01-13 21:27:20,047 - root - INFO - Epoch: 2, Step: 600, Average Loss: 7.2352, Average Regression Loss 2.2948, Average Classification Loss: 4.9404
2019-01-13 21:28:16,622 - root - INFO - Epoch: 3, Step: 100, Average Loss: 7.2610, Average Regression Loss 2.2991, Average Classification Loss: 4.9620
2019-01-13 21:28:45,473 - root - INFO - Epoch: 3, Step: 200, Average Loss: 7.1258, Average Regression Loss 2.2346, Average Classification Loss: 4.8913
2019-01-13 21:29:14,189 - root - INFO - Epoch: 3, Step: 300, Average Loss: 7.0895, Average Regression Loss 2.2320, Average Classification Loss: 4.8575
2019-01-13 21:29:43,971 - root - INFO - Epoch: 3, Step: 400, Average Loss: 7.1128, Average Regression Loss 2.2349, Average Classification Loss: 4.8778
2019-01-13 21:30:12,709 - root - INFO - Epoch: 3, Step: 500, Average Loss: 7.0817, Average Regression Loss 2.2241, Average Classification Loss: 4.8575
2019-01-13 21:30:41,351 - root - INFO - Epoch: 3, Step: 600, Average Loss: 7.0484, Average Regression Loss 2.2176, Average Classification Loss: 4.8308
2019-01-13 21:31:36,546 - root - INFO - Epoch: 4, Step: 100, Average Loss: 7.0517, Average Regression Loss 2.1818, Average Classification Loss: 4.8699
2019-01-13 21:32:05,244 - root - INFO - Epoch: 4, Step: 200, Average Loss: 7.0366, Average Regression Loss 2.1913, Average Classification Loss: 4.8453
2019-01-13 21:32:33,905 - root - INFO - Epoch: 4, Step: 300, Average Loss: 6.9818, Average Regression Loss 2.1619, Average Classification Loss: 4.8198
2019-01-13 21:33:02,620 - root - INFO - Epoch: 4, Step: 400, Average Loss: 6.9134, Average Regression Loss 2.1277, Average Classification Loss: 4.7857
2019-01-13 21:33:31,500 - root - INFO - Epoch: 4, Step: 500, Average Loss: 6.9463, Average Regression Loss 2.1381, Average Classification Loss: 4.8083
2019-01-13 21:34:00,282 - root - INFO - Epoch: 4, Step: 600, Average Loss: 6.9083, Average Regression Loss 2.1385, Average Classification Loss: 4.7698
2019-01-13 21:34:55,594 - root - INFO - Epoch: 5, Step: 100, Average Loss: 6.9922, Average Regression Loss 2.1560, Average Classification Loss: 4.8363
2019-01-13 21:35:24,280 - root - INFO - Epoch: 5, Step: 200, Average Loss: 6.8566, Average Regression Loss 2.1318, Average Classification Loss: 4.7248
2019-01-13 21:35:52,856 - root - INFO - Epoch: 5, Step: 300, Average Loss: 6.9307, Average Regression Loss 2.1179, Average Classification Loss: 4.8128
2019-01-13 21:36:21,406 - root - INFO - Epoch: 5, Step: 400, Average Loss: 6.8382, Average Regression Loss 2.1004, Average Classification Loss: 4.7378
2019-01-13 21:36:49,982 - root - INFO - Epoch: 5, Step: 500, Average Loss: 6.8544, Average Regression Loss 2.0775, Average Classification Loss: 4.7770
2019-01-13 21:37:18,964 - root - INFO - Epoch: 5, Step: 600, Average Loss: 6.8182, Average Regression Loss 2.0762, Average Classification Loss: 4.7420
2019-01-13 21:38:04,505 - root - INFO - Epoch: 5, Validation Loss: 6.7419, Validation Regression Loss 2.1553, Validation Classification Loss: 4.5866
2019-01-13 21:38:04,587 - root - INFO - Saved model models/inception-Epoch-5-Loss-6.7418600142290055.pth
2019-01-13 21:38:35,087 - root - INFO - Epoch: 6, Step: 100, Average Loss: 6.8715, Average Regression Loss 2.0934, Average Classification Loss: 4.7781
2019-01-13 21:39:03,615 - root - INFO - Epoch: 6, Step: 200, Average Loss: 6.7375, Average Regression Loss 2.0691, Average Classification Loss: 4.6684
2019-01-13 21:39:32,194 - root - INFO - Epoch: 6, Step: 300, Average Loss: 6.7274, Average Regression Loss 2.0408, Average Classification Loss: 4.6866
2019-01-13 21:40:00,765 - root - INFO - Epoch: 6, Step: 400, Average Loss: 6.8152, Average Regression Loss 2.1181, Average Classification Loss: 4.6971
2019-01-13 21:40:30,175 - root - INFO - Epoch: 6, Step: 500, Average Loss: 6.7619, Average Regression Loss 2.0171, Average Classification Loss: 4.7448
2019-01-13 21:40:59,159 - root - INFO - Epoch: 6, Step: 600, Average Loss: 6.7721, Average Regression Loss 2.0726, Average Classification Loss: 4.6995
2019-01-13 21:41:54,993 - root - INFO - Epoch: 7, Step: 100, Average Loss: 6.7684, Average Regression Loss 2.0663, Average Classification Loss: 4.7021
2019-01-13 21:42:23,501 - root - INFO - Epoch: 7, Step: 200, Average Loss: 6.6823, Average Regression Loss 2.0062, Average Classification Loss: 4.6762
2019-01-13 21:42:52,427 - root - INFO - Epoch: 7, Step: 300, Average Loss: 6.7508, Average Regression Loss 2.0338, Average Classification Loss: 4.7170
2019-01-13 21:43:20,949 - root - INFO - Epoch: 7, Step: 400, Average Loss: 6.6780, Average Regression Loss 2.0187, Average Classification Loss: 4.6593
2019-01-13 21:43:49,484 - root - INFO - Epoch: 7, Step: 500, Average Loss: 6.7208, Average Regression Loss 2.0373, Average Classification Loss: 4.6835
2019-01-13 21:44:17,988 - root - INFO - Epoch: 7, Step: 600, Average Loss: 6.6678, Average Regression Loss 2.0112, Average Classification Loss: 4.6566
2019-01-13 21:45:14,047 - root - INFO - Epoch: 8, Step: 100, Average Loss: 6.7530, Average Regression Loss 2.0358, Average Classification Loss: 4.7172
2019-01-13 21:45:43,092 - root - INFO - Epoch: 8, Step: 200, Average Loss: 6.6715, Average Regression Loss 2.0185, Average Classification Loss: 4.6530
2019-01-13 21:46:12,010 - root - INFO - Epoch: 8, Step: 300, Average Loss: 6.6417, Average Regression Loss 1.9988, Average Classification Loss: 4.6430
2019-01-13 21:46:40,763 - root - INFO - Epoch: 8, Step: 400, Average Loss: 6.6245, Average Regression Loss 1.9888, Average Classification Loss: 4.6357
2019-01-13 21:47:09,557 - root - INFO - Epoch: 8, Step: 500, Average Loss: 6.6300, Average Regression Loss 1.9848, Average Classification Loss: 4.6453
2019-01-13 21:47:38,634 - root - INFO - Epoch: 8, Step: 600, Average Loss: 6.5933, Average Regression Loss 2.0052, Average Classification Loss: 4.5881
2019-01-13 21:48:33,990 - root - INFO - Epoch: 9, Step: 100, Average Loss: 6.6753, Average Regression Loss 1.9720, Average Classification Loss: 4.7033
2019-01-13 21:49:02,536 - root - INFO - Epoch: 9, Step: 200, Average Loss: 6.5167, Average Regression Loss 1.9578, Average Classification Loss: 4.5589
2019-01-13 21:49:31,199 - root - INFO - Epoch: 9, Step: 300, Average Loss: 6.5815, Average Regression Loss 1.9919, Average Classification Loss: 4.5896
2019-01-13 21:49:59,938 - root - INFO - Epoch: 9, Step: 400, Average Loss: 6.5795, Average Regression Loss 1.9991, Average Classification Loss: 4.5804
2019-01-13 21:50:28,804 - root - INFO - Epoch: 9, Step: 500, Average Loss: 6.5689, Average Regression Loss 1.9811, Average Classification Loss: 4.5877
2019-01-13 21:50:57,542 - root - INFO - Epoch: 9, Step: 600, Average Loss: 6.5869, Average Regression Loss 1.9797, Average Classification Loss: 4.6072
2019-01-13 21:51:53,615 - root - INFO - Epoch: 10, Step: 100, Average Loss: 6.6158, Average Regression Loss 2.0108, Average Classification Loss: 4.6049
2019-01-13 21:52:22,457 - root - INFO - Epoch: 10, Step: 200, Average Loss: 6.5126, Average Regression Loss 1.9440, Average Classification Loss: 4.5686
2019-01-13 21:52:51,165 - root - INFO - Epoch: 10, Step: 300, Average Loss: 6.5401, Average Regression Loss 1.9745, Average Classification Loss: 4.5657
2019-01-13 21:53:19,660 - root - INFO - Epoch: 10, Step: 400, Average Loss: 6.5545, Average Regression Loss 1.9711, Average Classification Loss: 4.5834
2019-01-13 21:53:48,307 - root - INFO - Epoch: 10, Step: 500, Average Loss: 6.5505, Average Regression Loss 1.9723, Average Classification Loss: 4.5781
2019-01-13 21:54:17,148 - root - INFO - Epoch: 10, Step: 600, Average Loss: 6.4523, Average Regression Loss 1.9411, Average Classification Loss: 4.5112
2019-01-13 21:55:02,340 - root - INFO - Epoch: 10, Validation Loss: 6.4177, Validation Regression Loss 2.0400, Validation Classification Loss: 4.3777
2019-01-13 21:55:02,429 - root - INFO - Saved model models/inception-Epoch-10-Loss-6.417701656691694.pth
2019-01-13 21:55:32,032 - root - INFO - Epoch: 11, Step: 100, Average Loss: 6.5443, Average Regression Loss 1.9779, Average Classification Loss: 4.5664
2019-01-13 21:56:00,478 - root - INFO - Epoch: 11, Step: 200, Average Loss: 6.4972, Average Regression Loss 1.9583, Average Classification Loss: 4.5389
2019-01-13 21:56:29,449 - root - INFO - Epoch: 11, Step: 300, Average Loss: 6.4604, Average Regression Loss 1.9287, Average Classification Loss: 4.5317
2019-01-13 21:56:58,202 - root - INFO - Epoch: 11, Step: 400, Average Loss: 6.5173, Average Regression Loss 1.9547, Average Classification Loss: 4.5626
2019-01-13 21:57:26,933 - root - INFO - Epoch: 11, Step: 500, Average Loss: 6.3959, Average Regression Loss 1.9263, Average Classification Loss: 4.4696
2019-01-13 21:57:55,770 - root - INFO - Epoch: 11, Step: 600, Average Loss: 6.4809, Average Regression Loss 1.9598, Average Classification Loss: 4.5211
2019-01-13 21:58:51,412 - root - INFO - Epoch: 12, Step: 100, Average Loss: 6.5300, Average Regression Loss 1.9448, Average Classification Loss: 4.5852
2019-01-13 21:59:20,286 - root - INFO - Epoch: 12, Step: 200, Average Loss: 6.3965, Average Regression Loss 1.9140, Average Classification Loss: 4.4825
2019-01-13 21:59:49,123 - root - INFO - Epoch: 12, Step: 300, Average Loss: 6.4060, Average Regression Loss 1.9085, Average Classification Loss: 4.4975
2019-01-13 22:00:17,730 - root - INFO - Epoch: 12, Step: 400, Average Loss: 6.3788, Average Regression Loss 1.9060, Average Classification Loss: 4.4727
2019-01-13 22:00:46,377 - root - INFO - Epoch: 12, Step: 500, Average Loss: 6.3972, Average Regression Loss 1.9013, Average Classification Loss: 4.4959
2019-01-13 22:01:15,064 - root - INFO - Epoch: 12, Step: 600, Average Loss: 6.3826, Average Regression Loss 1.9122, Average Classification Loss: 4.4704
2019-01-13 22:02:10,260 - root - INFO - Epoch: 13, Step: 100, Average Loss: 6.4307, Average Regression Loss 1.9148, Average Classification Loss: 4.5159
2019-01-13 22:02:39,110 - root - INFO - Epoch: 13, Step: 200, Average Loss: 6.3883, Average Regression Loss 1.9070, Average Classification Loss: 4.4813
2019-01-13 22:03:08,076 - root - INFO - Epoch: 13, Step: 300, Average Loss: 6.3389, Average Regression Loss 1.8837, Average Classification Loss: 4.4551
2019-01-13 22:03:36,850 - root - INFO - Epoch: 13, Step: 400, Average Loss: 6.3101, Average Regression Loss 1.9051, Average Classification Loss: 4.4051
2019-01-13 22:04:05,423 - root - INFO - Epoch: 13, Step: 500, Average Loss: 6.3594, Average Regression Loss 1.9160, Average Classification Loss: 4.4434
2019-01-13 22:04:34,018 - root - INFO - Epoch: 13, Step: 600, Average Loss: 6.3540, Average Regression Loss 1.9018, Average Classification Loss: 4.4522
2019-01-13 22:05:29,749 - root - INFO - Epoch: 14, Step: 100, Average Loss: 6.3426, Average Regression Loss 1.8959, Average Classification Loss: 4.4467
2019-01-13 22:05:58,481 - root - INFO - Epoch: 14, Step: 200, Average Loss: 6.3382, Average Regression Loss 1.8927, Average Classification Loss: 4.4455
2019-01-13 22:06:27,144 - root - INFO - Epoch: 14, Step: 300, Average Loss: 6.2548, Average Regression Loss 1.8441, Average Classification Loss: 4.4107
2019-01-13 22:06:55,904 - root - INFO - Epoch: 14, Step: 400, Average Loss: 6.2980, Average Regression Loss 1.9130, Average Classification Loss: 4.3851
2019-01-13 22:07:24,665 - root - INFO - Epoch: 14, Step: 500, Average Loss: 6.2376, Average Regression Loss 1.8376, Average Classification Loss: 4.4000
2019-01-13 22:07:53,428 - root - INFO - Epoch: 14, Step: 600, Average Loss: 6.2908, Average Regression Loss 1.8926, Average Classification Loss: 4.3982
2019-01-13 22:08:48,731 - root - INFO - Epoch: 15, Step: 100, Average Loss: 6.3460, Average Regression Loss 1.8938, Average Classification Loss: 4.4521
2019-01-13 22:09:18,372 - root - INFO - Epoch: 15, Step: 200, Average Loss: 6.2518, Average Regression Loss 1.8621, Average Classification Loss: 4.3897
2019-01-13 22:09:47,299 - root - INFO - Epoch: 15, Step: 300, Average Loss: 6.2059, Average Regression Loss 1.8556, Average Classification Loss: 4.3503
2019-01-13 22:10:16,833 - root - INFO - Epoch: 15, Step: 400, Average Loss: 6.2010, Average Regression Loss 1.8526, Average Classification Loss: 4.3484
2019-01-13 22:10:45,820 - root - INFO - Epoch: 15, Step: 500, Average Loss: 6.2169, Average Regression Loss 1.8775, Average Classification Loss: 4.3394
2019-01-13 22:11:14,297 - root - INFO - Epoch: 15, Step: 600, Average Loss: 6.1998, Average Regression Loss 1.8577, Average Classification Loss: 4.3420
2019-01-13 22:11:58,845 - root - INFO - Epoch: 15, Validation Loss: 6.0434, Validation Regression Loss 1.9219, Validation Classification Loss: 4.1215
2019-01-13 22:11:58,924 - root - INFO - Saved model models/inception-Epoch-15-Loss-6.043363308561021.pth
2019-01-13 22:12:28,486 - root - INFO - Epoch: 16, Step: 100, Average Loss: 6.2483, Average Regression Loss 1.8834, Average Classification Loss: 4.3650
2019-01-13 22:12:56,813 - root - INFO - Epoch: 16, Step: 200, Average Loss: 6.1054, Average Regression Loss 1.8056, Average Classification Loss: 4.2998
2019-01-13 22:13:25,271 - root - INFO - Epoch: 16, Step: 300, Average Loss: 6.1966, Average Regression Loss 1.8594, Average Classification Loss: 4.3371
2019-01-13 22:13:53,631 - root - INFO - Epoch: 16, Step: 400, Average Loss: 6.1459, Average Regression Loss 1.8362, Average Classification Loss: 4.3097
2019-01-13 22:14:22,047 - root - INFO - Epoch: 16, Step: 500, Average Loss: 6.1548, Average Regression Loss 1.8119, Average Classification Loss: 4.3428
2019-01-13 22:14:50,449 - root - INFO - Epoch: 16, Step: 600, Average Loss: 6.1750, Average Regression Loss 1.8572, Average Classification Loss: 4.3178
2019-01-13 22:15:45,391 - root - INFO - Epoch: 17, Step: 100, Average Loss: 6.2053, Average Regression Loss 1.8737, Average Classification Loss: 4.3315
2019-01-13 22:16:13,833 - root - INFO - Epoch: 17, Step: 200, Average Loss: 6.1412, Average Regression Loss 1.8345, Average Classification Loss: 4.3067
2019-01-13 22:16:42,313 - root - INFO - Epoch: 17, Step: 300, Average Loss: 6.0882, Average Regression Loss 1.8146, Average Classification Loss: 4.2737
2019-01-13 22:17:10,732 - root - INFO - Epoch: 17, Step: 400, Average Loss: 6.0869, Average Regression Loss 1.8141, Average Classification Loss: 4.2727
2019-01-13 22:17:39,206 - root - INFO - Epoch: 17, Step: 500, Average Loss: 6.1092, Average Regression Loss 1.8119, Average Classification Loss: 4.2973
2019-01-13 22:18:07,628 - root - INFO - Epoch: 17, Step: 600, Average Loss: 6.1086, Average Regression Loss 1.8364, Average Classification Loss: 4.2722
2019-01-13 22:19:02,592 - root - INFO - Epoch: 18, Step: 100, Average Loss: 6.1100, Average Regression Loss 1.8301, Average Classification Loss: 4.2798
2019-01-13 22:19:31,088 - root - INFO - Epoch: 18, Step: 200, Average Loss: 6.0690, Average Regression Loss 1.8389, Average Classification Loss: 4.2301
2019-01-13 22:19:59,605 - root - INFO - Epoch: 18, Step: 300, Average Loss: 6.0564, Average Regression Loss 1.8111, Average Classification Loss: 4.2453
2019-01-13 22:20:28,153 - root - INFO - Epoch: 18, Step: 400, Average Loss: 6.0757, Average Regression Loss 1.8341, Average Classification Loss: 4.2415
2019-01-13 22:20:56,619 - root - INFO - Epoch: 18, Step: 500, Average Loss: 6.0618, Average Regression Loss 1.8139, Average Classification Loss: 4.2480
2019-01-13 22:21:25,173 - root - INFO - Epoch: 18, Step: 600, Average Loss: 6.0216, Average Regression Loss 1.8071, Average Classification Loss: 4.2145
2019-01-13 22:22:20,148 - root - INFO - Epoch: 19, Step: 100, Average Loss: 6.0601, Average Regression Loss 1.8164, Average Classification Loss: 4.2437
2019-01-13 22:22:48,458 - root - INFO - Epoch: 19, Step: 200, Average Loss: 5.9812, Average Regression Loss 1.7998, Average Classification Loss: 4.1814
2019-01-13 22:23:16,925 - root - INFO - Epoch: 19, Step: 300, Average Loss: 5.9895, Average Regression Loss 1.7953, Average Classification Loss: 4.1942
2019-01-13 22:23:45,423 - root - INFO - Epoch: 19, Step: 400, Average Loss: 5.9884, Average Regression Loss 1.7904, Average Classification Loss: 4.1980
2019-01-13 22:24:13,926 - root - INFO - Epoch: 19, Step: 500, Average Loss: 6.0468, Average Regression Loss 1.8198, Average Classification Loss: 4.2270
2019-01-13 22:24:42,367 - root - INFO - Epoch: 19, Step: 600, Average Loss: 5.9870, Average Regression Loss 1.7808, Average Classification Loss: 4.2062
2019-01-13 22:25:37,237 - root - INFO - Epoch: 20, Step: 100, Average Loss: 6.0217, Average Regression Loss 1.7763, Average Classification Loss: 4.2454
2019-01-13 22:26:05,733 - root - INFO - Epoch: 20, Step: 200, Average Loss: 5.9462, Average Regression Loss 1.7793, Average Classification Loss: 4.1669
2019-01-13 22:26:34,195 - root - INFO - Epoch: 20, Step: 300, Average Loss: 5.9241, Average Regression Loss 1.7552, Average Classification Loss: 4.1689
2019-01-13 22:27:02,687 - root - INFO - Epoch: 20, Step: 400, Average Loss: 5.9137, Average Regression Loss 1.7923, Average Classification Loss: 4.1214
2019-01-13 22:27:31,175 - root - INFO - Epoch: 20, Step: 500, Average Loss: 5.9276, Average Regression Loss 1.7749, Average Classification Loss: 4.1527
2019-01-13 22:27:59,609 - root - INFO - Epoch: 20, Step: 600, Average Loss: 5.9662, Average Regression Loss 1.7851, Average Classification Loss: 4.1811
2019-01-13 22:28:44,098 - root - INFO - Epoch: 20, Validation Loss: 5.8155, Validation Regression Loss 1.8376, Validation Classification Loss: 3.9780
2019-01-13 22:28:44,188 - root - INFO - Saved model models/inception-Epoch-20-Loss-5.815537791321243.pth
2019-01-13 22:29:13,655 - root - INFO - Epoch: 21, Step: 100, Average Loss: 6.0429, Average Regression Loss 1.8034, Average Classification Loss: 4.2395
2019-01-13 22:29:42,098 - root - INFO - Epoch: 21, Step: 200, Average Loss: 5.9339, Average Regression Loss 1.7740, Average Classification Loss: 4.1599
2019-01-13 22:30:10,515 - root - INFO - Epoch: 21, Step: 300, Average Loss: 5.9013, Average Regression Loss 1.7647, Average Classification Loss: 4.1366
2019-01-13 22:30:38,938 - root - INFO - Epoch: 21, Step: 400, Average Loss: 5.9015, Average Regression Loss 1.7716, Average Classification Loss: 4.1300
2019-01-13 22:31:07,331 - root - INFO - Epoch: 21, Step: 500, Average Loss: 5.8886, Average Regression Loss 1.7610, Average Classification Loss: 4.1276
2019-01-13 22:31:35,839 - root - INFO - Epoch: 21, Step: 600, Average Loss: 5.9397, Average Regression Loss 1.7898, Average Classification Loss: 4.1498
2019-01-13 22:32:30,610 - root - INFO - Epoch: 22, Step: 100, Average Loss: 5.9379, Average Regression Loss 1.7700, Average Classification Loss: 4.1679
2019-01-13 22:32:59,100 - root - INFO - Epoch: 22, Step: 200, Average Loss: 5.8989, Average Regression Loss 1.7474, Average Classification Loss: 4.1514
2019-01-13 22:33:27,561 - root - INFO - Epoch: 22, Step: 300, Average Loss: 5.8735, Average Regression Loss 1.7738, Average Classification Loss: 4.0997
2019-01-13 22:33:56,003 - root - INFO - Epoch: 22, Step: 400, Average Loss: 5.8832, Average Regression Loss 1.7615, Average Classification Loss: 4.1217
2019-01-13 22:34:25,058 - root - INFO - Epoch: 22, Step: 500, Average Loss: 5.8330, Average Regression Loss 1.7258, Average Classification Loss: 4.1072
2019-01-13 22:34:53,856 - root - INFO - Epoch: 22, Step: 600, Average Loss: 5.8607, Average Regression Loss 1.7558, Average Classification Loss: 4.1049
2019-01-13 22:35:48,838 - root - INFO - Epoch: 23, Step: 100, Average Loss: 5.9093, Average Regression Loss 1.7746, Average Classification Loss: 4.1347
2019-01-13 22:36:17,329 - root - INFO - Epoch: 23, Step: 200, Average Loss: 5.8260, Average Regression Loss 1.7349, Average Classification Loss: 4.0910
2019-01-13 22:36:45,805 - root - INFO - Epoch: 23, Step: 300, Average Loss: 5.8283, Average Regression Loss 1.7316, Average Classification Loss: 4.0967
2019-01-13 22:37:14,299 - root - INFO - Epoch: 23, Step: 400, Average Loss: 5.8829, Average Regression Loss 1.7524, Average Classification Loss: 4.1305
2019-01-13 22:37:42,809 - root - INFO - Epoch: 23, Step: 500, Average Loss: 5.7991, Average Regression Loss 1.7390, Average Classification Loss: 4.0601
2019-01-13 22:38:11,249 - root - INFO - Epoch: 23, Step: 600, Average Loss: 5.7949, Average Regression Loss 1.7354, Average Classification Loss: 4.0596
2019-01-13 22:39:06,246 - root - INFO - Epoch: 24, Step: 100, Average Loss: 5.8442, Average Regression Loss 1.7353, Average Classification Loss: 4.1088
2019-01-13 22:39:34,822 - root - INFO - Epoch: 24, Step: 200, Average Loss: 5.7538, Average Regression Loss 1.7305, Average Classification Loss: 4.0233
2019-01-13 22:40:03,410 - root - INFO - Epoch: 24, Step: 300, Average Loss: 5.7731, Average Regression Loss 1.7238, Average Classification Loss: 4.0493
2019-01-13 22:40:31,933 - root - INFO - Epoch: 24, Step: 400, Average Loss: 5.7887, Average Regression Loss 1.7433, Average Classification Loss: 4.0454
2019-01-13 22:41:00,513 - root - INFO - Epoch: 24, Step: 500, Average Loss: 5.7705, Average Regression Loss 1.7024, Average Classification Loss: 4.0681
2019-01-13 22:41:29,159 - root - INFO - Epoch: 24, Step: 600, Average Loss: 5.7822, Average Regression Loss 1.7291, Average Classification Loss: 4.0532
2019-01-13 22:42:24,166 - root - INFO - Epoch: 25, Step: 100, Average Loss: 5.8020, Average Regression Loss 1.7466, Average Classification Loss: 4.0554
2019-01-13 22:42:52,601 - root - INFO - Epoch: 25, Step: 200, Average Loss: 5.7801, Average Regression Loss 1.7126, Average Classification Loss: 4.0675
2019-01-13 22:43:20,965 - root - INFO - Epoch: 25, Step: 300, Average Loss: 5.7576, Average Regression Loss 1.7082, Average Classification Loss: 4.0493
2019-01-13 22:43:49,409 - root - INFO - Epoch: 25, Step: 400, Average Loss: 5.7504, Average Regression Loss 1.7103, Average Classification Loss: 4.0401
2019-01-13 22:44:17,874 - root - INFO - Epoch: 25, Step: 500, Average Loss: 5.7455, Average Regression Loss 1.7167, Average Classification Loss: 4.0288
2019-01-13 22:44:46,341 - root - INFO - Epoch: 25, Step: 600, Average Loss: 5.7381, Average Regression Loss 1.7041, Average Classification Loss: 4.0340
2019-01-13 22:45:30,805 - root - INFO - Epoch: 25, Validation Loss: 5.5542, Validation Regression Loss 1.7559, Validation Classification Loss: 3.7982
2019-01-13 22:45:30,886 - root - INFO - Saved model models/inception-Epoch-25-Loss-5.5541612307230634.pth
2019-01-13 22:46:00,448 - root - INFO - Epoch: 26, Step: 100, Average Loss: 5.8601, Average Regression Loss 1.7624, Average Classification Loss: 4.0977
2019-01-13 22:46:28,889 - root - INFO - Epoch: 26, Step: 200, Average Loss: 5.6776, Average Regression Loss 1.7093, Average Classification Loss: 3.9683
2019-01-13 22:46:57,361 - root - INFO - Epoch: 26, Step: 300, Average Loss: 5.6785, Average Regression Loss 1.6773, Average Classification Loss: 4.0012
2019-01-13 22:47:25,871 - root - INFO - Epoch: 26, Step: 400, Average Loss: 5.6954, Average Regression Loss 1.7052, Average Classification Loss: 3.9902
2019-01-13 22:47:54,392 - root - INFO - Epoch: 26, Step: 500, Average Loss: 5.6983, Average Regression Loss 1.6950, Average Classification Loss: 4.0033
2019-01-13 22:48:22,914 - root - INFO - Epoch: 26, Step: 600, Average Loss: 5.6953, Average Regression Loss 1.7054, Average Classification Loss: 3.9899
2019-01-13 22:49:17,775 - root - INFO - Epoch: 27, Step: 100, Average Loss: 5.8050, Average Regression Loss 1.7382, Average Classification Loss: 4.0668
2019-01-13 22:49:46,193 - root - INFO - Epoch: 27, Step: 200, Average Loss: 5.6360, Average Regression Loss 1.6753, Average Classification Loss: 3.9607
2019-01-13 22:50:14,655 - root - INFO - Epoch: 27, Step: 300, Average Loss: 5.7152, Average Regression Loss 1.7205, Average Classification Loss: 3.9948
2019-01-13 22:50:43,110 - root - INFO - Epoch: 27, Step: 400, Average Loss: 5.6394, Average Regression Loss 1.6872, Average Classification Loss: 3.9521
2019-01-13 22:51:11,552 - root - INFO - Epoch: 27, Step: 500, Average Loss: 5.6497, Average Regression Loss 1.6731, Average Classification Loss: 3.9766
2019-01-13 22:51:40,046 - root - INFO - Epoch: 27, Step: 600, Average Loss: 5.6561, Average Regression Loss 1.6825, Average Classification Loss: 3.9735
2019-01-13 22:52:34,881 - root - INFO - Epoch: 28, Step: 100, Average Loss: 5.7183, Average Regression Loss 1.7097, Average Classification Loss: 4.0086
2019-01-13 22:53:03,381 - root - INFO - Epoch: 28, Step: 200, Average Loss: 5.6192, Average Regression Loss 1.6662, Average Classification Loss: 3.9531
2019-01-13 22:53:31,793 - root - INFO - Epoch: 28, Step: 300, Average Loss: 5.6584, Average Regression Loss 1.7157, Average Classification Loss: 3.9426
2019-01-13 22:54:00,331 - root - INFO - Epoch: 28, Step: 400, Average Loss: 5.6083, Average Regression Loss 1.6904, Average Classification Loss: 3.9178
2019-01-13 22:54:28,783 - root - INFO - Epoch: 28, Step: 500, Average Loss: 5.6614, Average Regression Loss 1.6979, Average Classification Loss: 3.9635
2019-01-13 22:54:57,238 - root - INFO - Epoch: 28, Step: 600, Average Loss: 5.5870, Average Regression Loss 1.6635, Average Classification Loss: 3.9235
2019-01-13 22:55:52,046 - root - INFO - Epoch: 29, Step: 100, Average Loss: 5.6571, Average Regression Loss 1.6978, Average Classification Loss: 3.9593
2019-01-13 22:56:20,457 - root - INFO - Epoch: 29, Step: 200, Average Loss: 5.5952, Average Regression Loss 1.6729, Average Classification Loss: 3.9223
2019-01-13 22:56:48,888 - root - INFO - Epoch: 29, Step: 300, Average Loss: 5.6107, Average Regression Loss 1.6680, Average Classification Loss: 3.9428
2019-01-13 22:57:17,344 - root - INFO - Epoch: 29, Step: 400, Average Loss: 5.6142, Average Regression Loss 1.6910, Average Classification Loss: 3.9232
2019-01-13 22:57:45,790 - root - INFO - Epoch: 29, Step: 500, Average Loss: 5.5899, Average Regression Loss 1.6395, Average Classification Loss: 3.9504
2019-01-13 22:58:14,274 - root - INFO - Epoch: 29, Step: 600, Average Loss: 5.5884, Average Regression Loss 1.6573, Average Classification Loss: 3.9311
2019-01-13 22:59:09,059 - root - INFO - Epoch: 30, Step: 100, Average Loss: 5.5576, Average Regression Loss 1.6646, Average Classification Loss: 3.8930
2019-01-13 22:59:37,487 - root - INFO - Epoch: 30, Step: 200, Average Loss: 5.6136, Average Regression Loss 1.6684, Average Classification Loss: 3.9453
2019-01-13 23:00:05,952 - root - INFO - Epoch: 30, Step: 300, Average Loss: 5.6117, Average Regression Loss 1.6728, Average Classification Loss: 3.9389
2019-01-13 23:00:34,451 - root - INFO - Epoch: 30, Step: 400, Average Loss: 5.5397, Average Regression Loss 1.6491, Average Classification Loss: 3.8906
2019-01-13 23:01:02,898 - root - INFO - Epoch: 30, Step: 500, Average Loss: 5.5688, Average Regression Loss 1.6643, Average Classification Loss: 3.9045
2019-01-13 23:01:31,360 - root - INFO - Epoch: 30, Step: 600, Average Loss: 5.5930, Average Regression Loss 1.6623, Average Classification Loss: 3.9308
2019-01-13 23:02:15,972 - root - INFO - Epoch: 30, Validation Loss: 5.3669, Validation Regression Loss 1.6998, Validation Classification Loss: 3.6671
2019-01-13 23:02:16,091 - root - INFO - Saved model models/inception-Epoch-30-Loss-5.366898294808208.pth
2019-01-13 23:02:45,727 - root - INFO - Epoch: 31, Step: 100, Average Loss: 5.5702, Average Regression Loss 1.6644, Average Classification Loss: 3.9058
2019-01-13 23:03:14,288 - root - INFO - Epoch: 31, Step: 200, Average Loss: 5.5515, Average Regression Loss 1.6676, Average Classification Loss: 3.8839
2019-01-13 23:03:42,743 - root - INFO - Epoch: 31, Step: 300, Average Loss: 5.5312, Average Regression Loss 1.6289, Average Classification Loss: 3.9024
2019-01-13 23:04:11,375 - root - INFO - Epoch: 31, Step: 400, Average Loss: 5.5507, Average Regression Loss 1.6295, Average Classification Loss: 3.9211
2019-01-13 23:04:39,966 - root - INFO - Epoch: 31, Step: 500, Average Loss: 5.5697, Average Regression Loss 1.6656, Average Classification Loss: 3.9041
2019-01-13 23:05:08,549 - root - INFO - Epoch: 31, Step: 600, Average Loss: 5.5854, Average Regression Loss 1.6633, Average Classification Loss: 3.9222
2019-01-13 23:06:03,562 - root - INFO - Epoch: 32, Step: 100, Average Loss: 5.5462, Average Regression Loss 1.6705, Average Classification Loss: 3.8756
2019-01-13 23:06:32,022 - root - INFO - Epoch: 32, Step: 200, Average Loss: 5.4668, Average Regression Loss 1.6136, Average Classification Loss: 3.8532
2019-01-13 23:07:00,512 - root - INFO - Epoch: 32, Step: 300, Average Loss: 5.4676, Average Regression Loss 1.6192, Average Classification Loss: 3.8484
2019-01-13 23:07:28,989 - root - INFO - Epoch: 32, Step: 400, Average Loss: 5.5573, Average Regression Loss 1.6485, Average Classification Loss: 3.9087
2019-01-13 23:07:57,465 - root - INFO - Epoch: 32, Step: 500, Average Loss: 5.4857, Average Regression Loss 1.6237, Average Classification Loss: 3.8620
2019-01-13 23:08:25,982 - root - INFO - Epoch: 32, Step: 600, Average Loss: 5.5415, Average Regression Loss 1.6478, Average Classification Loss: 3.8937
2019-01-13 23:09:21,017 - root - INFO - Epoch: 33, Step: 100, Average Loss: 5.5388, Average Regression Loss 1.6559, Average Classification Loss: 3.8829
2019-01-13 23:09:49,574 - root - INFO - Epoch: 33, Step: 200, Average Loss: 5.4983, Average Regression Loss 1.6338, Average Classification Loss: 3.8645
2019-01-13 23:10:18,138 - root - INFO - Epoch: 33, Step: 300, Average Loss: 5.5183, Average Regression Loss 1.6486, Average Classification Loss: 3.8697
2019-01-13 23:10:46,726 - root - INFO - Epoch: 33, Step: 400, Average Loss: 5.4087, Average Regression Loss 1.5968, Average Classification Loss: 3.8119
2019-01-13 23:11:15,364 - root - INFO - Epoch: 33, Step: 500, Average Loss: 5.4721, Average Regression Loss 1.6397, Average Classification Loss: 3.8324
2019-01-13 23:11:43,968 - root - INFO - Epoch: 33, Step: 600, Average Loss: 5.5217, Average Regression Loss 1.6516, Average Classification Loss: 3.8701
2019-01-13 23:12:39,234 - root - INFO - Epoch: 34, Step: 100, Average Loss: 5.5265, Average Regression Loss 1.6406, Average Classification Loss: 3.8858
2019-01-13 23:13:07,666 - root - INFO - Epoch: 34, Step: 200, Average Loss: 5.4639, Average Regression Loss 1.6307, Average Classification Loss: 3.8333
2019-01-13 23:13:36,106 - root - INFO - Epoch: 34, Step: 300, Average Loss: 5.4656, Average Regression Loss 1.6408, Average Classification Loss: 3.8248
2019-01-13 23:14:04,575 - root - INFO - Epoch: 34, Step: 400, Average Loss: 5.4460, Average Regression Loss 1.6196, Average Classification Loss: 3.8265
2019-01-13 23:14:33,023 - root - INFO - Epoch: 34, Step: 500, Average Loss: 5.4654, Average Regression Loss 1.6123, Average Classification Loss: 3.8532
2019-01-13 23:15:01,532 - root - INFO - Epoch: 34, Step: 600, Average Loss: 5.4581, Average Regression Loss 1.6360, Average Classification Loss: 3.8221
2019-01-13 23:15:56,488 - root - INFO - Epoch: 35, Step: 100, Average Loss: 5.4567, Average Regression Loss 1.6351, Average Classification Loss: 3.8216
2019-01-13 23:16:24,927 - root - INFO - Epoch: 35, Step: 200, Average Loss: 5.4193, Average Regression Loss 1.6257, Average Classification Loss: 3.7936
2019-01-13 23:16:53,442 - root - INFO - Epoch: 35, Step: 300, Average Loss: 5.4142, Average Regression Loss 1.6243, Average Classification Loss: 3.7900
2019-01-13 23:17:21,948 - root - INFO - Epoch: 35, Step: 400, Average Loss: 5.3834, Average Regression Loss 1.5963, Average Classification Loss: 3.7871
2019-01-13 23:17:50,478 - root - INFO - Epoch: 35, Step: 500, Average Loss: 5.4083, Average Regression Loss 1.5985, Average Classification Loss: 3.8098
2019-01-13 23:18:18,947 - root - INFO - Epoch: 35, Step: 600, Average Loss: 5.4787, Average Regression Loss 1.6196, Average Classification Loss: 3.8591
2019-01-13 23:19:03,526 - root - INFO - Epoch: 35, Validation Loss: 5.1832, Validation Regression Loss 1.6514, Validation Classification Loss: 3.5317
2019-01-13 23:19:03,605 - root - INFO - Saved model models/inception-Epoch-35-Loss-5.183169966158659.pth
2019-01-13 23:19:33,239 - root - INFO - Epoch: 36, Step: 100, Average Loss: 5.5495, Average Regression Loss 1.6774, Average Classification Loss: 3.8721
2019-01-13 23:20:01,703 - root - INFO - Epoch: 36, Step: 200, Average Loss: 5.3603, Average Regression Loss 1.5605, Average Classification Loss: 3.7997
2019-01-13 23:20:30,130 - root - INFO - Epoch: 36, Step: 300, Average Loss: 5.4227, Average Regression Loss 1.5973, Average Classification Loss: 3.8254
2019-01-13 23:20:58,584 - root - INFO - Epoch: 36, Step: 400, Average Loss: 5.4661, Average Regression Loss 1.6420, Average Classification Loss: 3.8241
2019-01-13 23:21:27,033 - root - INFO - Epoch: 36, Step: 500, Average Loss: 5.3669, Average Regression Loss 1.6111, Average Classification Loss: 3.7558
2019-01-13 23:21:55,526 - root - INFO - Epoch: 36, Step: 600, Average Loss: 5.3951, Average Regression Loss 1.6032, Average Classification Loss: 3.7919
2019-01-13 23:22:50,509 - root - INFO - Epoch: 37, Step: 100, Average Loss: 5.4383, Average Regression Loss 1.6137, Average Classification Loss: 3.8246
2019-01-13 23:23:18,950 - root - INFO - Epoch: 37, Step: 200, Average Loss: 5.3892, Average Regression Loss 1.6006, Average Classification Loss: 3.7886
2019-01-13 23:23:47,387 - root - INFO - Epoch: 37, Step: 300, Average Loss: 5.3249, Average Regression Loss 1.5890, Average Classification Loss: 3.7359
2019-01-13 23:24:15,855 - root - INFO - Epoch: 37, Step: 400, Average Loss: 5.3932, Average Regression Loss 1.6144, Average Classification Loss: 3.7789
2019-01-13 23:24:44,264 - root - INFO - Epoch: 37, Step: 500, Average Loss: 5.3521, Average Regression Loss 1.5849, Average Classification Loss: 3.7672
2019-01-13 23:25:12,824 - root - INFO - Epoch: 37, Step: 600, Average Loss: 5.3425, Average Regression Loss 1.5909, Average Classification Loss: 3.7516
2019-01-13 23:26:07,758 - root - INFO - Epoch: 38, Step: 100, Average Loss: 5.3887, Average Regression Loss 1.6098, Average Classification Loss: 3.7789
2019-01-13 23:26:36,250 - root - INFO - Epoch: 38, Step: 200, Average Loss: 5.3048, Average Regression Loss 1.5796, Average Classification Loss: 3.7252
2019-01-13 23:27:04,736 - root - INFO - Epoch: 38, Step: 300, Average Loss: 5.2875, Average Regression Loss 1.5721, Average Classification Loss: 3.7154
2019-01-13 23:27:33,220 - root - INFO - Epoch: 38, Step: 400, Average Loss: 5.3656, Average Regression Loss 1.6073, Average Classification Loss: 3.7583
2019-01-13 23:28:01,688 - root - INFO - Epoch: 38, Step: 500, Average Loss: 5.3468, Average Regression Loss 1.6014, Average Classification Loss: 3.7453
2019-01-13 23:28:30,196 - root - INFO - Epoch: 38, Step: 600, Average Loss: 5.3959, Average Regression Loss 1.6019, Average Classification Loss: 3.7940
2019-01-13 23:29:24,998 - root - INFO - Epoch: 39, Step: 100, Average Loss: 5.3289, Average Regression Loss 1.5869, Average Classification Loss: 3.7419
2019-01-13 23:29:53,426 - root - INFO - Epoch: 39, Step: 200, Average Loss: 5.3462, Average Regression Loss 1.5851, Average Classification Loss: 3.7611
2019-01-13 23:30:21,929 - root - INFO - Epoch: 39, Step: 300, Average Loss: 5.3022, Average Regression Loss 1.5536, Average Classification Loss: 3.7486
2019-01-13 23:30:50,432 - root - INFO - Epoch: 39, Step: 400, Average Loss: 5.3453, Average Regression Loss 1.6053, Average Classification Loss: 3.7400
2019-01-13 23:31:18,945 - root - INFO - Epoch: 39, Step: 500, Average Loss: 5.3133, Average Regression Loss 1.5622, Average Classification Loss: 3.7511
2019-01-13 23:31:47,439 - root - INFO - Epoch: 39, Step: 600, Average Loss: 5.3131, Average Regression Loss 1.5768, Average Classification Loss: 3.7364
2019-01-13 23:32:42,504 - root - INFO - Epoch: 40, Step: 100, Average Loss: 5.3634, Average Regression Loss 1.6073, Average Classification Loss: 3.7561
2019-01-13 23:33:10,931 - root - INFO - Epoch: 40, Step: 200, Average Loss: 5.2936, Average Regression Loss 1.5690, Average Classification Loss: 3.7246
2019-01-13 23:33:39,441 - root - INFO - Epoch: 40, Step: 300, Average Loss: 5.2936, Average Regression Loss 1.5745, Average Classification Loss: 3.7192
2019-01-13 23:34:07,959 - root - INFO - Epoch: 40, Step: 400, Average Loss: 5.3379, Average Regression Loss 1.5910, Average Classification Loss: 3.7469
2019-01-13 23:34:36,477 - root - INFO - Epoch: 40, Step: 500, Average Loss: 5.2895, Average Regression Loss 1.5702, Average Classification Loss: 3.7193
2019-01-13 23:35:04,956 - root - INFO - Epoch: 40, Step: 600, Average Loss: 5.2918, Average Regression Loss 1.5822, Average Classification Loss: 3.7096
2019-01-13 23:35:49,582 - root - INFO - Epoch: 40, Validation Loss: 5.0627, Validation Regression Loss 1.5955, Validation Classification Loss: 3.4672
2019-01-13 23:35:49,664 - root - INFO - Saved model models/inception-Epoch-40-Loss-5.062741440851331.pth
2019-01-13 23:36:19,314 - root - INFO - Epoch: 41, Step: 100, Average Loss: 5.3463, Average Regression Loss 1.5798, Average Classification Loss: 3.7664
2019-01-13 23:36:47,774 - root - INFO - Epoch: 41, Step: 200, Average Loss: 5.2123, Average Regression Loss 1.5531, Average Classification Loss: 3.6592
2019-01-13 23:37:16,250 - root - INFO - Epoch: 41, Step: 300, Average Loss: 5.3055, Average Regression Loss 1.5700, Average Classification Loss: 3.7355
2019-01-13 23:37:44,746 - root - INFO - Epoch: 41, Step: 400, Average Loss: 5.3418, Average Regression Loss 1.5954, Average Classification Loss: 3.7464
2019-01-13 23:38:13,211 - root - INFO - Epoch: 41, Step: 500, Average Loss: 5.2490, Average Regression Loss 1.5636, Average Classification Loss: 3.6854
2019-01-13 23:38:41,704 - root - INFO - Epoch: 41, Step: 600, Average Loss: 5.2588, Average Regression Loss 1.5559, Average Classification Loss: 3.7029
2019-01-13 23:39:36,575 - root - INFO - Epoch: 42, Step: 100, Average Loss: 5.3111, Average Regression Loss 1.5835, Average Classification Loss: 3.7276
2019-01-13 23:40:05,053 - root - INFO - Epoch: 42, Step: 200, Average Loss: 5.2094, Average Regression Loss 1.5396, Average Classification Loss: 3.6697
2019-01-13 23:40:33,490 - root - INFO - Epoch: 42, Step: 300, Average Loss: 5.2051, Average Regression Loss 1.5464, Average Classification Loss: 3.6587
2019-01-13 23:41:02,013 - root - INFO - Epoch: 42, Step: 400, Average Loss: 5.1698, Average Regression Loss 1.5286, Average Classification Loss: 3.6412
2019-01-13 23:41:30,482 - root - INFO - Epoch: 42, Step: 500, Average Loss: 5.2638, Average Regression Loss 1.5818, Average Classification Loss: 3.6820
2019-01-13 23:41:58,983 - root - INFO - Epoch: 42, Step: 600, Average Loss: 5.2506, Average Regression Loss 1.5708, Average Classification Loss: 3.6798
2019-01-13 23:42:53,973 - root - INFO - Epoch: 43, Step: 100, Average Loss: 5.3518, Average Regression Loss 1.6065, Average Classification Loss: 3.7453
2019-01-13 23:43:22,488 - root - INFO - Epoch: 43, Step: 200, Average Loss: 5.1908, Average Regression Loss 1.5350, Average Classification Loss: 3.6558
2019-01-13 23:43:51,072 - root - INFO - Epoch: 43, Step: 300, Average Loss: 5.2412, Average Regression Loss 1.5454, Average Classification Loss: 3.6958
2019-01-13 23:44:19,696 - root - INFO - Epoch: 43, Step: 400, Average Loss: 5.2052, Average Regression Loss 1.5359, Average Classification Loss: 3.6693
2019-01-13 23:44:48,283 - root - INFO - Epoch: 43, Step: 500, Average Loss: 5.2009, Average Regression Loss 1.5424, Average Classification Loss: 3.6585
2019-01-13 23:45:16,873 - root - INFO - Epoch: 43, Step: 600, Average Loss: 5.2886, Average Regression Loss 1.5855, Average Classification Loss: 3.7030
2019-01-13 23:46:11,984 - root - INFO - Epoch: 44, Step: 100, Average Loss: 5.2726, Average Regression Loss 1.5798, Average Classification Loss: 3.6928
2019-01-13 23:46:40,403 - root - INFO - Epoch: 44, Step: 200, Average Loss: 5.1800, Average Regression Loss 1.5159, Average Classification Loss: 3.6641
2019-01-13 23:47:08,789 - root - INFO - Epoch: 44, Step: 300, Average Loss: 5.2052, Average Regression Loss 1.5368, Average Classification Loss: 3.6684
2019-01-13 23:47:37,256 - root - INFO - Epoch: 44, Step: 400, Average Loss: 5.2025, Average Regression Loss 1.5778, Average Classification Loss: 3.6247
2019-01-13 23:48:05,707 - root - INFO - Epoch: 44, Step: 500, Average Loss: 5.1704, Average Regression Loss 1.5151, Average Classification Loss: 3.6553
2019-01-13 23:48:34,274 - root - INFO - Epoch: 44, Step: 600, Average Loss: 5.2442, Average Regression Loss 1.5651, Average Classification Loss: 3.6791
2019-01-13 23:49:29,167 - root - INFO - Epoch: 45, Step: 100, Average Loss: 5.2087, Average Regression Loss 1.5478, Average Classification Loss: 3.6609
2019-01-13 23:49:57,651 - root - INFO - Epoch: 45, Step: 200, Average Loss: 5.2156, Average Regression Loss 1.5495, Average Classification Loss: 3.6661
2019-01-13 23:50:26,150 - root - INFO - Epoch: 45, Step: 300, Average Loss: 5.1526, Average Regression Loss 1.5373, Average Classification Loss: 3.6153
2019-01-13 23:50:54,602 - root - INFO - Epoch: 45, Step: 400, Average Loss: 5.1971, Average Regression Loss 1.5405, Average Classification Loss: 3.6566
2019-01-13 23:51:23,100 - root - INFO - Epoch: 45, Step: 500, Average Loss: 5.1464, Average Regression Loss 1.5136, Average Classification Loss: 3.6328
2019-01-13 23:51:51,615 - root - INFO - Epoch: 45, Step: 600, Average Loss: 5.1873, Average Regression Loss 1.5532, Average Classification Loss: 3.6341
2019-01-13 23:52:36,145 - root - INFO - Epoch: 45, Validation Loss: 5.0399, Validation Regression Loss 1.5949, Validation Classification Loss: 3.4450
2019-01-13 23:52:36,221 - root - INFO - Saved model models/inception-Epoch-45-Loss-5.039898480770093.pth
2019-01-13 23:53:05,788 - root - INFO - Epoch: 46, Step: 100, Average Loss: 5.2122, Average Regression Loss 1.5461, Average Classification Loss: 3.6660
2019-01-13 23:53:34,253 - root - INFO - Epoch: 46, Step: 200, Average Loss: 5.1551, Average Regression Loss 1.5498, Average Classification Loss: 3.6053
2019-01-13 23:54:02,678 - root - INFO - Epoch: 46, Step: 300, Average Loss: 5.1874, Average Regression Loss 1.5388, Average Classification Loss: 3.6486
2019-01-13 23:54:31,174 - root - INFO - Epoch: 46, Step: 400, Average Loss: 5.1191, Average Regression Loss 1.5295, Average Classification Loss: 3.5896
2019-01-13 23:54:59,600 - root - INFO - Epoch: 46, Step: 500, Average Loss: 5.0773, Average Regression Loss 1.4964, Average Classification Loss: 3.5809
2019-01-13 23:55:27,978 - root - INFO - Epoch: 46, Step: 600, Average Loss: 5.1442, Average Regression Loss 1.5232, Average Classification Loss: 3.6209
2019-01-13 23:56:22,797 - root - INFO - Epoch: 47, Step: 100, Average Loss: 5.2087, Average Regression Loss 1.5706, Average Classification Loss: 3.6381
2019-01-13 23:56:51,221 - root - INFO - Epoch: 47, Step: 200, Average Loss: 5.1061, Average Regression Loss 1.5355, Average Classification Loss: 3.5706
2019-01-13 23:57:19,704 - root - INFO - Epoch: 47, Step: 300, Average Loss: 5.1527, Average Regression Loss 1.5077, Average Classification Loss: 3.6450
2019-01-13 23:57:48,198 - root - INFO - Epoch: 47, Step: 400, Average Loss: 5.1117, Average Regression Loss 1.5339, Average Classification Loss: 3.5778
2019-01-13 23:58:16,668 - root - INFO - Epoch: 47, Step: 500, Average Loss: 5.0755, Average Regression Loss 1.5208, Average Classification Loss: 3.5547
2019-01-13 23:58:45,157 - root - INFO - Epoch: 47, Step: 600, Average Loss: 5.2327, Average Regression Loss 1.5432, Average Classification Loss: 3.6894
2019-01-13 23:59:40,107 - root - INFO - Epoch: 48, Step: 100, Average Loss: 5.1681, Average Regression Loss 1.5288, Average Classification Loss: 3.6393
2019-01-14 00:00:08,655 - root - INFO - Epoch: 48, Step: 200, Average Loss: 5.1283, Average Regression Loss 1.5288, Average Classification Loss: 3.5995
2019-01-14 00:00:37,200 - root - INFO - Epoch: 48, Step: 300, Average Loss: 5.1096, Average Regression Loss 1.5288, Average Classification Loss: 3.5808
2019-01-14 00:01:05,793 - root - INFO - Epoch: 48, Step: 400, Average Loss: 5.1130, Average Regression Loss 1.5214, Average Classification Loss: 3.5915
2019-01-14 00:01:34,437 - root - INFO - Epoch: 48, Step: 500, Average Loss: 5.0733, Average Regression Loss 1.5050, Average Classification Loss: 3.5684
2019-01-14 00:02:03,041 - root - INFO - Epoch: 48, Step: 600, Average Loss: 5.1065, Average Regression Loss 1.5316, Average Classification Loss: 3.5749
2019-01-14 00:02:58,194 - root - INFO - Epoch: 49, Step: 100, Average Loss: 5.1651, Average Regression Loss 1.5422, Average Classification Loss: 3.6229
2019-01-14 00:03:26,666 - root - INFO - Epoch: 49, Step: 200, Average Loss: 5.0718, Average Regression Loss 1.5012, Average Classification Loss: 3.5706
2019-01-14 00:03:55,104 - root - INFO - Epoch: 49, Step: 300, Average Loss: 5.0878, Average Regression Loss 1.4915, Average Classification Loss: 3.5963
2019-01-14 00:04:23,605 - root - INFO - Epoch: 49, Step: 400, Average Loss: 5.0737, Average Regression Loss 1.5417, Average Classification Loss: 3.5320
2019-01-14 00:04:52,082 - root - INFO - Epoch: 49, Step: 500, Average Loss: 5.0096, Average Regression Loss 1.4622, Average Classification Loss: 3.5474
2019-01-14 00:05:20,574 - root - INFO - Epoch: 49, Step: 600, Average Loss: 5.1645, Average Regression Loss 1.5366, Average Classification Loss: 3.6279
2019-01-14 00:06:15,445 - root - INFO - Epoch: 50, Step: 100, Average Loss: 5.1346, Average Regression Loss 1.5362, Average Classification Loss: 3.5984
2019-01-14 00:06:43,888 - root - INFO - Epoch: 50, Step: 200, Average Loss: 5.0964, Average Regression Loss 1.5255, Average Classification Loss: 3.5709
2019-01-14 00:07:12,410 - root - INFO - Epoch: 50, Step: 300, Average Loss: 5.0419, Average Regression Loss 1.4833, Average Classification Loss: 3.5586
2019-01-14 00:07:40,836 - root - INFO - Epoch: 50, Step: 400, Average Loss: 5.0982, Average Regression Loss 1.5139, Average Classification Loss: 3.5843
2019-01-14 00:08:09,291 - root - INFO - Epoch: 50, Step: 500, Average Loss: 5.0623, Average Regression Loss 1.4932, Average Classification Loss: 3.5691
2019-01-14 00:08:37,807 - root - INFO - Epoch: 50, Step: 600, Average Loss: 5.0444, Average Regression Loss 1.5210, Average Classification Loss: 3.5234
2019-01-14 00:09:22,380 - root - INFO - Epoch: 50, Validation Loss: 4.8409, Validation Regression Loss 1.5321, Validation Classification Loss: 3.3088
2019-01-14 00:09:22,460 - root - INFO - Saved model models/inception-Epoch-50-Loss-4.840862779801594.pth
2019-01-14 00:09:52,058 - root - INFO - Epoch: 51, Step: 100, Average Loss: 5.1033, Average Regression Loss 1.5311, Average Classification Loss: 3.5722
2019-01-14 00:10:20,556 - root - INFO - Epoch: 51, Step: 200, Average Loss: 4.9934, Average Regression Loss 1.4881, Average Classification Loss: 3.5053
2019-01-14 00:10:49,034 - root - INFO - Epoch: 51, Step: 300, Average Loss: 5.0465, Average Regression Loss 1.4976, Average Classification Loss: 3.5488
2019-01-14 00:11:17,550 - root - INFO - Epoch: 51, Step: 400, Average Loss: 5.0227, Average Regression Loss 1.4809, Average Classification Loss: 3.5419
2019-01-14 00:11:46,044 - root - INFO - Epoch: 51, Step: 500, Average Loss: 5.0076, Average Regression Loss 1.4997, Average Classification Loss: 3.5080
2019-01-14 00:12:14,574 - root - INFO - Epoch: 51, Step: 600, Average Loss: 5.0367, Average Regression Loss 1.5287, Average Classification Loss: 3.5080
2019-01-14 00:13:09,551 - root - INFO - Epoch: 52, Step: 100, Average Loss: 5.1022, Average Regression Loss 1.5024, Average Classification Loss: 3.5998
2019-01-14 00:13:38,060 - root - INFO - Epoch: 52, Step: 200, Average Loss: 5.0776, Average Regression Loss 1.5178, Average Classification Loss: 3.5598
2019-01-14 00:14:06,480 - root - INFO - Epoch: 52, Step: 300, Average Loss: 5.0455, Average Regression Loss 1.4923, Average Classification Loss: 3.5532
2019-01-14 00:14:34,981 - root - INFO - Epoch: 52, Step: 400, Average Loss: 5.0486, Average Regression Loss 1.5077, Average Classification Loss: 3.5409
2019-01-14 00:15:03,435 - root - INFO - Epoch: 52, Step: 500, Average Loss: 4.9826, Average Regression Loss 1.4801, Average Classification Loss: 3.5025
2019-01-14 00:15:31,901 - root - INFO - Epoch: 52, Step: 600, Average Loss: 5.0233, Average Regression Loss 1.5026, Average Classification Loss: 3.5207
2019-01-14 00:16:26,899 - root - INFO - Epoch: 53, Step: 100, Average Loss: 5.0133, Average Regression Loss 1.5102, Average Classification Loss: 3.5030
2019-01-14 00:16:55,361 - root - INFO - Epoch: 53, Step: 200, Average Loss: 4.9991, Average Regression Loss 1.4771, Average Classification Loss: 3.5220
2019-01-14 00:17:23,811 - root - INFO - Epoch: 53, Step: 300, Average Loss: 5.0639, Average Regression Loss 1.5025, Average Classification Loss: 3.5614
2019-01-14 00:17:52,301 - root - INFO - Epoch: 53, Step: 400, Average Loss: 5.0096, Average Regression Loss 1.4889, Average Classification Loss: 3.5207
2019-01-14 00:18:20,804 - root - INFO - Epoch: 53, Step: 500, Average Loss: 4.9415, Average Regression Loss 1.4716, Average Classification Loss: 3.4699
2019-01-14 00:18:49,353 - root - INFO - Epoch: 53, Step: 600, Average Loss: 5.0736, Average Regression Loss 1.5164, Average Classification Loss: 3.5572
2019-01-14 00:19:44,266 - root - INFO - Epoch: 54, Step: 100, Average Loss: 5.0319, Average Regression Loss 1.4767, Average Classification Loss: 3.5551
2019-01-14 00:20:12,730 - root - INFO - Epoch: 54, Step: 200, Average Loss: 4.9491, Average Regression Loss 1.4783, Average Classification Loss: 3.4708
2019-01-14 00:20:41,226 - root - INFO - Epoch: 54, Step: 300, Average Loss: 5.0100, Average Regression Loss 1.5031, Average Classification Loss: 3.5070
2019-01-14 00:21:09,701 - root - INFO - Epoch: 54, Step: 400, Average Loss: 5.0384, Average Regression Loss 1.5062, Average Classification Loss: 3.5321
2019-01-14 00:21:38,205 - root - INFO - Epoch: 54, Step: 500, Average Loss: 5.0286, Average Regression Loss 1.4857, Average Classification Loss: 3.5429
2019-01-14 00:22:06,688 - root - INFO - Epoch: 54, Step: 600, Average Loss: 4.9924, Average Regression Loss 1.4980, Average Classification Loss: 3.4943
2019-01-14 00:23:01,751 - root - INFO - Epoch: 55, Step: 100, Average Loss: 5.0434, Average Regression Loss 1.5133, Average Classification Loss: 3.5301
2019-01-14 00:23:30,214 - root - INFO - Epoch: 55, Step: 200, Average Loss: 5.0077, Average Regression Loss 1.4863, Average Classification Loss: 3.5213
2019-01-14 00:23:58,733 - root - INFO - Epoch: 55, Step: 300, Average Loss: 4.9986, Average Regression Loss 1.4673, Average Classification Loss: 3.5314
2019-01-14 00:24:27,209 - root - INFO - Epoch: 55, Step: 400, Average Loss: 4.9607, Average Regression Loss 1.4656, Average Classification Loss: 3.4951
2019-01-14 00:24:55,681 - root - INFO - Epoch: 55, Step: 500, Average Loss: 4.9653, Average Regression Loss 1.4965, Average Classification Loss: 3.4688
2019-01-14 00:25:24,202 - root - INFO - Epoch: 55, Step: 600, Average Loss: 4.9927, Average Regression Loss 1.5051, Average Classification Loss: 3.4876
2019-01-14 00:26:08,684 - root - INFO - Epoch: 55, Validation Loss: 4.7668, Validation Regression Loss 1.5128, Validation Classification Loss: 3.2541
2019-01-14 00:26:08,761 - root - INFO - Saved model models/inception-Epoch-55-Loss-4.76683833748822.pth
2019-01-14 00:26:38,438 - root - INFO - Epoch: 56, Step: 100, Average Loss: 5.0251, Average Regression Loss 1.5165, Average Classification Loss: 3.5086
2019-01-14 00:27:06,871 - root - INFO - Epoch: 56, Step: 200, Average Loss: 4.8978, Average Regression Loss 1.4642, Average Classification Loss: 3.4336
2019-01-14 00:27:35,367 - root - INFO - Epoch: 56, Step: 300, Average Loss: 4.9037, Average Regression Loss 1.4487, Average Classification Loss: 3.4550
2019-01-14 00:28:03,890 - root - INFO - Epoch: 56, Step: 400, Average Loss: 5.0079, Average Regression Loss 1.4932, Average Classification Loss: 3.5147
2019-01-14 00:28:32,322 - root - INFO - Epoch: 56, Step: 500, Average Loss: 4.9424, Average Regression Loss 1.4667, Average Classification Loss: 3.4756
2019-01-14 00:29:00,810 - root - INFO - Epoch: 56, Step: 600, Average Loss: 4.9304, Average Regression Loss 1.4798, Average Classification Loss: 3.4505
2019-01-14 00:29:55,652 - root - INFO - Epoch: 57, Step: 100, Average Loss: 5.0587, Average Regression Loss 1.5072, Average Classification Loss: 3.5515
2019-01-14 00:30:24,119 - root - INFO - Epoch: 57, Step: 200, Average Loss: 4.9485, Average Regression Loss 1.4705, Average Classification Loss: 3.4781
2019-01-14 00:30:52,599 - root - INFO - Epoch: 57, Step: 300, Average Loss: 4.9032, Average Regression Loss 1.4519, Average Classification Loss: 3.4513
2019-01-14 00:31:21,031 - root - INFO - Epoch: 57, Step: 400, Average Loss: 4.9384, Average Regression Loss 1.4718, Average Classification Loss: 3.4666
2019-01-14 00:31:49,516 - root - INFO - Epoch: 57, Step: 500, Average Loss: 4.9265, Average Regression Loss 1.4619, Average Classification Loss: 3.4647
2019-01-14 00:32:18,046 - root - INFO - Epoch: 57, Step: 600, Average Loss: 4.9551, Average Regression Loss 1.4903, Average Classification Loss: 3.4648
2019-01-14 00:33:12,971 - root - INFO - Epoch: 58, Step: 100, Average Loss: 5.0298, Average Regression Loss 1.5201, Average Classification Loss: 3.5097
2019-01-14 00:33:41,555 - root - INFO - Epoch: 58, Step: 200, Average Loss: 4.9086, Average Regression Loss 1.4517, Average Classification Loss: 3.4569
2019-01-14 00:34:10,170 - root - INFO - Epoch: 58, Step: 300, Average Loss: 4.9240, Average Regression Loss 1.4779, Average Classification Loss: 3.4462
2019-01-14 00:34:38,791 - root - INFO - Epoch: 58, Step: 400, Average Loss: 4.9484, Average Regression Loss 1.4774, Average Classification Loss: 3.4710
2019-01-14 00:35:07,429 - root - INFO - Epoch: 58, Step: 500, Average Loss: 4.8926, Average Regression Loss 1.4608, Average Classification Loss: 3.4317
2019-01-14 00:35:36,024 - root - INFO - Epoch: 58, Step: 600, Average Loss: 4.9134, Average Regression Loss 1.4709, Average Classification Loss: 3.4425
2019-01-14 00:36:31,164 - root - INFO - Epoch: 59, Step: 100, Average Loss: 4.9625, Average Regression Loss 1.4980, Average Classification Loss: 3.4646
2019-01-14 00:36:59,589 - root - INFO - Epoch: 59, Step: 200, Average Loss: 4.9145, Average Regression Loss 1.4546, Average Classification Loss: 3.4599
2019-01-14 00:37:28,105 - root - INFO - Epoch: 59, Step: 300, Average Loss: 4.8867, Average Regression Loss 1.4524, Average Classification Loss: 3.4343
2019-01-14 00:37:56,563 - root - INFO - Epoch: 59, Step: 400, Average Loss: 4.9351, Average Regression Loss 1.4700, Average Classification Loss: 3.4651
2019-01-14 00:38:25,049 - root - INFO - Epoch: 59, Step: 500, Average Loss: 4.9110, Average Regression Loss 1.4516, Average Classification Loss: 3.4593
2019-01-14 00:38:53,542 - root - INFO - Epoch: 59, Step: 600, Average Loss: 4.9281, Average Regression Loss 1.4694, Average Classification Loss: 3.4587
2019-01-14 00:39:48,541 - root - INFO - Epoch: 60, Step: 100, Average Loss: 4.9573, Average Regression Loss 1.4715, Average Classification Loss: 3.4858
2019-01-14 00:40:17,034 - root - INFO - Epoch: 60, Step: 200, Average Loss: 4.8816, Average Regression Loss 1.4435, Average Classification Loss: 3.4382
2019-01-14 00:40:45,566 - root - INFO - Epoch: 60, Step: 300, Average Loss: 4.8665, Average Regression Loss 1.4445, Average Classification Loss: 3.4221
2019-01-14 00:41:14,039 - root - INFO - Epoch: 60, Step: 400, Average Loss: 4.9482, Average Regression Loss 1.4823, Average Classification Loss: 3.4659
2019-01-14 00:41:42,536 - root - INFO - Epoch: 60, Step: 500, Average Loss: 4.9260, Average Regression Loss 1.4580, Average Classification Loss: 3.4680
2019-01-14 00:42:11,030 - root - INFO - Epoch: 60, Step: 600, Average Loss: 4.8309, Average Regression Loss 1.4453, Average Classification Loss: 3.3856
2019-01-14 00:42:55,650 - root - INFO - Epoch: 60, Validation Loss: 4.6760, Validation Regression Loss 1.4959, Validation Classification Loss: 3.1801
2019-01-14 00:42:55,733 - root - INFO - Saved model models/inception-Epoch-60-Loss-4.676046035140033.pth
2019-01-14 00:43:25,250 - root - INFO - Epoch: 61, Step: 100, Average Loss: 4.9074, Average Regression Loss 1.4595, Average Classification Loss: 3.4478
2019-01-14 00:43:53,699 - root - INFO - Epoch: 61, Step: 200, Average Loss: 4.8308, Average Regression Loss 1.4343, Average Classification Loss: 3.3965
2019-01-14 00:44:22,165 - root - INFO - Epoch: 61, Step: 300, Average Loss: 4.8855, Average Regression Loss 1.4647, Average Classification Loss: 3.4208
2019-01-14 00:44:50,621 - root - INFO - Epoch: 61, Step: 400, Average Loss: 4.8647, Average Regression Loss 1.4472, Average Classification Loss: 3.4176
2019-01-14 00:45:19,134 - root - INFO - Epoch: 61, Step: 500, Average Loss: 4.8463, Average Regression Loss 1.4480, Average Classification Loss: 3.3982
2019-01-14 00:45:47,620 - root - INFO - Epoch: 61, Step: 600, Average Loss: 4.8648, Average Regression Loss 1.4357, Average Classification Loss: 3.4292
2019-01-14 00:46:42,700 - root - INFO - Epoch: 62, Step: 100, Average Loss: 4.9374, Average Regression Loss 1.4780, Average Classification Loss: 3.4594
2019-01-14 00:47:11,295 - root - INFO - Epoch: 62, Step: 200, Average Loss: 4.8175, Average Regression Loss 1.3977, Average Classification Loss: 3.4198
2019-01-14 00:47:39,860 - root - INFO - Epoch: 62, Step: 300, Average Loss: 4.8110, Average Regression Loss 1.4243, Average Classification Loss: 3.3866
2019-01-14 00:48:08,520 - root - INFO - Epoch: 62, Step: 400, Average Loss: 4.8743, Average Regression Loss 1.4601, Average Classification Loss: 3.4143
2019-01-14 00:48:37,127 - root - INFO - Epoch: 62, Step: 500, Average Loss: 4.8510, Average Regression Loss 1.4489, Average Classification Loss: 3.4021
2019-01-14 00:49:05,694 - root - INFO - Epoch: 62, Step: 600, Average Loss: 4.8264, Average Regression Loss 1.4290, Average Classification Loss: 3.3973
2019-01-14 00:50:00,830 - root - INFO - Epoch: 63, Step: 100, Average Loss: 4.9186, Average Regression Loss 1.4596, Average Classification Loss: 3.4590
2019-01-14 00:50:29,484 - root - INFO - Epoch: 63, Step: 200, Average Loss: 4.8248, Average Regression Loss 1.4207, Average Classification Loss: 3.4041
2019-01-14 00:50:58,164 - root - INFO - Epoch: 63, Step: 300, Average Loss: 4.8895, Average Regression Loss 1.4733, Average Classification Loss: 3.4162
2019-01-14 00:51:26,813 - root - INFO - Epoch: 63, Step: 400, Average Loss: 4.8211, Average Regression Loss 1.4485, Average Classification Loss: 3.3725
2019-01-14 00:51:55,484 - root - INFO - Epoch: 63, Step: 500, Average Loss: 4.8333, Average Regression Loss 1.4517, Average Classification Loss: 3.3816
2019-01-14 00:52:24,144 - root - INFO - Epoch: 63, Step: 600, Average Loss: 4.8320, Average Regression Loss 1.4306, Average Classification Loss: 3.4015
2019-01-14 00:53:19,268 - root - INFO - Epoch: 64, Step: 100, Average Loss: 4.8911, Average Regression Loss 1.4320, Average Classification Loss: 3.4591
2019-01-14 00:53:47,721 - root - INFO - Epoch: 64, Step: 200, Average Loss: 4.7674, Average Regression Loss 1.4305, Average Classification Loss: 3.3368
2019-01-14 00:54:16,225 - root - INFO - Epoch: 64, Step: 300, Average Loss: 4.8389, Average Regression Loss 1.4405, Average Classification Loss: 3.3984
2019-01-14 00:54:44,708 - root - INFO - Epoch: 64, Step: 400, Average Loss: 4.8278, Average Regression Loss 1.4365, Average Classification Loss: 3.3913
2019-01-14 00:55:13,153 - root - INFO - Epoch: 64, Step: 500, Average Loss: 4.8103, Average Regression Loss 1.4335, Average Classification Loss: 3.3768
2019-01-14 00:55:41,566 - root - INFO - Epoch: 64, Step: 600, Average Loss: 4.8295, Average Regression Loss 1.4279, Average Classification Loss: 3.4015
2019-01-14 00:56:36,389 - root - INFO - Epoch: 65, Step: 100, Average Loss: 4.9258, Average Regression Loss 1.4614, Average Classification Loss: 3.4644
2019-01-14 00:57:04,885 - root - INFO - Epoch: 65, Step: 200, Average Loss: 4.8134, Average Regression Loss 1.4355, Average Classification Loss: 3.3779
2019-01-14 00:57:33,341 - root - INFO - Epoch: 65, Step: 300, Average Loss: 4.7548, Average Regression Loss 1.4043, Average Classification Loss: 3.3505
2019-01-14 00:58:01,855 - root - INFO - Epoch: 65, Step: 400, Average Loss: 4.8137, Average Regression Loss 1.4295, Average Classification Loss: 3.3843
2019-01-14 00:58:30,323 - root - INFO - Epoch: 65, Step: 500, Average Loss: 4.8287, Average Regression Loss 1.4474, Average Classification Loss: 3.3813
2019-01-14 00:58:58,854 - root - INFO - Epoch: 65, Step: 600, Average Loss: 4.7590, Average Regression Loss 1.4158, Average Classification Loss: 3.3432
2019-01-14 00:59:43,351 - root - INFO - Epoch: 65, Validation Loss: 4.5772, Validation Regression Loss 1.4529, Validation Classification Loss: 3.1243
2019-01-14 00:59:43,430 - root - INFO - Saved model models/inception-Epoch-65-Loss-4.5772060334394515.pth
2019-01-14 01:00:12,994 - root - INFO - Epoch: 66, Step: 100, Average Loss: 4.8717, Average Regression Loss 1.4655, Average Classification Loss: 3.4061
2019-01-14 01:00:41,483 - root - INFO - Epoch: 66, Step: 200, Average Loss: 4.7559, Average Regression Loss 1.4149, Average Classification Loss: 3.3410
2019-01-14 01:01:09,880 - root - INFO - Epoch: 66, Step: 300, Average Loss: 4.7597, Average Regression Loss 1.4010, Average Classification Loss: 3.3587
2019-01-14 01:01:38,403 - root - INFO - Epoch: 66, Step: 400, Average Loss: 4.8007, Average Regression Loss 1.4353, Average Classification Loss: 3.3654
2019-01-14 01:02:06,856 - root - INFO - Epoch: 66, Step: 500, Average Loss: 4.8597, Average Regression Loss 1.4559, Average Classification Loss: 3.4037
2019-01-14 01:02:35,361 - root - INFO - Epoch: 66, Step: 600, Average Loss: 4.7941, Average Regression Loss 1.4409, Average Classification Loss: 3.3531
2019-01-14 01:03:30,347 - root - INFO - Epoch: 67, Step: 100, Average Loss: 4.8481, Average Regression Loss 1.4403, Average Classification Loss: 3.4079
2019-01-14 01:03:58,812 - root - INFO - Epoch: 67, Step: 200, Average Loss: 4.7165, Average Regression Loss 1.3911, Average Classification Loss: 3.3255
2019-01-14 01:04:27,305 - root - INFO - Epoch: 67, Step: 300, Average Loss: 4.7500, Average Regression Loss 1.4056, Average Classification Loss: 3.3444
2019-01-14 01:04:55,770 - root - INFO - Epoch: 67, Step: 400, Average Loss: 4.7601, Average Regression Loss 1.4194, Average Classification Loss: 3.3407
2019-01-14 01:05:24,238 - root - INFO - Epoch: 67, Step: 500, Average Loss: 4.7625, Average Regression Loss 1.4106, Average Classification Loss: 3.3518
2019-01-14 01:05:52,744 - root - INFO - Epoch: 67, Step: 600, Average Loss: 4.7778, Average Regression Loss 1.4314, Average Classification Loss: 3.3464
2019-01-14 01:06:47,720 - root - INFO - Epoch: 68, Step: 100, Average Loss: 4.8002, Average Regression Loss 1.4333, Average Classification Loss: 3.3669
2019-01-14 01:07:16,232 - root - INFO - Epoch: 68, Step: 200, Average Loss: 4.7003, Average Regression Loss 1.3850, Average Classification Loss: 3.3153
2019-01-14 01:07:44,724 - root - INFO - Epoch: 68, Step: 300, Average Loss: 4.7651, Average Regression Loss 1.4093, Average Classification Loss: 3.3558
2019-01-14 01:08:13,216 - root - INFO - Epoch: 68, Step: 400, Average Loss: 4.7804, Average Regression Loss 1.4264, Average Classification Loss: 3.3541
2019-01-14 01:08:41,737 - root - INFO - Epoch: 68, Step: 500, Average Loss: 4.7575, Average Regression Loss 1.4127, Average Classification Loss: 3.3448
2019-01-14 01:09:10,173 - root - INFO - Epoch: 68, Step: 600, Average Loss: 4.7665, Average Regression Loss 1.4127, Average Classification Loss: 3.3539
2019-01-14 01:10:05,181 - root - INFO - Epoch: 69, Step: 100, Average Loss: 4.7320, Average Regression Loss 1.4021, Average Classification Loss: 3.3299
2019-01-14 01:10:33,650 - root - INFO - Epoch: 69, Step: 200, Average Loss: 4.7659, Average Regression Loss 1.4142, Average Classification Loss: 3.3517
2019-01-14 01:11:02,107 - root - INFO - Epoch: 69, Step: 300, Average Loss: 4.7394, Average Regression Loss 1.4027, Average Classification Loss: 3.3367
2019-01-14 01:11:30,655 - root - INFO - Epoch: 69, Step: 400, Average Loss: 4.6778, Average Regression Loss 1.3953, Average Classification Loss: 3.2824
2019-01-14 01:11:59,140 - root - INFO - Epoch: 69, Step: 500, Average Loss: 4.7521, Average Regression Loss 1.4160, Average Classification Loss: 3.3361
2019-01-14 01:12:27,657 - root - INFO - Epoch: 69, Step: 600, Average Loss: 4.7877, Average Regression Loss 1.4169, Average Classification Loss: 3.3707
2019-01-14 01:13:22,417 - root - INFO - Epoch: 70, Step: 100, Average Loss: 4.8018, Average Regression Loss 1.4275, Average Classification Loss: 3.3743
2019-01-14 01:13:50,852 - root - INFO - Epoch: 70, Step: 200, Average Loss: 4.6886, Average Regression Loss 1.3820, Average Classification Loss: 3.3066
2019-01-14 01:14:19,360 - root - INFO - Epoch: 70, Step: 300, Average Loss: 4.7245, Average Regression Loss 1.3984, Average Classification Loss: 3.3261
2019-01-14 01:14:47,839 - root - INFO - Epoch: 70, Step: 400, Average Loss: 4.7373, Average Regression Loss 1.4177, Average Classification Loss: 3.3197
2019-01-14 01:15:16,379 - root - INFO - Epoch: 70, Step: 500, Average Loss: 4.7124, Average Regression Loss 1.3864, Average Classification Loss: 3.3261
2019-01-14 01:15:44,900 - root - INFO - Epoch: 70, Step: 600, Average Loss: 4.7374, Average Regression Loss 1.3980, Average Classification Loss: 3.3394
2019-01-14 01:16:29,568 - root - INFO - Epoch: 70, Validation Loss: 4.4875, Validation Regression Loss 1.4234, Validation Classification Loss: 3.0642
2019-01-14 01:16:29,646 - root - INFO - Saved model models/inception-Epoch-70-Loss-4.487544386859101.pth
2019-01-14 01:16:59,256 - root - INFO - Epoch: 71, Step: 100, Average Loss: 4.7995, Average Regression Loss 1.4289, Average Classification Loss: 3.3706
2019-01-14 01:17:27,698 - root - INFO - Epoch: 71, Step: 200, Average Loss: 4.6978, Average Regression Loss 1.3742, Average Classification Loss: 3.3237
2019-01-14 01:17:56,207 - root - INFO - Epoch: 71, Step: 300, Average Loss: 4.7328, Average Regression Loss 1.3987, Average Classification Loss: 3.3341
2019-01-14 01:18:24,719 - root - INFO - Epoch: 71, Step: 400, Average Loss: 4.6707, Average Regression Loss 1.3990, Average Classification Loss: 3.2717
2019-01-14 01:18:53,167 - root - INFO - Epoch: 71, Step: 500, Average Loss: 4.6954, Average Regression Loss 1.3975, Average Classification Loss: 3.2980
2019-01-14 01:19:21,719 - root - INFO - Epoch: 71, Step: 600, Average Loss: 4.6697, Average Regression Loss 1.3771, Average Classification Loss: 3.2926
2019-01-14 01:20:16,698 - root - INFO - Epoch: 72, Step: 100, Average Loss: 4.7406, Average Regression Loss 1.4225, Average Classification Loss: 3.3181
2019-01-14 01:20:45,220 - root - INFO - Epoch: 72, Step: 200, Average Loss: 4.6653, Average Regression Loss 1.3985, Average Classification Loss: 3.2669
2019-01-14 01:21:13,675 - root - INFO - Epoch: 72, Step: 300, Average Loss: 4.6899, Average Regression Loss 1.3950, Average Classification Loss: 3.2949
2019-01-14 01:21:42,138 - root - INFO - Epoch: 72, Step: 400, Average Loss: 4.7084, Average Regression Loss 1.3899, Average Classification Loss: 3.3185
2019-01-14 01:22:10,652 - root - INFO - Epoch: 72, Step: 500, Average Loss: 4.6706, Average Regression Loss 1.3979, Average Classification Loss: 3.2727
2019-01-14 01:22:39,176 - root - INFO - Epoch: 72, Step: 600, Average Loss: 4.7767, Average Regression Loss 1.4322, Average Classification Loss: 3.3446
2019-01-14 01:23:34,146 - root - INFO - Epoch: 73, Step: 100, Average Loss: 4.8308, Average Regression Loss 1.4526, Average Classification Loss: 3.3782
2019-01-14 01:24:02,598 - root - INFO - Epoch: 73, Step: 200, Average Loss: 4.6409, Average Regression Loss 1.3733, Average Classification Loss: 3.2676
2019-01-14 01:24:31,082 - root - INFO - Epoch: 73, Step: 300, Average Loss: 4.7102, Average Regression Loss 1.3851, Average Classification Loss: 3.3251
2019-01-14 01:24:59,489 - root - INFO - Epoch: 73, Step: 400, Average Loss: 4.6202, Average Regression Loss 1.3726, Average Classification Loss: 3.2476
2019-01-14 01:25:28,024 - root - INFO - Epoch: 73, Step: 500, Average Loss: 4.6381, Average Regression Loss 1.3728, Average Classification Loss: 3.2653
2019-01-14 01:25:56,478 - root - INFO - Epoch: 73, Step: 600, Average Loss: 4.7480, Average Regression Loss 1.4208, Average Classification Loss: 3.3272
2019-01-14 01:26:51,572 - root - INFO - Epoch: 74, Step: 100, Average Loss: 4.7804, Average Regression Loss 1.4289, Average Classification Loss: 3.3515
2019-01-14 01:27:20,225 - root - INFO - Epoch: 74, Step: 200, Average Loss: 4.6385, Average Regression Loss 1.3790, Average Classification Loss: 3.2595
2019-01-14 01:27:48,866 - root - INFO - Epoch: 74, Step: 300, Average Loss: 4.6774, Average Regression Loss 1.4002, Average Classification Loss: 3.2772
2019-01-14 01:28:17,568 - root - INFO - Epoch: 74, Step: 400, Average Loss: 4.6556, Average Regression Loss 1.3841, Average Classification Loss: 3.2715
2019-01-14 01:28:46,259 - root - INFO - Epoch: 74, Step: 500, Average Loss: 4.7111, Average Regression Loss 1.4216, Average Classification Loss: 3.2895
2019-01-14 01:29:14,938 - root - INFO - Epoch: 74, Step: 600, Average Loss: 4.6620, Average Regression Loss 1.3757, Average Classification Loss: 3.2862
2019-01-14 01:30:10,166 - root - INFO - Epoch: 75, Step: 100, Average Loss: 4.7680, Average Regression Loss 1.4266, Average Classification Loss: 3.3413
2019-01-14 01:30:38,721 - root - INFO - Epoch: 75, Step: 200, Average Loss: 4.6208, Average Regression Loss 1.3612, Average Classification Loss: 3.2596
2019-01-14 01:31:07,298 - root - INFO - Epoch: 75, Step: 300, Average Loss: 4.6129, Average Regression Loss 1.3738, Average Classification Loss: 3.2391
2019-01-14 01:31:35,893 - root - INFO - Epoch: 75, Step: 400, Average Loss: 4.6442, Average Regression Loss 1.3762, Average Classification Loss: 3.2680
2019-01-14 01:32:04,467 - root - INFO - Epoch: 75, Step: 500, Average Loss: 4.6406, Average Regression Loss 1.3852, Average Classification Loss: 3.2553
2019-01-14 01:32:33,077 - root - INFO - Epoch: 75, Step: 600, Average Loss: 4.6892, Average Regression Loss 1.3715, Average Classification Loss: 3.3177
2019-01-14 01:33:17,870 - root - INFO - Epoch: 75, Validation Loss: 4.4771, Validation Regression Loss 1.4124, Validation Classification Loss: 3.0646
2019-01-14 01:33:17,963 - root - INFO - Saved model models/inception-Epoch-75-Loss-4.477071158551939.pth
2019-01-14 01:33:47,491 - root - INFO - Epoch: 76, Step: 100, Average Loss: 4.7362, Average Regression Loss 1.4096, Average Classification Loss: 3.3266
2019-01-14 01:34:15,898 - root - INFO - Epoch: 76, Step: 200, Average Loss: 4.6192, Average Regression Loss 1.3877, Average Classification Loss: 3.2315
2019-01-14 01:34:44,384 - root - INFO - Epoch: 76, Step: 300, Average Loss: 4.6878, Average Regression Loss 1.3960, Average Classification Loss: 3.2917
2019-01-14 01:35:12,851 - root - INFO - Epoch: 76, Step: 400, Average Loss: 4.6167, Average Regression Loss 1.3594, Average Classification Loss: 3.2572
2019-01-14 01:35:41,394 - root - INFO - Epoch: 76, Step: 500, Average Loss: 4.6738, Average Regression Loss 1.4018, Average Classification Loss: 3.2720
2019-01-14 01:36:09,905 - root - INFO - Epoch: 76, Step: 600, Average Loss: 4.6061, Average Regression Loss 1.3411, Average Classification Loss: 3.2650
2019-01-14 01:37:04,685 - root - INFO - Epoch: 77, Step: 100, Average Loss: 4.6681, Average Regression Loss 1.3839, Average Classification Loss: 3.2842
2019-01-14 01:37:33,173 - root - INFO - Epoch: 77, Step: 200, Average Loss: 4.6150, Average Regression Loss 1.3686, Average Classification Loss: 3.2464
2019-01-14 01:38:01,623 - root - INFO - Epoch: 77, Step: 300, Average Loss: 4.6398, Average Regression Loss 1.3840, Average Classification Loss: 3.2558
2019-01-14 01:38:30,174 - root - INFO - Epoch: 77, Step: 400, Average Loss: 4.5993, Average Regression Loss 1.3709, Average Classification Loss: 3.2284
2019-01-14 01:38:58,705 - root - INFO - Epoch: 77, Step: 500, Average Loss: 4.6506, Average Regression Loss 1.3784, Average Classification Loss: 3.2722
2019-01-14 01:39:27,211 - root - INFO - Epoch: 77, Step: 600, Average Loss: 4.6267, Average Regression Loss 1.3806, Average Classification Loss: 3.2461
2019-01-14 01:40:22,118 - root - INFO - Epoch: 78, Step: 100, Average Loss: 4.6556, Average Regression Loss 1.3843, Average Classification Loss: 3.2713
2019-01-14 01:40:50,624 - root - INFO - Epoch: 78, Step: 200, Average Loss: 4.5956, Average Regression Loss 1.3738, Average Classification Loss: 3.2218
2019-01-14 01:41:19,093 - root - INFO - Epoch: 78, Step: 300, Average Loss: 4.5776, Average Regression Loss 1.3544, Average Classification Loss: 3.2232
2019-01-14 01:41:47,575 - root - INFO - Epoch: 78, Step: 400, Average Loss: 4.6287, Average Regression Loss 1.3859, Average Classification Loss: 3.2428
2019-01-14 01:42:16,104 - root - INFO - Epoch: 78, Step: 500, Average Loss: 4.6122, Average Regression Loss 1.3591, Average Classification Loss: 3.2531
2019-01-14 01:42:44,670 - root - INFO - Epoch: 78, Step: 600, Average Loss: 4.6576, Average Regression Loss 1.3819, Average Classification Loss: 3.2756
2019-01-14 01:43:39,804 - root - INFO - Epoch: 79, Step: 100, Average Loss: 4.6105, Average Regression Loss 1.3581, Average Classification Loss: 3.2524
2019-01-14 01:44:08,285 - root - INFO - Epoch: 79, Step: 200, Average Loss: 4.5800, Average Regression Loss 1.3627, Average Classification Loss: 3.2173
2019-01-14 01:44:36,771 - root - INFO - Epoch: 79, Step: 300, Average Loss: 4.6036, Average Regression Loss 1.3462, Average Classification Loss: 3.2574
2019-01-14 01:45:05,262 - root - INFO - Epoch: 79, Step: 400, Average Loss: 4.6232, Average Regression Loss 1.3872, Average Classification Loss: 3.2360
2019-01-14 01:45:33,798 - root - INFO - Epoch: 79, Step: 500, Average Loss: 4.5882, Average Regression Loss 1.3565, Average Classification Loss: 3.2317
2019-01-14 01:46:02,362 - root - INFO - Epoch: 79, Step: 600, Average Loss: 4.5643, Average Regression Loss 1.3397, Average Classification Loss: 3.2246
2019-01-14 01:46:57,313 - root - INFO - Epoch: 80, Step: 100, Average Loss: 4.5890, Average Regression Loss 1.3903, Average Classification Loss: 3.1986
2019-01-14 01:47:25,763 - root - INFO - Epoch: 80, Step: 200, Average Loss: 4.6321, Average Regression Loss 1.3672, Average Classification Loss: 3.2649
2019-01-14 01:47:54,218 - root - INFO - Epoch: 80, Step: 300, Average Loss: 4.6085, Average Regression Loss 1.3702, Average Classification Loss: 3.2383
2019-01-14 01:48:22,731 - root - INFO - Epoch: 80, Step: 400, Average Loss: 4.6093, Average Regression Loss 1.3579, Average Classification Loss: 3.2514
2019-01-14 01:48:51,233 - root - INFO - Epoch: 80, Step: 500, Average Loss: 4.5495, Average Regression Loss 1.3543, Average Classification Loss: 3.1953
2019-01-14 01:49:19,715 - root - INFO - Epoch: 80, Step: 600, Average Loss: 4.6032, Average Regression Loss 1.3631, Average Classification Loss: 3.2401
2019-01-14 01:50:04,317 - root - INFO - Epoch: 80, Validation Loss: 4.3999, Validation Regression Loss 1.3879, Validation Classification Loss: 3.0119
2019-01-14 01:50:04,396 - root - INFO - Saved model models/inception-Epoch-80-Loss-4.399850261384162.pth
2019-01-14 01:50:33,994 - root - INFO - Epoch: 81, Step: 100, Average Loss: 4.5872, Average Regression Loss 1.3727, Average Classification Loss: 3.2145
2019-01-14 01:51:02,416 - root - INFO - Epoch: 81, Step: 200, Average Loss: 4.6401, Average Regression Loss 1.3819, Average Classification Loss: 3.2582
2019-01-14 01:51:30,913 - root - INFO - Epoch: 81, Step: 300, Average Loss: 4.5356, Average Regression Loss 1.3325, Average Classification Loss: 3.2031
2019-01-14 01:51:59,391 - root - INFO - Epoch: 81, Step: 400, Average Loss: 4.5959, Average Regression Loss 1.3641, Average Classification Loss: 3.2318
2019-01-14 01:52:27,869 - root - INFO - Epoch: 81, Step: 500, Average Loss: 4.5728, Average Regression Loss 1.3588, Average Classification Loss: 3.2141
2019-01-14 01:52:56,298 - root - INFO - Epoch: 81, Step: 600, Average Loss: 4.5709, Average Regression Loss 1.3626, Average Classification Loss: 3.2082
2019-01-14 01:53:51,165 - root - INFO - Epoch: 82, Step: 100, Average Loss: 4.6110, Average Regression Loss 1.3730, Average Classification Loss: 3.2380
2019-01-14 01:54:19,605 - root - INFO - Epoch: 82, Step: 200, Average Loss: 4.5148, Average Regression Loss 1.3380, Average Classification Loss: 3.1769
2019-01-14 01:54:48,075 - root - INFO - Epoch: 82, Step: 300, Average Loss: 4.6074, Average Regression Loss 1.3521, Average Classification Loss: 3.2553
2019-01-14 01:55:16,551 - root - INFO - Epoch: 82, Step: 400, Average Loss: 4.6266, Average Regression Loss 1.3828, Average Classification Loss: 3.2438
2019-01-14 01:55:45,014 - root - INFO - Epoch: 82, Step: 500, Average Loss: 4.5454, Average Regression Loss 1.3265, Average Classification Loss: 3.2189
2019-01-14 01:56:13,511 - root - INFO - Epoch: 82, Step: 600, Average Loss: 4.6050, Average Regression Loss 1.3654, Average Classification Loss: 3.2396
2019-01-14 01:57:08,617 - root - INFO - Epoch: 83, Step: 100, Average Loss: 4.5721, Average Regression Loss 1.3509, Average Classification Loss: 3.2212
2019-01-14 01:57:37,214 - root - INFO - Epoch: 83, Step: 200, Average Loss: 4.5292, Average Regression Loss 1.3505, Average Classification Loss: 3.1786
2019-01-14 01:58:05,901 - root - INFO - Epoch: 83, Step: 300, Average Loss: 4.5471, Average Regression Loss 1.3469, Average Classification Loss: 3.2002
2019-01-14 01:58:34,501 - root - INFO - Epoch: 83, Step: 400, Average Loss: 4.5506, Average Regression Loss 1.3594, Average Classification Loss: 3.1912
2019-01-14 01:59:03,106 - root - INFO - Epoch: 83, Step: 500, Average Loss: 4.6088, Average Regression Loss 1.3586, Average Classification Loss: 3.2502
2019-01-14 01:59:31,655 - root - INFO - Epoch: 83, Step: 600, Average Loss: 4.5427, Average Regression Loss 1.3420, Average Classification Loss: 3.2007
2019-01-14 02:00:26,666 - root - INFO - Epoch: 84, Step: 100, Average Loss: 4.5922, Average Regression Loss 1.3581, Average Classification Loss: 3.2341
2019-01-14 02:00:55,178 - root - INFO - Epoch: 84, Step: 200, Average Loss: 4.4861, Average Regression Loss 1.3216, Average Classification Loss: 3.1645
2019-01-14 02:01:23,678 - root - INFO - Epoch: 84, Step: 300, Average Loss: 4.4670, Average Regression Loss 1.3061, Average Classification Loss: 3.1609
2019-01-14 02:01:52,168 - root - INFO - Epoch: 84, Step: 400, Average Loss: 4.5824, Average Regression Loss 1.3671, Average Classification Loss: 3.2154
2019-01-14 02:02:20,624 - root - INFO - Epoch: 84, Step: 500, Average Loss: 4.5012, Average Regression Loss 1.3269, Average Classification Loss: 3.1743
2019-01-14 02:02:49,123 - root - INFO - Epoch: 84, Step: 600, Average Loss: 4.5840, Average Regression Loss 1.3636, Average Classification Loss: 3.2203
2019-01-14 02:03:44,139 - root - INFO - Epoch: 85, Step: 100, Average Loss: 4.6432, Average Regression Loss 1.3954, Average Classification Loss: 3.2478
2019-01-14 02:04:12,619 - root - INFO - Epoch: 85, Step: 200, Average Loss: 4.5109, Average Regression Loss 1.3226, Average Classification Loss: 3.1883
2019-01-14 02:04:41,097 - root - INFO - Epoch: 85, Step: 300, Average Loss: 4.5428, Average Regression Loss 1.3637, Average Classification Loss: 3.1791
2019-01-14 02:05:09,583 - root - INFO - Epoch: 85, Step: 400, Average Loss: 4.4670, Average Regression Loss 1.3293, Average Classification Loss: 3.1377
2019-01-14 02:05:38,089 - root - INFO - Epoch: 85, Step: 500, Average Loss: 4.5008, Average Regression Loss 1.3278, Average Classification Loss: 3.1730
2019-01-14 02:06:06,566 - root - INFO - Epoch: 85, Step: 600, Average Loss: 4.5627, Average Regression Loss 1.3497, Average Classification Loss: 3.2130
2019-01-14 02:06:51,104 - root - INFO - Epoch: 85, Validation Loss: 4.3515, Validation Regression Loss 1.3816, Validation Classification Loss: 2.9699
2019-01-14 02:06:51,225 - root - INFO - Saved model models/inception-Epoch-85-Loss-4.351495453700927.pth
2019-01-14 02:07:20,814 - root - INFO - Epoch: 86, Step: 100, Average Loss: 4.5215, Average Regression Loss 1.3527, Average Classification Loss: 3.1688
2019-01-14 02:07:49,290 - root - INFO - Epoch: 86, Step: 200, Average Loss: 4.5817, Average Regression Loss 1.3695, Average Classification Loss: 3.2121
2019-01-14 02:08:17,776 - root - INFO - Epoch: 86, Step: 300, Average Loss: 4.5115, Average Regression Loss 1.3292, Average Classification Loss: 3.1823
2019-01-14 02:08:46,224 - root - INFO - Epoch: 86, Step: 400, Average Loss: 4.5074, Average Regression Loss 1.3485, Average Classification Loss: 3.1589
2019-01-14 02:09:14,757 - root - INFO - Epoch: 86, Step: 500, Average Loss: 4.5446, Average Regression Loss 1.3539, Average Classification Loss: 3.1906
2019-01-14 02:09:43,265 - root - INFO - Epoch: 86, Step: 600, Average Loss: 4.5842, Average Regression Loss 1.3390, Average Classification Loss: 3.2452
2019-01-14 02:10:38,202 - root - INFO - Epoch: 87, Step: 100, Average Loss: 4.5690, Average Regression Loss 1.3550, Average Classification Loss: 3.2140
2019-01-14 02:11:06,703 - root - INFO - Epoch: 87, Step: 200, Average Loss: 4.5556, Average Regression Loss 1.3554, Average Classification Loss: 3.2002
2019-01-14 02:11:35,231 - root - INFO - Epoch: 87, Step: 300, Average Loss: 4.4798, Average Regression Loss 1.3165, Average Classification Loss: 3.1633
2019-01-14 02:12:03,714 - root - INFO - Epoch: 87, Step: 400, Average Loss: 4.5008, Average Regression Loss 1.3365, Average Classification Loss: 3.1643
2019-01-14 02:12:32,177 - root - INFO - Epoch: 87, Step: 500, Average Loss: 4.5057, Average Regression Loss 1.3290, Average Classification Loss: 3.1767
2019-01-14 02:13:00,682 - root - INFO - Epoch: 87, Step: 600, Average Loss: 4.4524, Average Regression Loss 1.3257, Average Classification Loss: 3.1267
2019-01-14 02:13:55,586 - root - INFO - Epoch: 88, Step: 100, Average Loss: 4.5283, Average Regression Loss 1.3361, Average Classification Loss: 3.1922
2019-01-14 02:14:24,061 - root - INFO - Epoch: 88, Step: 200, Average Loss: 4.4561, Average Regression Loss 1.3259, Average Classification Loss: 3.1303
2019-01-14 02:14:52,573 - root - INFO - Epoch: 88, Step: 300, Average Loss: 4.5054, Average Regression Loss 1.3325, Average Classification Loss: 3.1729
2019-01-14 02:15:21,078 - root - INFO - Epoch: 88, Step: 400, Average Loss: 4.5485, Average Regression Loss 1.3525, Average Classification Loss: 3.1959
2019-01-14 02:15:49,531 - root - INFO - Epoch: 88, Step: 500, Average Loss: 4.4731, Average Regression Loss 1.3158, Average Classification Loss: 3.1572
2019-01-14 02:16:17,981 - root - INFO - Epoch: 88, Step: 600, Average Loss: 4.5436, Average Regression Loss 1.3552, Average Classification Loss: 3.1884
2019-01-14 02:17:12,839 - root - INFO - Epoch: 89, Step: 100, Average Loss: 4.5683, Average Regression Loss 1.3373, Average Classification Loss: 3.2310
2019-01-14 02:17:41,286 - root - INFO - Epoch: 89, Step: 200, Average Loss: 4.4928, Average Regression Loss 1.3369, Average Classification Loss: 3.1559
2019-01-14 02:18:09,764 - root - INFO - Epoch: 89, Step: 300, Average Loss: 4.4727, Average Regression Loss 1.3384, Average Classification Loss: 3.1343
2019-01-14 02:18:38,209 - root - INFO - Epoch: 89, Step: 400, Average Loss: 4.5529, Average Regression Loss 1.3741, Average Classification Loss: 3.1788
2019-01-14 02:19:06,703 - root - INFO - Epoch: 89, Step: 500, Average Loss: 4.4479, Average Regression Loss 1.3120, Average Classification Loss: 3.1359
2019-01-14 02:19:35,181 - root - INFO - Epoch: 89, Step: 600, Average Loss: 4.4283, Average Regression Loss 1.3287, Average Classification Loss: 3.0996
2019-01-14 02:20:30,262 - root - INFO - Epoch: 90, Step: 100, Average Loss: 4.5290, Average Regression Loss 1.3381, Average Classification Loss: 3.1909
2019-01-14 02:20:58,934 - root - INFO - Epoch: 90, Step: 200, Average Loss: 4.4842, Average Regression Loss 1.3351, Average Classification Loss: 3.1491
2019-01-14 02:21:27,642 - root - INFO - Epoch: 90, Step: 300, Average Loss: 4.4455, Average Regression Loss 1.3100, Average Classification Loss: 3.1356
2019-01-14 02:21:56,251 - root - INFO - Epoch: 90, Step: 400, Average Loss: 4.4734, Average Regression Loss 1.3207, Average Classification Loss: 3.1528
2019-01-14 02:22:24,914 - root - INFO - Epoch: 90, Step: 500, Average Loss: 4.4643, Average Regression Loss 1.3292, Average Classification Loss: 3.1351
2019-01-14 02:22:53,628 - root - INFO - Epoch: 90, Step: 600, Average Loss: 4.4736, Average Regression Loss 1.3503, Average Classification Loss: 3.1233
2019-01-14 02:23:38,197 - root - INFO - Epoch: 90, Validation Loss: 4.2587, Validation Regression Loss 1.3447, Validation Classification Loss: 2.9140
2019-01-14 02:23:38,324 - root - INFO - Saved model models/inception-Epoch-90-Loss-4.258717290445227.pth
2019-01-14 02:24:08,056 - root - INFO - Epoch: 91, Step: 100, Average Loss: 4.5191, Average Regression Loss 1.3481, Average Classification Loss: 3.1710
2019-01-14 02:24:36,660 - root - INFO - Epoch: 91, Step: 200, Average Loss: 4.4139, Average Regression Loss 1.3139, Average Classification Loss: 3.1000
2019-01-14 02:25:05,257 - root - INFO - Epoch: 91, Step: 300, Average Loss: 4.4613, Average Regression Loss 1.3125, Average Classification Loss: 3.1489
2019-01-14 02:25:33,843 - root - INFO - Epoch: 91, Step: 400, Average Loss: 4.4587, Average Regression Loss 1.3149, Average Classification Loss: 3.1438
2019-01-14 02:26:02,426 - root - INFO - Epoch: 91, Step: 500, Average Loss: 4.4441, Average Regression Loss 1.2898, Average Classification Loss: 3.1543
2019-01-14 02:26:30,998 - root - INFO - Epoch: 91, Step: 600, Average Loss: 4.4814, Average Regression Loss 1.3274, Average Classification Loss: 3.1540
2019-01-14 02:27:26,084 - root - INFO - Epoch: 92, Step: 100, Average Loss: 4.5655, Average Regression Loss 1.3599, Average Classification Loss: 3.2056
2019-01-14 02:27:54,569 - root - INFO - Epoch: 92, Step: 200, Average Loss: 4.4194, Average Regression Loss 1.2998, Average Classification Loss: 3.1197
2019-01-14 02:28:23,067 - root - INFO - Epoch: 92, Step: 300, Average Loss: 4.4806, Average Regression Loss 1.3444, Average Classification Loss: 3.1362
2019-01-14 02:28:51,597 - root - INFO - Epoch: 92, Step: 400, Average Loss: 4.3645, Average Regression Loss 1.3047, Average Classification Loss: 3.0599
2019-01-14 02:29:20,115 - root - INFO - Epoch: 92, Step: 500, Average Loss: 4.4640, Average Regression Loss 1.3246, Average Classification Loss: 3.1394
2019-01-14 02:29:48,624 - root - INFO - Epoch: 92, Step: 600, Average Loss: 4.4944, Average Regression Loss 1.3438, Average Classification Loss: 3.1506
2019-01-14 02:30:43,614 - root - INFO - Epoch: 93, Step: 100, Average Loss: 4.5322, Average Regression Loss 1.3610, Average Classification Loss: 3.1713
2019-01-14 02:31:12,024 - root - INFO - Epoch: 93, Step: 200, Average Loss: 4.3883, Average Regression Loss 1.3076, Average Classification Loss: 3.0806
2019-01-14 02:31:40,526 - root - INFO - Epoch: 93, Step: 300, Average Loss: 4.3652, Average Regression Loss 1.2902, Average Classification Loss: 3.0750
2019-01-14 02:32:09,065 - root - INFO - Epoch: 93, Step: 400, Average Loss: 4.4743, Average Regression Loss 1.3371, Average Classification Loss: 3.1372
2019-01-14 02:32:37,590 - root - INFO - Epoch: 93, Step: 500, Average Loss: 4.4235, Average Regression Loss 1.3039, Average Classification Loss: 3.1196
2019-01-14 02:33:06,139 - root - INFO - Epoch: 93, Step: 600, Average Loss: 4.4057, Average Regression Loss 1.3068, Average Classification Loss: 3.0989
2019-01-14 02:34:01,162 - root - INFO - Epoch: 94, Step: 100, Average Loss: 4.5164, Average Regression Loss 1.3513, Average Classification Loss: 3.1651
2019-01-14 02:34:29,811 - root - INFO - Epoch: 94, Step: 200, Average Loss: 4.4500, Average Regression Loss 1.3234, Average Classification Loss: 3.1266
2019-01-14 02:34:58,478 - root - INFO - Epoch: 94, Step: 300, Average Loss: 4.4121, Average Regression Loss 1.3165, Average Classification Loss: 3.0956
2019-01-14 02:35:27,147 - root - INFO - Epoch: 94, Step: 400, Average Loss: 4.4151, Average Regression Loss 1.2928, Average Classification Loss: 3.1224
2019-01-14 02:35:55,739 - root - INFO - Epoch: 94, Step: 500, Average Loss: 4.4975, Average Regression Loss 1.3429, Average Classification Loss: 3.1546
2019-01-14 02:36:24,353 - root - INFO - Epoch: 94, Step: 600, Average Loss: 4.3832, Average Regression Loss 1.2793, Average Classification Loss: 3.1039
2019-01-14 02:37:19,499 - root - INFO - Epoch: 95, Step: 100, Average Loss: 4.4412, Average Regression Loss 1.3177, Average Classification Loss: 3.1235
2019-01-14 02:37:48,107 - root - INFO - Epoch: 95, Step: 200, Average Loss: 4.3692, Average Regression Loss 1.2977, Average Classification Loss: 3.0715
2019-01-14 02:38:16,760 - root - INFO - Epoch: 95, Step: 300, Average Loss: 4.3082, Average Regression Loss 1.2638, Average Classification Loss: 3.0444
2019-01-14 02:38:45,415 - root - INFO - Epoch: 95, Step: 400, Average Loss: 4.4378, Average Regression Loss 1.3356, Average Classification Loss: 3.1023
2019-01-14 02:39:14,071 - root - INFO - Epoch: 95, Step: 500, Average Loss: 4.4442, Average Regression Loss 1.3303, Average Classification Loss: 3.1140
2019-01-14 02:39:42,736 - root - INFO - Epoch: 95, Step: 600, Average Loss: 4.4904, Average Regression Loss 1.3304, Average Classification Loss: 3.1600
2019-01-14 02:40:27,654 - root - INFO - Epoch: 95, Validation Loss: 4.2717, Validation Regression Loss 1.3402, Validation Classification Loss: 2.9315
2019-01-14 02:40:27,735 - root - INFO - Saved model models/inception-Epoch-95-Loss-4.271705458129662.pth
2019-01-14 02:40:57,280 - root - INFO - Epoch: 96, Step: 100, Average Loss: 4.4330, Average Regression Loss 1.3043, Average Classification Loss: 3.1287
2019-01-14 02:41:25,742 - root - INFO - Epoch: 96, Step: 200, Average Loss: 4.3908, Average Regression Loss 1.3122, Average Classification Loss: 3.0785
2019-01-14 02:41:54,192 - root - INFO - Epoch: 96, Step: 300, Average Loss: 4.4269, Average Regression Loss 1.3113, Average Classification Loss: 3.1156
2019-01-14 02:42:22,632 - root - INFO - Epoch: 96, Step: 400, Average Loss: 4.3497, Average Regression Loss 1.2766, Average Classification Loss: 3.0731
2019-01-14 02:42:51,141 - root - INFO - Epoch: 96, Step: 500, Average Loss: 4.4540, Average Regression Loss 1.3211, Average Classification Loss: 3.1329
2019-01-14 02:43:19,637 - root - INFO - Epoch: 96, Step: 600, Average Loss: 4.4318, Average Regression Loss 1.3247, Average Classification Loss: 3.1071
2019-01-14 02:44:14,603 - root - INFO - Epoch: 97, Step: 100, Average Loss: 4.4503, Average Regression Loss 1.3358, Average Classification Loss: 3.1145
2019-01-14 02:44:43,063 - root - INFO - Epoch: 97, Step: 200, Average Loss: 4.3554, Average Regression Loss 1.2818, Average Classification Loss: 3.0735
2019-01-14 02:45:11,591 - root - INFO - Epoch: 97, Step: 300, Average Loss: 4.3821, Average Regression Loss 1.2950, Average Classification Loss: 3.0871
2019-01-14 02:45:40,054 - root - INFO - Epoch: 97, Step: 400, Average Loss: 4.3676, Average Regression Loss 1.3055, Average Classification Loss: 3.0621
2019-01-14 02:46:08,513 - root - INFO - Epoch: 97, Step: 500, Average Loss: 4.3627, Average Regression Loss 1.2823, Average Classification Loss: 3.0804
2019-01-14 02:46:37,011 - root - INFO - Epoch: 97, Step: 600, Average Loss: 4.4191, Average Regression Loss 1.3066, Average Classification Loss: 3.1125
2019-01-14 02:47:31,933 - root - INFO - Epoch: 98, Step: 100, Average Loss: 4.4330, Average Regression Loss 1.3329, Average Classification Loss: 3.1001
2019-01-14 02:48:00,347 - root - INFO - Epoch: 98, Step: 200, Average Loss: 4.4160, Average Regression Loss 1.3157, Average Classification Loss: 3.1003
2019-01-14 02:48:28,839 - root - INFO - Epoch: 98, Step: 300, Average Loss: 4.3431, Average Regression Loss 1.2970, Average Classification Loss: 3.0461
2019-01-14 02:48:57,343 - root - INFO - Epoch: 98, Step: 400, Average Loss: 4.4127, Average Regression Loss 1.3034, Average Classification Loss: 3.1093
2019-01-14 02:49:25,841 - root - INFO - Epoch: 98, Step: 500, Average Loss: 4.3649, Average Regression Loss 1.3031, Average Classification Loss: 3.0618
2019-01-14 02:49:54,323 - root - INFO - Epoch: 98, Step: 600, Average Loss: 4.3639, Average Regression Loss 1.2908, Average Classification Loss: 3.0731
2019-01-14 02:50:49,448 - root - INFO - Epoch: 99, Step: 100, Average Loss: 4.4039, Average Regression Loss 1.3081, Average Classification Loss: 3.0958
2019-01-14 02:51:17,912 - root - INFO - Epoch: 99, Step: 200, Average Loss: 4.3232, Average Regression Loss 1.2766, Average Classification Loss: 3.0466
2019-01-14 02:51:46,407 - root - INFO - Epoch: 99, Step: 300, Average Loss: 4.3836, Average Regression Loss 1.3121, Average Classification Loss: 3.0715
2019-01-14 02:52:14,845 - root - INFO - Epoch: 99, Step: 400, Average Loss: 4.3284, Average Regression Loss 1.2850, Average Classification Loss: 3.0434
2019-01-14 02:52:43,369 - root - INFO - Epoch: 99, Step: 500, Average Loss: 4.3738, Average Regression Loss 1.2984, Average Classification Loss: 3.0754
2019-01-14 02:53:11,895 - root - INFO - Epoch: 99, Step: 600, Average Loss: 4.4003, Average Regression Loss 1.2957, Average Classification Loss: 3.1045
2019-01-14 02:54:06,987 - root - INFO - Epoch: 100, Step: 100, Average Loss: 4.3994, Average Regression Loss 1.2951, Average Classification Loss: 3.1043
2019-01-14 02:54:35,549 - root - INFO - Epoch: 100, Step: 200, Average Loss: 4.3102, Average Regression Loss 1.2864, Average Classification Loss: 3.0239
2019-01-14 02:55:04,092 - root - INFO - Epoch: 100, Step: 300, Average Loss: 4.3496, Average Regression Loss 1.3017, Average Classification Loss: 3.0479
2019-01-14 02:55:32,702 - root - INFO - Epoch: 100, Step: 400, Average Loss: 4.4274, Average Regression Loss 1.3033, Average Classification Loss: 3.1241
2019-01-14 02:56:01,290 - root - INFO - Epoch: 100, Step: 500, Average Loss: 4.3644, Average Regression Loss 1.2985, Average Classification Loss: 3.0659
2019-01-14 02:56:29,799 - root - INFO - Epoch: 100, Step: 600, Average Loss: 4.3301, Average Regression Loss 1.2792, Average Classification Loss: 3.0508
2019-01-14 02:57:14,491 - root - INFO - Epoch: 100, Validation Loss: 4.1905, Validation Regression Loss 1.3068, Validation Classification Loss: 2.8837
2019-01-14 02:57:14,575 - root - INFO - Saved model models/inception-Epoch-100-Loss-4.190470589531793.pth
2019-01-14 02:57:44,205 - root - INFO - Epoch: 101, Step: 100, Average Loss: 4.4974, Average Regression Loss 1.3372, Average Classification Loss: 3.1603
2019-01-14 02:58:12,714 - root - INFO - Epoch: 101, Step: 200, Average Loss: 4.3115, Average Regression Loss 1.2871, Average Classification Loss: 3.0245
2019-01-14 02:58:41,209 - root - INFO - Epoch: 101, Step: 300, Average Loss: 4.3071, Average Regression Loss 1.2697, Average Classification Loss: 3.0374
2019-01-14 02:59:09,706 - root - INFO - Epoch: 101, Step: 400, Average Loss: 4.3731, Average Regression Loss 1.2852, Average Classification Loss: 3.0879
2019-01-14 02:59:38,217 - root - INFO - Epoch: 101, Step: 500, Average Loss: 4.3431, Average Regression Loss 1.2619, Average Classification Loss: 3.0812
2019-01-14 03:00:06,693 - root - INFO - Epoch: 101, Step: 600, Average Loss: 4.3976, Average Regression Loss 1.3055, Average Classification Loss: 3.0921
2019-01-14 03:01:01,866 - root - INFO - Epoch: 102, Step: 100, Average Loss: 4.3714, Average Regression Loss 1.2886, Average Classification Loss: 3.0829
2019-01-14 03:01:30,507 - root - INFO - Epoch: 102, Step: 200, Average Loss: 4.3431, Average Regression Loss 1.2811, Average Classification Loss: 3.0619
2019-01-14 03:01:59,036 - root - INFO - Epoch: 102, Step: 300, Average Loss: 4.3427, Average Regression Loss 1.2760, Average Classification Loss: 3.0668
2019-01-14 03:02:27,573 - root - INFO - Epoch: 102, Step: 400, Average Loss: 4.2919, Average Regression Loss 1.2611, Average Classification Loss: 3.0308
2019-01-14 03:02:56,248 - root - INFO - Epoch: 102, Step: 500, Average Loss: 4.3530, Average Regression Loss 1.2841, Average Classification Loss: 3.0689
2019-01-14 03:03:24,890 - root - INFO - Epoch: 102, Step: 600, Average Loss: 4.4064, Average Regression Loss 1.2939, Average Classification Loss: 3.1125
2019-01-14 03:04:20,024 - root - INFO - Epoch: 103, Step: 100, Average Loss: 4.4198, Average Regression Loss 1.3070, Average Classification Loss: 3.1128
2019-01-14 03:04:48,516 - root - INFO - Epoch: 103, Step: 200, Average Loss: 4.3376, Average Regression Loss 1.2930, Average Classification Loss: 3.0446
2019-01-14 03:05:17,010 - root - INFO - Epoch: 103, Step: 300, Average Loss: 4.3076, Average Regression Loss 1.2787, Average Classification Loss: 3.0289
2019-01-14 03:05:45,439 - root - INFO - Epoch: 103, Step: 400, Average Loss: 4.3200, Average Regression Loss 1.2808, Average Classification Loss: 3.0392
2019-01-14 03:06:13,934 - root - INFO - Epoch: 103, Step: 500, Average Loss: 4.3296, Average Regression Loss 1.2879, Average Classification Loss: 3.0417
2019-01-14 03:06:42,453 - root - INFO - Epoch: 103, Step: 600, Average Loss: 4.3105, Average Regression Loss 1.2860, Average Classification Loss: 3.0245
2019-01-14 03:07:37,695 - root - INFO - Epoch: 104, Step: 100, Average Loss: 4.2877, Average Regression Loss 1.2796, Average Classification Loss: 3.0081
2019-01-14 03:08:06,290 - root - INFO - Epoch: 104, Step: 200, Average Loss: 4.2967, Average Regression Loss 1.2748, Average Classification Loss: 3.0219
2019-01-14 03:08:34,912 - root - INFO - Epoch: 104, Step: 300, Average Loss: 4.3045, Average Regression Loss 1.2763, Average Classification Loss: 3.0281
2019-01-14 03:09:03,532 - root - INFO - Epoch: 104, Step: 400, Average Loss: 4.3057, Average Regression Loss 1.2593, Average Classification Loss: 3.0465
2019-01-14 03:09:32,211 - root - INFO - Epoch: 104, Step: 500, Average Loss: 4.3764, Average Regression Loss 1.3032, Average Classification Loss: 3.0732
2019-01-14 03:10:00,789 - root - INFO - Epoch: 104, Step: 600, Average Loss: 4.3832, Average Regression Loss 1.2944, Average Classification Loss: 3.0888
2019-01-14 03:10:55,801 - root - INFO - Epoch: 105, Step: 100, Average Loss: 4.3445, Average Regression Loss 1.2944, Average Classification Loss: 3.0501
2019-01-14 03:11:24,424 - root - INFO - Epoch: 105, Step: 200, Average Loss: 4.3090, Average Regression Loss 1.2801, Average Classification Loss: 3.0289
2019-01-14 03:11:53,019 - root - INFO - Epoch: 105, Step: 300, Average Loss: 4.2684, Average Regression Loss 1.2606, Average Classification Loss: 3.0077
2019-01-14 03:12:21,612 - root - INFO - Epoch: 105, Step: 400, Average Loss: 4.3565, Average Regression Loss 1.3022, Average Classification Loss: 3.0543
2019-01-14 03:12:50,157 - root - INFO - Epoch: 105, Step: 500, Average Loss: 4.3108, Average Regression Loss 1.2681, Average Classification Loss: 3.0427
2019-01-14 03:13:18,719 - root - INFO - Epoch: 105, Step: 600, Average Loss: 4.3062, Average Regression Loss 1.2730, Average Classification Loss: 3.0332
2019-01-14 03:14:03,214 - root - INFO - Epoch: 105, Validation Loss: 4.1175, Validation Regression Loss 1.2954, Validation Classification Loss: 2.8221
2019-01-14 03:14:03,297 - root - INFO - Saved model models/inception-Epoch-105-Loss-4.117542667665344.pth
2019-01-14 03:14:32,809 - root - INFO - Epoch: 106, Step: 100, Average Loss: 4.2858, Average Regression Loss 1.2669, Average Classification Loss: 3.0189
2019-01-14 03:15:01,301 - root - INFO - Epoch: 106, Step: 200, Average Loss: 4.3249, Average Regression Loss 1.3011, Average Classification Loss: 3.0238
2019-01-14 03:15:29,825 - root - INFO - Epoch: 106, Step: 300, Average Loss: 4.2858, Average Regression Loss 1.2701, Average Classification Loss: 3.0157
2019-01-14 03:15:58,244 - root - INFO - Epoch: 106, Step: 400, Average Loss: 4.2369, Average Regression Loss 1.2447, Average Classification Loss: 2.9923
2019-01-14 03:16:26,775 - root - INFO - Epoch: 106, Step: 500, Average Loss: 4.2770, Average Regression Loss 1.2629, Average Classification Loss: 3.0141
2019-01-14 03:16:55,240 - root - INFO - Epoch: 106, Step: 600, Average Loss: 4.3089, Average Regression Loss 1.2877, Average Classification Loss: 3.0211
2019-01-14 03:17:50,255 - root - INFO - Epoch: 107, Step: 100, Average Loss: 4.3427, Average Regression Loss 1.2718, Average Classification Loss: 3.0709
2019-01-14 03:18:18,688 - root - INFO - Epoch: 107, Step: 200, Average Loss: 4.2148, Average Regression Loss 1.2354, Average Classification Loss: 2.9793
2019-01-14 03:18:47,167 - root - INFO - Epoch: 107, Step: 300, Average Loss: 4.2365, Average Regression Loss 1.2499, Average Classification Loss: 2.9867
2019-01-14 03:19:15,704 - root - INFO - Epoch: 107, Step: 400, Average Loss: 4.2459, Average Regression Loss 1.2447, Average Classification Loss: 3.0012
2019-01-14 03:19:44,206 - root - INFO - Epoch: 107, Step: 500, Average Loss: 4.2878, Average Regression Loss 1.2694, Average Classification Loss: 3.0184
2019-01-14 03:20:12,746 - root - INFO - Epoch: 107, Step: 600, Average Loss: 4.3478, Average Regression Loss 1.3081, Average Classification Loss: 3.0396
2019-01-14 03:21:07,801 - root - INFO - Epoch: 108, Step: 100, Average Loss: 4.3913, Average Regression Loss 1.3080, Average Classification Loss: 3.0833
2019-01-14 03:21:36,318 - root - INFO - Epoch: 108, Step: 200, Average Loss: 4.2717, Average Regression Loss 1.2758, Average Classification Loss: 2.9960
2019-01-14 03:22:04,860 - root - INFO - Epoch: 108, Step: 300, Average Loss: 4.2591, Average Regression Loss 1.2482, Average Classification Loss: 3.0109
2019-01-14 03:22:33,388 - root - INFO - Epoch: 108, Step: 400, Average Loss: 4.2354, Average Regression Loss 1.2607, Average Classification Loss: 2.9747
2019-01-14 03:23:01,954 - root - INFO - Epoch: 108, Step: 500, Average Loss: 4.2630, Average Regression Loss 1.2774, Average Classification Loss: 2.9856
2019-01-14 03:23:30,468 - root - INFO - Epoch: 108, Step: 600, Average Loss: 4.3480, Average Regression Loss 1.2780, Average Classification Loss: 3.0700
2019-01-14 03:24:25,633 - root - INFO - Epoch: 109, Step: 100, Average Loss: 4.2806, Average Regression Loss 1.2672, Average Classification Loss: 3.0133
2019-01-14 03:24:54,124 - root - INFO - Epoch: 109, Step: 200, Average Loss: 4.2812, Average Regression Loss 1.2687, Average Classification Loss: 3.0125
2019-01-14 03:25:22,593 - root - INFO - Epoch: 109, Step: 300, Average Loss: 4.2819, Average Regression Loss 1.2863, Average Classification Loss: 2.9956
2019-01-14 03:25:51,056 - root - INFO - Epoch: 109, Step: 400, Average Loss: 4.3496, Average Regression Loss 1.3018, Average Classification Loss: 3.0478
2019-01-14 03:26:19,510 - root - INFO - Epoch: 109, Step: 500, Average Loss: 4.2745, Average Regression Loss 1.2898, Average Classification Loss: 2.9847
2019-01-14 03:26:48,048 - root - INFO - Epoch: 109, Step: 600, Average Loss: 4.2449, Average Regression Loss 1.2584, Average Classification Loss: 2.9865
2019-01-14 03:27:43,147 - root - INFO - Epoch: 110, Step: 100, Average Loss: 4.3099, Average Regression Loss 1.2716, Average Classification Loss: 3.0383
2019-01-14 03:28:11,778 - root - INFO - Epoch: 110, Step: 200, Average Loss: 4.2856, Average Regression Loss 1.2728, Average Classification Loss: 3.0127
2019-01-14 03:28:40,335 - root - INFO - Epoch: 110, Step: 300, Average Loss: 4.2944, Average Regression Loss 1.2802, Average Classification Loss: 3.0142
2019-01-14 03:29:08,950 - root - INFO - Epoch: 110, Step: 400, Average Loss: 4.1775, Average Regression Loss 1.2288, Average Classification Loss: 2.9486
2019-01-14 03:29:37,533 - root - INFO - Epoch: 110, Step: 500, Average Loss: 4.2657, Average Regression Loss 1.2572, Average Classification Loss: 3.0086
2019-01-14 03:30:06,210 - root - INFO - Epoch: 110, Step: 600, Average Loss: 4.2570, Average Regression Loss 1.2663, Average Classification Loss: 2.9907
2019-01-14 03:30:50,893 - root - INFO - Epoch: 110, Validation Loss: 4.1121, Validation Regression Loss 1.2915, Validation Classification Loss: 2.8206
2019-01-14 03:30:51,011 - root - INFO - Saved model models/inception-Epoch-110-Loss-4.112057710039442.pth
2019-01-14 03:31:20,606 - root - INFO - Epoch: 111, Step: 100, Average Loss: 4.3123, Average Regression Loss 1.2967, Average Classification Loss: 3.0156
2019-01-14 03:31:49,090 - root - INFO - Epoch: 111, Step: 200, Average Loss: 4.2509, Average Regression Loss 1.2599, Average Classification Loss: 2.9910
2019-01-14 03:32:17,559 - root - INFO - Epoch: 111, Step: 300, Average Loss: 4.2276, Average Regression Loss 1.2411, Average Classification Loss: 2.9865
2019-01-14 03:32:46,081 - root - INFO - Epoch: 111, Step: 400, Average Loss: 4.2582, Average Regression Loss 1.2465, Average Classification Loss: 3.0118
2019-01-14 03:33:14,609 - root - INFO - Epoch: 111, Step: 500, Average Loss: 4.1880, Average Regression Loss 1.2380, Average Classification Loss: 2.9499
2019-01-14 03:33:43,077 - root - INFO - Epoch: 111, Step: 600, Average Loss: 4.2546, Average Regression Loss 1.2442, Average Classification Loss: 3.0104
2019-01-14 03:34:38,104 - root - INFO - Epoch: 112, Step: 100, Average Loss: 4.3043, Average Regression Loss 1.2781, Average Classification Loss: 3.0261
2019-01-14 03:35:06,616 - root - INFO - Epoch: 112, Step: 200, Average Loss: 4.2218, Average Regression Loss 1.2315, Average Classification Loss: 2.9903
2019-01-14 03:35:35,109 - root - INFO - Epoch: 112, Step: 300, Average Loss: 4.2102, Average Regression Loss 1.2469, Average Classification Loss: 2.9632
2019-01-14 03:36:03,602 - root - INFO - Epoch: 112, Step: 400, Average Loss: 4.2622, Average Regression Loss 1.2609, Average Classification Loss: 3.0013
2019-01-14 03:36:32,110 - root - INFO - Epoch: 112, Step: 500, Average Loss: 4.2371, Average Regression Loss 1.2553, Average Classification Loss: 2.9818
2019-01-14 03:37:00,609 - root - INFO - Epoch: 112, Step: 600, Average Loss: 4.2830, Average Regression Loss 1.2947, Average Classification Loss: 2.9883
2019-01-14 03:37:55,580 - root - INFO - Epoch: 113, Step: 100, Average Loss: 4.2422, Average Regression Loss 1.2393, Average Classification Loss: 3.0029
2019-01-14 03:38:24,061 - root - INFO - Epoch: 113, Step: 200, Average Loss: 4.1908, Average Regression Loss 1.2539, Average Classification Loss: 2.9370
2019-01-14 03:38:52,521 - root - INFO - Epoch: 113, Step: 300, Average Loss: 4.2994, Average Regression Loss 1.2894, Average Classification Loss: 3.0100
2019-01-14 03:39:21,003 - root - INFO - Epoch: 113, Step: 400, Average Loss: 4.2976, Average Regression Loss 1.2786, Average Classification Loss: 3.0190
2019-01-14 03:39:49,449 - root - INFO - Epoch: 113, Step: 500, Average Loss: 4.2386, Average Regression Loss 1.2476, Average Classification Loss: 2.9910
2019-01-14 03:40:17,983 - root - INFO - Epoch: 113, Step: 600, Average Loss: 4.2246, Average Regression Loss 1.2434, Average Classification Loss: 2.9812
2019-01-14 03:41:12,867 - root - INFO - Epoch: 114, Step: 100, Average Loss: 4.2764, Average Regression Loss 1.2878, Average Classification Loss: 2.9886
2019-01-14 03:41:41,340 - root - INFO - Epoch: 114, Step: 200, Average Loss: 4.2042, Average Regression Loss 1.2573, Average Classification Loss: 2.9469
2019-01-14 03:42:09,899 - root - INFO - Epoch: 114, Step: 300, Average Loss: 4.2297, Average Regression Loss 1.2695, Average Classification Loss: 2.9602
2019-01-14 03:42:38,290 - root - INFO - Epoch: 114, Step: 400, Average Loss: 4.1999, Average Regression Loss 1.2282, Average Classification Loss: 2.9717
2019-01-14 03:43:06,799 - root - INFO - Epoch: 114, Step: 500, Average Loss: 4.2198, Average Regression Loss 1.2356, Average Classification Loss: 2.9842
2019-01-14 03:43:35,313 - root - INFO - Epoch: 114, Step: 600, Average Loss: 4.2673, Average Regression Loss 1.2591, Average Classification Loss: 3.0082
2019-01-14 03:44:30,358 - root - INFO - Epoch: 115, Step: 100, Average Loss: 4.2412, Average Regression Loss 1.2590, Average Classification Loss: 2.9822
2019-01-14 03:44:59,022 - root - INFO - Epoch: 115, Step: 200, Average Loss: 4.1651, Average Regression Loss 1.2332, Average Classification Loss: 2.9319
2019-01-14 03:45:27,694 - root - INFO - Epoch: 115, Step: 300, Average Loss: 4.2349, Average Regression Loss 1.2477, Average Classification Loss: 2.9872
2019-01-14 03:45:56,402 - root - INFO - Epoch: 115, Step: 400, Average Loss: 4.2020, Average Regression Loss 1.2168, Average Classification Loss: 2.9852
2019-01-14 03:46:25,062 - root - INFO - Epoch: 115, Step: 500, Average Loss: 4.1861, Average Regression Loss 1.2338, Average Classification Loss: 2.9524
2019-01-14 03:46:53,682 - root - INFO - Epoch: 115, Step: 600, Average Loss: 4.2454, Average Regression Loss 1.2451, Average Classification Loss: 3.0003
2019-01-14 03:47:38,455 - root - INFO - Epoch: 115, Validation Loss: 4.0179, Validation Regression Loss 1.2594, Validation Classification Loss: 2.7585
2019-01-14 03:47:38,533 - root - INFO - Saved model models/inception-Epoch-115-Loss-4.017902543579322.pth
2019-01-14 03:48:08,176 - root - INFO - Epoch: 116, Step: 100, Average Loss: 4.2441, Average Regression Loss 1.2643, Average Classification Loss: 2.9798
2019-01-14 03:48:36,683 - root - INFO - Epoch: 116, Step: 200, Average Loss: 4.2200, Average Regression Loss 1.2470, Average Classification Loss: 2.9731
2019-01-14 03:49:05,179 - root - INFO - Epoch: 116, Step: 300, Average Loss: 4.1781, Average Regression Loss 1.2391, Average Classification Loss: 2.9390
2019-01-14 03:49:33,667 - root - INFO - Epoch: 116, Step: 400, Average Loss: 4.1894, Average Regression Loss 1.2582, Average Classification Loss: 2.9311
2019-01-14 03:50:02,123 - root - INFO - Epoch: 116, Step: 500, Average Loss: 4.1823, Average Regression Loss 1.2448, Average Classification Loss: 2.9375
2019-01-14 03:50:30,648 - root - INFO - Epoch: 116, Step: 600, Average Loss: 4.2236, Average Regression Loss 1.2330, Average Classification Loss: 2.9906
2019-01-14 03:51:25,623 - root - INFO - Epoch: 117, Step: 100, Average Loss: 4.2406, Average Regression Loss 1.2546, Average Classification Loss: 2.9861
2019-01-14 03:51:54,189 - root - INFO - Epoch: 117, Step: 200, Average Loss: 4.1871, Average Regression Loss 1.2311, Average Classification Loss: 2.9560
2019-01-14 03:52:22,735 - root - INFO - Epoch: 117, Step: 300, Average Loss: 4.1734, Average Regression Loss 1.2327, Average Classification Loss: 2.9407
2019-01-14 03:52:51,174 - root - INFO - Epoch: 117, Step: 400, Average Loss: 4.2029, Average Regression Loss 1.2533, Average Classification Loss: 2.9496
2019-01-14 03:53:19,654 - root - INFO - Epoch: 117, Step: 500, Average Loss: 4.1765, Average Regression Loss 1.2214, Average Classification Loss: 2.9551
2019-01-14 03:53:48,163 - root - INFO - Epoch: 117, Step: 600, Average Loss: 4.2141, Average Regression Loss 1.2484, Average Classification Loss: 2.9656
2019-01-14 03:54:43,100 - root - INFO - Epoch: 118, Step: 100, Average Loss: 4.2046, Average Regression Loss 1.2322, Average Classification Loss: 2.9724
2019-01-14 03:55:11,547 - root - INFO - Epoch: 118, Step: 200, Average Loss: 4.1370, Average Regression Loss 1.2182, Average Classification Loss: 2.9188
2019-01-14 03:55:40,024 - root - INFO - Epoch: 118, Step: 300, Average Loss: 4.1840, Average Regression Loss 1.2337, Average Classification Loss: 2.9503
2019-01-14 03:56:08,525 - root - INFO - Epoch: 118, Step: 400, Average Loss: 4.1679, Average Regression Loss 1.2240, Average Classification Loss: 2.9439
2019-01-14 03:56:37,034 - root - INFO - Epoch: 118, Step: 500, Average Loss: 4.1630, Average Regression Loss 1.2260, Average Classification Loss: 2.9370
2019-01-14 03:57:05,596 - root - INFO - Epoch: 118, Step: 600, Average Loss: 4.2271, Average Regression Loss 1.2451, Average Classification Loss: 2.9820
2019-01-14 03:58:00,562 - root - INFO - Epoch: 119, Step: 100, Average Loss: 4.2728, Average Regression Loss 1.2632, Average Classification Loss: 3.0097
2019-01-14 03:58:29,049 - root - INFO - Epoch: 119, Step: 200, Average Loss: 4.2273, Average Regression Loss 1.2465, Average Classification Loss: 2.9809
2019-01-14 03:58:57,561 - root - INFO - Epoch: 119, Step: 300, Average Loss: 4.1260, Average Regression Loss 1.2104, Average Classification Loss: 2.9156
2019-01-14 03:59:26,078 - root - INFO - Epoch: 119, Step: 400, Average Loss: 4.1193, Average Regression Loss 1.2286, Average Classification Loss: 2.8906
2019-01-14 03:59:54,640 - root - INFO - Epoch: 119, Step: 500, Average Loss: 4.2265, Average Regression Loss 1.2574, Average Classification Loss: 2.9691
2019-01-14 04:00:23,149 - root - INFO - Epoch: 119, Step: 600, Average Loss: 4.2149, Average Regression Loss 1.2498, Average Classification Loss: 2.9651
2019-01-14 04:01:18,219 - root - INFO - Epoch: 120, Step: 100, Average Loss: 4.1703, Average Regression Loss 1.2238, Average Classification Loss: 2.9466
2019-01-14 04:01:46,684 - root - INFO - Epoch: 120, Step: 200, Average Loss: 4.0380, Average Regression Loss 1.1867, Average Classification Loss: 2.8514
2019-01-14 04:02:15,233 - root - INFO - Epoch: 120, Step: 300, Average Loss: 4.0551, Average Regression Loss 1.2087, Average Classification Loss: 2.8463
2019-01-14 04:02:43,724 - root - INFO - Epoch: 120, Step: 400, Average Loss: 4.0168, Average Regression Loss 1.1869, Average Classification Loss: 2.8299
2019-01-14 04:03:12,266 - root - INFO - Epoch: 120, Step: 500, Average Loss: 4.0553, Average Regression Loss 1.1963, Average Classification Loss: 2.8590
2019-01-14 04:03:40,805 - root - INFO - Epoch: 120, Step: 600, Average Loss: 4.1075, Average Regression Loss 1.2247, Average Classification Loss: 2.8828
2019-01-14 04:04:25,340 - root - INFO - Epoch: 120, Validation Loss: 3.8751, Validation Regression Loss 1.2145, Validation Classification Loss: 2.6606
2019-01-14 04:04:25,461 - root - INFO - Saved model models/inception-Epoch-120-Loss-3.875058579560063.pth
2019-01-14 04:04:55,048 - root - INFO - Epoch: 121, Step: 100, Average Loss: 4.1123, Average Regression Loss 1.2216, Average Classification Loss: 2.8907
2019-01-14 04:05:23,534 - root - INFO - Epoch: 121, Step: 200, Average Loss: 3.9721, Average Regression Loss 1.1746, Average Classification Loss: 2.7976
2019-01-14 04:05:52,037 - root - INFO - Epoch: 121, Step: 300, Average Loss: 4.0894, Average Regression Loss 1.2297, Average Classification Loss: 2.8597
2019-01-14 04:06:20,513 - root - INFO - Epoch: 121, Step: 400, Average Loss: 4.0300, Average Regression Loss 1.1969, Average Classification Loss: 2.8332
2019-01-14 04:06:49,044 - root - INFO - Epoch: 121, Step: 500, Average Loss: 4.0614, Average Regression Loss 1.1956, Average Classification Loss: 2.8658
2019-01-14 04:07:17,548 - root - INFO - Epoch: 121, Step: 600, Average Loss: 4.0600, Average Regression Loss 1.2024, Average Classification Loss: 2.8576
2019-01-14 04:08:12,690 - root - INFO - Epoch: 122, Step: 100, Average Loss: 4.0928, Average Regression Loss 1.2239, Average Classification Loss: 2.8689
2019-01-14 04:08:41,236 - root - INFO - Epoch: 122, Step: 200, Average Loss: 4.0675, Average Regression Loss 1.2144, Average Classification Loss: 2.8531
2019-01-14 04:09:09,737 - root - INFO - Epoch: 122, Step: 300, Average Loss: 4.0315, Average Regression Loss 1.1956, Average Classification Loss: 2.8359
2019-01-14 04:09:38,382 - root - INFO - Epoch: 122, Step: 400, Average Loss: 4.0121, Average Regression Loss 1.1759, Average Classification Loss: 2.8362
2019-01-14 04:10:06,997 - root - INFO - Epoch: 122, Step: 500, Average Loss: 3.9803, Average Regression Loss 1.1613, Average Classification Loss: 2.8190
2019-01-14 04:10:35,630 - root - INFO - Epoch: 122, Step: 600, Average Loss: 4.0492, Average Regression Loss 1.1992, Average Classification Loss: 2.8500
2019-01-14 04:11:30,832 - root - INFO - Epoch: 123, Step: 100, Average Loss: 4.0487, Average Regression Loss 1.2053, Average Classification Loss: 2.8434
2019-01-14 04:11:59,437 - root - INFO - Epoch: 123, Step: 200, Average Loss: 3.9937, Average Regression Loss 1.1844, Average Classification Loss: 2.8094
2019-01-14 04:12:28,100 - root - INFO - Epoch: 123, Step: 300, Average Loss: 4.0227, Average Regression Loss 1.1791, Average Classification Loss: 2.8436
2019-01-14 04:12:56,704 - root - INFO - Epoch: 123, Step: 400, Average Loss: 4.0237, Average Regression Loss 1.1953, Average Classification Loss: 2.8284
2019-01-14 04:13:25,362 - root - INFO - Epoch: 123, Step: 500, Average Loss: 4.0698, Average Regression Loss 1.2061, Average Classification Loss: 2.8637
2019-01-14 04:13:53,978 - root - INFO - Epoch: 123, Step: 600, Average Loss: 4.0133, Average Regression Loss 1.1782, Average Classification Loss: 2.8351
2019-01-14 04:14:49,049 - root - INFO - Epoch: 124, Step: 100, Average Loss: 4.0106, Average Regression Loss 1.1932, Average Classification Loss: 2.8174
2019-01-14 04:15:17,499 - root - INFO - Epoch: 124, Step: 200, Average Loss: 3.9940, Average Regression Loss 1.1866, Average Classification Loss: 2.8075
2019-01-14 04:15:45,938 - root - INFO - Epoch: 124, Step: 300, Average Loss: 3.9914, Average Regression Loss 1.1648, Average Classification Loss: 2.8266
2019-01-14 04:16:14,347 - root - INFO - Epoch: 124, Step: 400, Average Loss: 4.0897, Average Regression Loss 1.2318, Average Classification Loss: 2.8578
2019-01-14 04:16:42,827 - root - INFO - Epoch: 124, Step: 500, Average Loss: 4.0301, Average Regression Loss 1.1907, Average Classification Loss: 2.8394
2019-01-14 04:17:11,272 - root - INFO - Epoch: 124, Step: 600, Average Loss: 3.9792, Average Regression Loss 1.1752, Average Classification Loss: 2.8041
2019-01-14 04:18:06,358 - root - INFO - Epoch: 125, Step: 100, Average Loss: 4.0549, Average Regression Loss 1.1901, Average Classification Loss: 2.8648
2019-01-14 04:18:34,867 - root - INFO - Epoch: 125, Step: 200, Average Loss: 3.9608, Average Regression Loss 1.1600, Average Classification Loss: 2.8008
2019-01-14 04:19:03,369 - root - INFO - Epoch: 125, Step: 300, Average Loss: 3.9990, Average Regression Loss 1.1942, Average Classification Loss: 2.8048
2019-01-14 04:19:31,782 - root - INFO - Epoch: 125, Step: 400, Average Loss: 4.0057, Average Regression Loss 1.1692, Average Classification Loss: 2.8366
2019-01-14 04:20:00,285 - root - INFO - Epoch: 125, Step: 500, Average Loss: 4.0601, Average Regression Loss 1.2305, Average Classification Loss: 2.8296
2019-01-14 04:20:28,777 - root - INFO - Epoch: 125, Step: 600, Average Loss: 3.9543, Average Regression Loss 1.1536, Average Classification Loss: 2.8008
2019-01-14 04:21:13,378 - root - INFO - Epoch: 125, Validation Loss: 3.8417, Validation Regression Loss 1.2028, Validation Classification Loss: 2.6389
2019-01-14 04:21:13,457 - root - INFO - Saved model models/inception-Epoch-125-Loss-3.8417012104089707.pth
2019-01-14 04:21:43,071 - root - INFO - Epoch: 126, Step: 100, Average Loss: 4.0835, Average Regression Loss 1.2049, Average Classification Loss: 2.8786
2019-01-14 04:22:11,545 - root - INFO - Epoch: 126, Step: 200, Average Loss: 3.9515, Average Regression Loss 1.1683, Average Classification Loss: 2.7832
2019-01-14 04:22:40,012 - root - INFO - Epoch: 126, Step: 300, Average Loss: 4.0133, Average Regression Loss 1.1940, Average Classification Loss: 2.8193
2019-01-14 04:23:08,503 - root - INFO - Epoch: 126, Step: 400, Average Loss: 3.9845, Average Regression Loss 1.1733, Average Classification Loss: 2.8112
2019-01-14 04:23:36,997 - root - INFO - Epoch: 126, Step: 500, Average Loss: 3.9895, Average Regression Loss 1.1688, Average Classification Loss: 2.8207
2019-01-14 04:24:05,530 - root - INFO - Epoch: 126, Step: 600, Average Loss: 4.0291, Average Regression Loss 1.2084, Average Classification Loss: 2.8207
2019-01-14 04:25:00,675 - root - INFO - Epoch: 127, Step: 100, Average Loss: 4.0611, Average Regression Loss 1.2060, Average Classification Loss: 2.8552
2019-01-14 04:25:29,201 - root - INFO - Epoch: 127, Step: 200, Average Loss: 3.9877, Average Regression Loss 1.1858, Average Classification Loss: 2.8019
2019-01-14 04:25:57,830 - root - INFO - Epoch: 127, Step: 300, Average Loss: 3.9652, Average Regression Loss 1.1632, Average Classification Loss: 2.8019
2019-01-14 04:26:26,430 - root - INFO - Epoch: 127, Step: 400, Average Loss: 4.0304, Average Regression Loss 1.1959, Average Classification Loss: 2.8346
2019-01-14 04:26:55,022 - root - INFO - Epoch: 127, Step: 500, Average Loss: 4.0112, Average Regression Loss 1.1747, Average Classification Loss: 2.8365
2019-01-14 04:27:23,658 - root - INFO - Epoch: 127, Step: 600, Average Loss: 3.9942, Average Regression Loss 1.1799, Average Classification Loss: 2.8143
2019-01-14 04:28:18,678 - root - INFO - Epoch: 128, Step: 100, Average Loss: 4.0321, Average Regression Loss 1.2048, Average Classification Loss: 2.8273
2019-01-14 04:28:47,145 - root - INFO - Epoch: 128, Step: 200, Average Loss: 3.9788, Average Regression Loss 1.1753, Average Classification Loss: 2.8035
2019-01-14 04:29:15,655 - root - INFO - Epoch: 128, Step: 300, Average Loss: 4.0282, Average Regression Loss 1.1798, Average Classification Loss: 2.8484
2019-01-14 04:29:44,115 - root - INFO - Epoch: 128, Step: 400, Average Loss: 4.0030, Average Regression Loss 1.1859, Average Classification Loss: 2.8170
2019-01-14 04:30:12,633 - root - INFO - Epoch: 128, Step: 500, Average Loss: 4.0640, Average Regression Loss 1.2066, Average Classification Loss: 2.8574
2019-01-14 04:30:41,158 - root - INFO - Epoch: 128, Step: 600, Average Loss: 4.0240, Average Regression Loss 1.1918, Average Classification Loss: 2.8323
2019-01-14 04:31:35,971 - root - INFO - Epoch: 129, Step: 100, Average Loss: 4.0648, Average Regression Loss 1.2049, Average Classification Loss: 2.8599
2019-01-14 04:32:04,521 - root - INFO - Epoch: 129, Step: 200, Average Loss: 3.9839, Average Regression Loss 1.1659, Average Classification Loss: 2.8180
2019-01-14 04:32:33,058 - root - INFO - Epoch: 129, Step: 300, Average Loss: 4.0209, Average Regression Loss 1.1907, Average Classification Loss: 2.8302
2019-01-14 04:33:01,511 - root - INFO - Epoch: 129, Step: 400, Average Loss: 3.9700, Average Regression Loss 1.1645, Average Classification Loss: 2.8056
2019-01-14 04:33:29,989 - root - INFO - Epoch: 129, Step: 500, Average Loss: 4.0440, Average Regression Loss 1.2121, Average Classification Loss: 2.8320
2019-01-14 04:33:58,482 - root - INFO - Epoch: 129, Step: 600, Average Loss: 4.0281, Average Regression Loss 1.2340, Average Classification Loss: 2.7941
2019-01-14 04:34:53,310 - root - INFO - Epoch: 130, Step: 100, Average Loss: 4.0396, Average Regression Loss 1.1997, Average Classification Loss: 2.8399
2019-01-14 04:35:21,802 - root - INFO - Epoch: 130, Step: 200, Average Loss: 3.9194, Average Regression Loss 1.1543, Average Classification Loss: 2.7651
2019-01-14 04:35:50,311 - root - INFO - Epoch: 130, Step: 300, Average Loss: 3.9595, Average Regression Loss 1.1908, Average Classification Loss: 2.7688
2019-01-14 04:36:18,788 - root - INFO - Epoch: 130, Step: 400, Average Loss: 3.9750, Average Regression Loss 1.1665, Average Classification Loss: 2.8084
2019-01-14 04:36:47,296 - root - INFO - Epoch: 130, Step: 500, Average Loss: 3.9794, Average Regression Loss 1.1639, Average Classification Loss: 2.8155
2019-01-14 04:37:15,839 - root - INFO - Epoch: 130, Step: 600, Average Loss: 4.0002, Average Regression Loss 1.1897, Average Classification Loss: 2.8105
2019-01-14 04:38:00,439 - root - INFO - Epoch: 130, Validation Loss: 3.8281, Validation Regression Loss 1.2009, Validation Classification Loss: 2.6272
2019-01-14 04:38:00,536 - root - INFO - Saved model models/inception-Epoch-130-Loss-3.8280652571415557.pth
2019-01-14 04:38:30,215 - root - INFO - Epoch: 131, Step: 100, Average Loss: 4.0699, Average Regression Loss 1.2219, Average Classification Loss: 2.8479
2019-01-14 04:38:58,711 - root - INFO - Epoch: 131, Step: 200, Average Loss: 3.9247, Average Regression Loss 1.1666, Average Classification Loss: 2.7581
2019-01-14 04:39:27,192 - root - INFO - Epoch: 131, Step: 300, Average Loss: 4.0005, Average Regression Loss 1.1667, Average Classification Loss: 2.8338
2019-01-14 04:39:55,693 - root - INFO - Epoch: 131, Step: 400, Average Loss: 3.9804, Average Regression Loss 1.1682, Average Classification Loss: 2.8121
2019-01-14 04:40:24,214 - root - INFO - Epoch: 131, Step: 500, Average Loss: 3.9962, Average Regression Loss 1.1929, Average Classification Loss: 2.8033
2019-01-14 04:40:52,671 - root - INFO - Epoch: 131, Step: 600, Average Loss: 3.9513, Average Regression Loss 1.1683, Average Classification Loss: 2.7829
2019-01-14 04:41:47,508 - root - INFO - Epoch: 132, Step: 100, Average Loss: 4.0084, Average Regression Loss 1.1892, Average Classification Loss: 2.8192
2019-01-14 04:42:15,984 - root - INFO - Epoch: 132, Step: 200, Average Loss: 3.9728, Average Regression Loss 1.1849, Average Classification Loss: 2.7879
2019-01-14 04:42:44,470 - root - INFO - Epoch: 132, Step: 300, Average Loss: 4.0023, Average Regression Loss 1.1905, Average Classification Loss: 2.8118
2019-01-14 04:43:12,977 - root - INFO - Epoch: 132, Step: 400, Average Loss: 4.0408, Average Regression Loss 1.2162, Average Classification Loss: 2.8246
2019-01-14 04:43:41,523 - root - INFO - Epoch: 132, Step: 500, Average Loss: 3.9933, Average Regression Loss 1.1824, Average Classification Loss: 2.8109
2019-01-14 04:44:10,016 - root - INFO - Epoch: 132, Step: 600, Average Loss: 4.0005, Average Regression Loss 1.1909, Average Classification Loss: 2.8096
2019-01-14 04:45:04,993 - root - INFO - Epoch: 133, Step: 100, Average Loss: 4.0675, Average Regression Loss 1.2028, Average Classification Loss: 2.8647
2019-01-14 04:45:33,500 - root - INFO - Epoch: 133, Step: 200, Average Loss: 4.0161, Average Regression Loss 1.2011, Average Classification Loss: 2.8151
2019-01-14 04:46:01,977 - root - INFO - Epoch: 133, Step: 300, Average Loss: 3.9369, Average Regression Loss 1.1727, Average Classification Loss: 2.7642
2019-01-14 04:46:30,510 - root - INFO - Epoch: 133, Step: 400, Average Loss: 4.0454, Average Regression Loss 1.1912, Average Classification Loss: 2.8542
2019-01-14 04:46:58,985 - root - INFO - Epoch: 133, Step: 500, Average Loss: 3.9666, Average Regression Loss 1.1756, Average Classification Loss: 2.7910
2019-01-14 04:47:27,480 - root - INFO - Epoch: 133, Step: 600, Average Loss: 3.9533, Average Regression Loss 1.1644, Average Classification Loss: 2.7889
2019-01-14 04:48:22,449 - root - INFO - Epoch: 134, Step: 100, Average Loss: 4.0013, Average Regression Loss 1.1812, Average Classification Loss: 2.8202
2019-01-14 04:48:50,960 - root - INFO - Epoch: 134, Step: 200, Average Loss: 3.9827, Average Regression Loss 1.1663, Average Classification Loss: 2.8165
2019-01-14 04:49:19,380 - root - INFO - Epoch: 134, Step: 300, Average Loss: 4.0039, Average Regression Loss 1.1933, Average Classification Loss: 2.8106
2019-01-14 04:49:47,874 - root - INFO - Epoch: 134, Step: 400, Average Loss: 3.9704, Average Regression Loss 1.1716, Average Classification Loss: 2.7989
2019-01-14 04:50:16,395 - root - INFO - Epoch: 134, Step: 500, Average Loss: 3.9911, Average Regression Loss 1.1662, Average Classification Loss: 2.8249
2019-01-14 04:50:44,888 - root - INFO - Epoch: 134, Step: 600, Average Loss: 3.9887, Average Regression Loss 1.1790, Average Classification Loss: 2.8097
2019-01-14 04:51:39,846 - root - INFO - Epoch: 135, Step: 100, Average Loss: 4.0288, Average Regression Loss 1.2114, Average Classification Loss: 2.8173
2019-01-14 04:52:08,368 - root - INFO - Epoch: 135, Step: 200, Average Loss: 3.9556, Average Regression Loss 1.1928, Average Classification Loss: 2.7628
2019-01-14 04:52:36,847 - root - INFO - Epoch: 135, Step: 300, Average Loss: 4.0564, Average Regression Loss 1.2039, Average Classification Loss: 2.8525
2019-01-14 04:53:05,362 - root - INFO - Epoch: 135, Step: 400, Average Loss: 3.9672, Average Regression Loss 1.1706, Average Classification Loss: 2.7966
2019-01-14 04:53:33,895 - root - INFO - Epoch: 135, Step: 500, Average Loss: 3.9982, Average Regression Loss 1.1804, Average Classification Loss: 2.8179
2019-01-14 04:54:02,403 - root - INFO - Epoch: 135, Step: 600, Average Loss: 4.0036, Average Regression Loss 1.1725, Average Classification Loss: 2.8311
2019-01-14 04:54:47,034 - root - INFO - Epoch: 135, Validation Loss: 3.8211, Validation Regression Loss 1.1985, Validation Classification Loss: 2.6226
2019-01-14 04:54:47,126 - root - INFO - Saved model models/inception-Epoch-135-Loss-3.8211161710213926.pth
2019-01-14 04:55:16,728 - root - INFO - Epoch: 136, Step: 100, Average Loss: 4.0276, Average Regression Loss 1.2081, Average Classification Loss: 2.8195
2019-01-14 04:55:45,221 - root - INFO - Epoch: 136, Step: 200, Average Loss: 3.9555, Average Regression Loss 1.1743, Average Classification Loss: 2.7811
2019-01-14 04:56:13,853 - root - INFO - Epoch: 136, Step: 300, Average Loss: 3.9767, Average Regression Loss 1.1562, Average Classification Loss: 2.8205
2019-01-14 04:56:42,370 - root - INFO - Epoch: 136, Step: 400, Average Loss: 3.9152, Average Regression Loss 1.1639, Average Classification Loss: 2.7513
2019-01-14 04:57:10,948 - root - INFO - Epoch: 136, Step: 500, Average Loss: 3.9629, Average Regression Loss 1.1587, Average Classification Loss: 2.8041
2019-01-14 04:57:39,501 - root - INFO - Epoch: 136, Step: 600, Average Loss: 3.9343, Average Regression Loss 1.1691, Average Classification Loss: 2.7653
2019-01-14 04:58:34,520 - root - INFO - Epoch: 137, Step: 100, Average Loss: 4.0872, Average Regression Loss 1.2175, Average Classification Loss: 2.8697
2019-01-14 04:59:03,060 - root - INFO - Epoch: 137, Step: 200, Average Loss: 3.9195, Average Regression Loss 1.1689, Average Classification Loss: 2.7506
2019-01-14 04:59:31,613 - root - INFO - Epoch: 137, Step: 300, Average Loss: 3.9560, Average Regression Loss 1.1705, Average Classification Loss: 2.7855
2019-01-14 05:00:00,339 - root - INFO - Epoch: 137, Step: 400, Average Loss: 3.9157, Average Regression Loss 1.1509, Average Classification Loss: 2.7648
2019-01-14 05:00:28,972 - root - INFO - Epoch: 137, Step: 500, Average Loss: 3.9149, Average Regression Loss 1.1447, Average Classification Loss: 2.7701
2019-01-14 05:00:57,576 - root - INFO - Epoch: 137, Step: 600, Average Loss: 4.0176, Average Regression Loss 1.1886, Average Classification Loss: 2.8290
2019-01-14 05:01:52,665 - root - INFO - Epoch: 138, Step: 100, Average Loss: 4.0541, Average Regression Loss 1.2004, Average Classification Loss: 2.8536
2019-01-14 05:02:21,173 - root - INFO - Epoch: 138, Step: 200, Average Loss: 4.0026, Average Regression Loss 1.1742, Average Classification Loss: 2.8283
2019-01-14 05:02:49,705 - root - INFO - Epoch: 138, Step: 300, Average Loss: 3.9975, Average Regression Loss 1.1871, Average Classification Loss: 2.8104
2019-01-14 05:03:18,176 - root - INFO - Epoch: 138, Step: 400, Average Loss: 3.9553, Average Regression Loss 1.1743, Average Classification Loss: 2.7810
2019-01-14 05:03:46,708 - root - INFO - Epoch: 138, Step: 500, Average Loss: 3.9363, Average Regression Loss 1.1658, Average Classification Loss: 2.7704
2019-01-14 05:04:15,227 - root - INFO - Epoch: 138, Step: 600, Average Loss: 4.0327, Average Regression Loss 1.2048, Average Classification Loss: 2.8279
2019-01-14 05:05:10,231 - root - INFO - Epoch: 139, Step: 100, Average Loss: 4.0280, Average Regression Loss 1.1919, Average Classification Loss: 2.8361
2019-01-14 05:05:38,762 - root - INFO - Epoch: 139, Step: 200, Average Loss: 3.9305, Average Regression Loss 1.1694, Average Classification Loss: 2.7612
2019-01-14 05:06:07,236 - root - INFO - Epoch: 139, Step: 300, Average Loss: 3.9758, Average Regression Loss 1.1959, Average Classification Loss: 2.7799
2019-01-14 05:06:35,751 - root - INFO - Epoch: 139, Step: 400, Average Loss: 3.9529, Average Regression Loss 1.1727, Average Classification Loss: 2.7802
2019-01-14 05:07:04,313 - root - INFO - Epoch: 139, Step: 500, Average Loss: 3.9597, Average Regression Loss 1.1627, Average Classification Loss: 2.7970
2019-01-14 05:07:32,867 - root - INFO - Epoch: 139, Step: 600, Average Loss: 4.0208, Average Regression Loss 1.1854, Average Classification Loss: 2.8354
2019-01-14 05:08:27,831 - root - INFO - Epoch: 140, Step: 100, Average Loss: 3.9619, Average Regression Loss 1.1633, Average Classification Loss: 2.7986
2019-01-14 05:08:56,326 - root - INFO - Epoch: 140, Step: 200, Average Loss: 3.9222, Average Regression Loss 1.1629, Average Classification Loss: 2.7594
2019-01-14 05:09:24,851 - root - INFO - Epoch: 140, Step: 300, Average Loss: 3.9958, Average Regression Loss 1.1875, Average Classification Loss: 2.8083
2019-01-14 05:09:53,345 - root - INFO - Epoch: 140, Step: 400, Average Loss: 3.9905, Average Regression Loss 1.1873, Average Classification Loss: 2.8032
2019-01-14 05:10:21,875 - root - INFO - Epoch: 140, Step: 500, Average Loss: 4.0094, Average Regression Loss 1.1971, Average Classification Loss: 2.8123
2019-01-14 05:10:50,483 - root - INFO - Epoch: 140, Step: 600, Average Loss: 3.8815, Average Regression Loss 1.1511, Average Classification Loss: 2.7304
2019-01-14 05:11:35,115 - root - INFO - Epoch: 140, Validation Loss: 3.8098, Validation Regression Loss 1.1925, Validation Classification Loss: 2.6172
2019-01-14 05:11:35,195 - root - INFO - Saved model models/inception-Epoch-140-Loss-3.8097893039961366.pth
2019-01-14 05:12:04,824 - root - INFO - Epoch: 141, Step: 100, Average Loss: 4.0212, Average Regression Loss 1.1918, Average Classification Loss: 2.8294
2019-01-14 05:12:33,290 - root - INFO - Epoch: 141, Step: 200, Average Loss: 3.9005, Average Regression Loss 1.1646, Average Classification Loss: 2.7359
2019-01-14 05:13:01,791 - root - INFO - Epoch: 141, Step: 300, Average Loss: 3.9750, Average Regression Loss 1.1719, Average Classification Loss: 2.8031
2019-01-14 05:13:30,288 - root - INFO - Epoch: 141, Step: 400, Average Loss: 4.0096, Average Regression Loss 1.1822, Average Classification Loss: 2.8274
2019-01-14 05:13:58,834 - root - INFO - Epoch: 141, Step: 500, Average Loss: 3.9604, Average Regression Loss 1.1557, Average Classification Loss: 2.8047
2019-01-14 05:14:27,401 - root - INFO - Epoch: 141, Step: 600, Average Loss: 4.0020, Average Regression Loss 1.1998, Average Classification Loss: 2.8023
2019-01-14 05:15:22,334 - root - INFO - Epoch: 142, Step: 100, Average Loss: 3.9992, Average Regression Loss 1.2006, Average Classification Loss: 2.7986
2019-01-14 05:15:50,843 - root - INFO - Epoch: 142, Step: 200, Average Loss: 3.9515, Average Regression Loss 1.1677, Average Classification Loss: 2.7839
2019-01-14 05:16:19,396 - root - INFO - Epoch: 142, Step: 300, Average Loss: 3.9956, Average Regression Loss 1.1760, Average Classification Loss: 2.8195
2019-01-14 05:16:47,881 - root - INFO - Epoch: 142, Step: 400, Average Loss: 3.9784, Average Regression Loss 1.1648, Average Classification Loss: 2.8136
2019-01-14 05:17:16,407 - root - INFO - Epoch: 142, Step: 500, Average Loss: 3.9598, Average Regression Loss 1.1721, Average Classification Loss: 2.7877
2019-01-14 05:17:44,866 - root - INFO - Epoch: 142, Step: 600, Average Loss: 3.8890, Average Regression Loss 1.1694, Average Classification Loss: 2.7196
2019-01-14 05:18:39,833 - root - INFO - Epoch: 143, Step: 100, Average Loss: 4.0419, Average Regression Loss 1.1994, Average Classification Loss: 2.8425
2019-01-14 05:19:08,286 - root - INFO - Epoch: 143, Step: 200, Average Loss: 3.9529, Average Regression Loss 1.1805, Average Classification Loss: 2.7724
2019-01-14 05:19:36,805 - root - INFO - Epoch: 143, Step: 300, Average Loss: 3.9397, Average Regression Loss 1.1547, Average Classification Loss: 2.7850
2019-01-14 05:20:05,329 - root - INFO - Epoch: 143, Step: 400, Average Loss: 3.9420, Average Regression Loss 1.1828, Average Classification Loss: 2.7593
2019-01-14 05:20:33,780 - root - INFO - Epoch: 143, Step: 500, Average Loss: 3.9042, Average Regression Loss 1.1442, Average Classification Loss: 2.7600
2019-01-14 05:21:02,299 - root - INFO - Epoch: 143, Step: 600, Average Loss: 4.0098, Average Regression Loss 1.1992, Average Classification Loss: 2.8107
2019-01-14 05:21:57,358 - root - INFO - Epoch: 144, Step: 100, Average Loss: 4.0508, Average Regression Loss 1.1928, Average Classification Loss: 2.8580
2019-01-14 05:22:25,909 - root - INFO - Epoch: 144, Step: 200, Average Loss: 3.9492, Average Regression Loss 1.1777, Average Classification Loss: 2.7716
2019-01-14 05:22:54,522 - root - INFO - Epoch: 144, Step: 300, Average Loss: 3.9484, Average Regression Loss 1.1695, Average Classification Loss: 2.7789
2019-01-14 05:23:23,206 - root - INFO - Epoch: 144, Step: 400, Average Loss: 3.9469, Average Regression Loss 1.1821, Average Classification Loss: 2.7649
2019-01-14 05:23:51,828 - root - INFO - Epoch: 144, Step: 500, Average Loss: 3.9499, Average Regression Loss 1.1563, Average Classification Loss: 2.7937
2019-01-14 05:24:20,432 - root - INFO - Epoch: 144, Step: 600, Average Loss: 3.9967, Average Regression Loss 1.1901, Average Classification Loss: 2.8066
2019-01-14 05:25:15,530 - root - INFO - Epoch: 145, Step: 100, Average Loss: 4.0894, Average Regression Loss 1.2115, Average Classification Loss: 2.8780
2019-01-14 05:25:44,002 - root - INFO - Epoch: 145, Step: 200, Average Loss: 3.8600, Average Regression Loss 1.1361, Average Classification Loss: 2.7239
2019-01-14 05:26:12,525 - root - INFO - Epoch: 145, Step: 300, Average Loss: 3.9396, Average Regression Loss 1.1746, Average Classification Loss: 2.7650
2019-01-14 05:26:41,026 - root - INFO - Epoch: 145, Step: 400, Average Loss: 4.0233, Average Regression Loss 1.1978, Average Classification Loss: 2.8254
2019-01-14 05:27:09,534 - root - INFO - Epoch: 145, Step: 500, Average Loss: 3.9439, Average Regression Loss 1.1693, Average Classification Loss: 2.7747
2019-01-14 05:27:38,063 - root - INFO - Epoch: 145, Step: 600, Average Loss: 3.9167, Average Regression Loss 1.1638, Average Classification Loss: 2.7529
2019-01-14 05:28:22,542 - root - INFO - Epoch: 145, Validation Loss: 3.8089, Validation Regression Loss 1.1934, Validation Classification Loss: 2.6155
2019-01-14 05:28:22,624 - root - INFO - Saved model models/inception-Epoch-145-Loss-3.808917014495186.pth
2019-01-14 05:28:52,208 - root - INFO - Epoch: 146, Step: 100, Average Loss: 4.0099, Average Regression Loss 1.1949, Average Classification Loss: 2.8150
2019-01-14 05:29:20,782 - root - INFO - Epoch: 146, Step: 200, Average Loss: 3.9543, Average Regression Loss 1.1937, Average Classification Loss: 2.7607
2019-01-14 05:29:49,393 - root - INFO - Epoch: 146, Step: 300, Average Loss: 3.9451, Average Regression Loss 1.1692, Average Classification Loss: 2.7759
2019-01-14 05:30:17,989 - root - INFO - Epoch: 146, Step: 400, Average Loss: 3.9975, Average Regression Loss 1.1778, Average Classification Loss: 2.8197
2019-01-14 05:30:46,611 - root - INFO - Epoch: 146, Step: 500, Average Loss: 3.9055, Average Regression Loss 1.1432, Average Classification Loss: 2.7623
2019-01-14 05:31:15,212 - root - INFO - Epoch: 146, Step: 600, Average Loss: 4.0315, Average Regression Loss 1.2073, Average Classification Loss: 2.8242
2019-01-14 05:32:10,373 - root - INFO - Epoch: 147, Step: 100, Average Loss: 3.9901, Average Regression Loss 1.1837, Average Classification Loss: 2.8064
2019-01-14 05:32:38,965 - root - INFO - Epoch: 147, Step: 200, Average Loss: 3.9961, Average Regression Loss 1.1854, Average Classification Loss: 2.8108
2019-01-14 05:33:07,577 - root - INFO - Epoch: 147, Step: 300, Average Loss: 3.9625, Average Regression Loss 1.1685, Average Classification Loss: 2.7940
2019-01-14 05:33:36,157 - root - INFO - Epoch: 147, Step: 400, Average Loss: 3.9698, Average Regression Loss 1.1703, Average Classification Loss: 2.7995
2019-01-14 05:34:04,711 - root - INFO - Epoch: 147, Step: 500, Average Loss: 3.9597, Average Regression Loss 1.1756, Average Classification Loss: 2.7841
2019-01-14 05:34:33,310 - root - INFO - Epoch: 147, Step: 600, Average Loss: 3.9740, Average Regression Loss 1.1930, Average Classification Loss: 2.7810
2019-01-14 05:35:28,551 - root - INFO - Epoch: 148, Step: 100, Average Loss: 4.0039, Average Regression Loss 1.1904, Average Classification Loss: 2.8135
2019-01-14 05:35:57,207 - root - INFO - Epoch: 148, Step: 200, Average Loss: 4.0205, Average Regression Loss 1.1974, Average Classification Loss: 2.8231
2019-01-14 05:36:25,826 - root - INFO - Epoch: 148, Step: 300, Average Loss: 3.9210, Average Regression Loss 1.1719, Average Classification Loss: 2.7490
2019-01-14 05:36:54,411 - root - INFO - Epoch: 148, Step: 400, Average Loss: 3.9779, Average Regression Loss 1.1950, Average Classification Loss: 2.7828
2019-01-14 05:37:22,998 - root - INFO - Epoch: 148, Step: 500, Average Loss: 3.9412, Average Regression Loss 1.1578, Average Classification Loss: 2.7834
2019-01-14 05:37:51,640 - root - INFO - Epoch: 148, Step: 600, Average Loss: 3.8907, Average Regression Loss 1.1592, Average Classification Loss: 2.7315
2019-01-14 05:38:46,755 - root - INFO - Epoch: 149, Step: 100, Average Loss: 3.9510, Average Regression Loss 1.1523, Average Classification Loss: 2.7987
2019-01-14 05:39:15,315 - root - INFO - Epoch: 149, Step: 200, Average Loss: 3.9920, Average Regression Loss 1.2089, Average Classification Loss: 2.7832
2019-01-14 05:39:43,759 - root - INFO - Epoch: 149, Step: 300, Average Loss: 3.9070, Average Regression Loss 1.1652, Average Classification Loss: 2.7418
2019-01-14 05:40:12,268 - root - INFO - Epoch: 149, Step: 400, Average Loss: 3.9368, Average Regression Loss 1.1787, Average Classification Loss: 2.7581
2019-01-14 05:40:40,732 - root - INFO - Epoch: 149, Step: 500, Average Loss: 3.9443, Average Regression Loss 1.1785, Average Classification Loss: 2.7658
2019-01-14 05:41:09,223 - root - INFO - Epoch: 149, Step: 600, Average Loss: 3.9868, Average Regression Loss 1.1714, Average Classification Loss: 2.8154
2019-01-14 05:42:04,129 - root - INFO - Epoch: 150, Step: 100, Average Loss: 4.0115, Average Regression Loss 1.1931, Average Classification Loss: 2.8183
2019-01-14 05:42:32,607 - root - INFO - Epoch: 150, Step: 200, Average Loss: 3.9598, Average Regression Loss 1.1759, Average Classification Loss: 2.7839
2019-01-14 05:43:01,103 - root - INFO - Epoch: 150, Step: 300, Average Loss: 3.8656, Average Regression Loss 1.1352, Average Classification Loss: 2.7304
2019-01-14 05:43:29,591 - root - INFO - Epoch: 150, Step: 400, Average Loss: 3.9782, Average Regression Loss 1.1862, Average Classification Loss: 2.7920
2019-01-14 05:43:58,116 - root - INFO - Epoch: 150, Step: 500, Average Loss: 3.9091, Average Regression Loss 1.1641, Average Classification Loss: 2.7450
2019-01-14 05:44:26,606 - root - INFO - Epoch: 150, Step: 600, Average Loss: 3.9513, Average Regression Loss 1.1756, Average Classification Loss: 2.7757
2019-01-14 05:45:11,188 - root - INFO - Epoch: 150, Validation Loss: 3.8026, Validation Regression Loss 1.1901, Validation Classification Loss: 2.6125
2019-01-14 05:45:11,323 - root - INFO - Saved model models/inception-Epoch-150-Loss-3.8026227939532.pth
2019-01-14 05:45:40,983 - root - INFO - Epoch: 151, Step: 100, Average Loss: 4.0256, Average Regression Loss 1.1991, Average Classification Loss: 2.8265
2019-01-14 05:46:09,454 - root - INFO - Epoch: 151, Step: 200, Average Loss: 3.9212, Average Regression Loss 1.1623, Average Classification Loss: 2.7589
2019-01-14 05:46:37,992 - root - INFO - Epoch: 151, Step: 300, Average Loss: 3.9754, Average Regression Loss 1.1807, Average Classification Loss: 2.7947
2019-01-14 05:47:06,522 - root - INFO - Epoch: 151, Step: 400, Average Loss: 3.9155, Average Regression Loss 1.1597, Average Classification Loss: 2.7557
2019-01-14 05:47:35,000 - root - INFO - Epoch: 151, Step: 500, Average Loss: 3.9022, Average Regression Loss 1.1523, Average Classification Loss: 2.7499
2019-01-14 05:48:03,481 - root - INFO - Epoch: 151, Step: 600, Average Loss: 3.9739, Average Regression Loss 1.1826, Average Classification Loss: 2.7913
2019-01-14 05:48:58,395 - root - INFO - Epoch: 152, Step: 100, Average Loss: 3.9628, Average Regression Loss 1.1701, Average Classification Loss: 2.7927
2019-01-14 05:49:26,940 - root - INFO - Epoch: 152, Step: 200, Average Loss: 3.9843, Average Regression Loss 1.1712, Average Classification Loss: 2.8131
2019-01-14 05:49:55,464 - root - INFO - Epoch: 152, Step: 300, Average Loss: 3.9134, Average Regression Loss 1.1596, Average Classification Loss: 2.7538
2019-01-14 05:50:23,956 - root - INFO - Epoch: 152, Step: 400, Average Loss: 3.9421, Average Regression Loss 1.1726, Average Classification Loss: 2.7695
2019-01-14 05:50:52,483 - root - INFO - Epoch: 152, Step: 500, Average Loss: 4.0085, Average Regression Loss 1.1914, Average Classification Loss: 2.8171
2019-01-14 05:51:20,973 - root - INFO - Epoch: 152, Step: 600, Average Loss: 4.0446, Average Regression Loss 1.1955, Average Classification Loss: 2.8492
2019-01-14 05:52:16,011 - root - INFO - Epoch: 153, Step: 100, Average Loss: 3.9738, Average Regression Loss 1.1906, Average Classification Loss: 2.7832
2019-01-14 05:52:44,508 - root - INFO - Epoch: 153, Step: 200, Average Loss: 3.9216, Average Regression Loss 1.1586, Average Classification Loss: 2.7629
2019-01-14 05:53:12,977 - root - INFO - Epoch: 153, Step: 300, Average Loss: 3.9159, Average Regression Loss 1.1425, Average Classification Loss: 2.7734
2019-01-14 05:53:41,486 - root - INFO - Epoch: 153, Step: 400, Average Loss: 3.9880, Average Regression Loss 1.1916, Average Classification Loss: 2.7964
2019-01-14 05:54:10,080 - root - INFO - Epoch: 153, Step: 500, Average Loss: 3.9728, Average Regression Loss 1.1863, Average Classification Loss: 2.7865
2019-01-14 05:54:38,630 - root - INFO - Epoch: 153, Step: 600, Average Loss: 3.9437, Average Regression Loss 1.1763, Average Classification Loss: 2.7674
2019-01-14 05:55:33,538 - root - INFO - Epoch: 154, Step: 100, Average Loss: 3.9815, Average Regression Loss 1.1790, Average Classification Loss: 2.8025
2019-01-14 05:56:01,953 - root - INFO - Epoch: 154, Step: 200, Average Loss: 3.9300, Average Regression Loss 1.1649, Average Classification Loss: 2.7650
2019-01-14 05:56:30,419 - root - INFO - Epoch: 154, Step: 300, Average Loss: 3.9647, Average Regression Loss 1.1884, Average Classification Loss: 2.7763
2019-01-14 05:56:58,980 - root - INFO - Epoch: 154, Step: 400, Average Loss: 3.9498, Average Regression Loss 1.1816, Average Classification Loss: 2.7682
2019-01-14 05:57:27,491 - root - INFO - Epoch: 154, Step: 500, Average Loss: 3.9753, Average Regression Loss 1.1851, Average Classification Loss: 2.7902
2019-01-14 05:57:55,998 - root - INFO - Epoch: 154, Step: 600, Average Loss: 3.9819, Average Regression Loss 1.1668, Average Classification Loss: 2.8151
2019-01-14 05:58:50,987 - root - INFO - Epoch: 155, Step: 100, Average Loss: 4.0819, Average Regression Loss 1.1992, Average Classification Loss: 2.8828
2019-01-14 05:59:19,491 - root - INFO - Epoch: 155, Step: 200, Average Loss: 3.9358, Average Regression Loss 1.1778, Average Classification Loss: 2.7579
2019-01-14 05:59:48,021 - root - INFO - Epoch: 155, Step: 300, Average Loss: 3.8971, Average Regression Loss 1.1300, Average Classification Loss: 2.7671
2019-01-14 06:00:16,565 - root - INFO - Epoch: 155, Step: 400, Average Loss: 3.9904, Average Regression Loss 1.1718, Average Classification Loss: 2.8186
2019-01-14 06:00:45,097 - root - INFO - Epoch: 155, Step: 500, Average Loss: 3.9819, Average Regression Loss 1.1734, Average Classification Loss: 2.8085
2019-01-14 06:01:13,627 - root - INFO - Epoch: 155, Step: 600, Average Loss: 3.9175, Average Regression Loss 1.1652, Average Classification Loss: 2.7523
2019-01-14 06:01:58,313 - root - INFO - Epoch: 155, Validation Loss: 3.7953, Validation Regression Loss 1.1880, Validation Classification Loss: 2.6074
2019-01-14 06:01:58,387 - root - INFO - Saved model models/inception-Epoch-155-Loss-3.795344947040945.pth
2019-01-14 06:02:27,948 - root - INFO - Epoch: 156, Step: 100, Average Loss: 3.9765, Average Regression Loss 1.1773, Average Classification Loss: 2.7993
2019-01-14 06:02:56,379 - root - INFO - Epoch: 156, Step: 200, Average Loss: 3.8993, Average Regression Loss 1.1443, Average Classification Loss: 2.7550
2019-01-14 06:03:24,819 - root - INFO - Epoch: 156, Step: 300, Average Loss: 3.9797, Average Regression Loss 1.1798, Average Classification Loss: 2.7999
2019-01-14 06:03:53,298 - root - INFO - Epoch: 156, Step: 400, Average Loss: 3.9065, Average Regression Loss 1.1696, Average Classification Loss: 2.7369
2019-01-14 06:04:21,768 - root - INFO - Epoch: 156, Step: 500, Average Loss: 3.9523, Average Regression Loss 1.1502, Average Classification Loss: 2.8021
2019-01-14 06:04:50,290 - root - INFO - Epoch: 156, Step: 600, Average Loss: 3.9777, Average Regression Loss 1.1878, Average Classification Loss: 2.7899
2019-01-14 06:05:45,357 - root - INFO - Epoch: 157, Step: 100, Average Loss: 4.0120, Average Regression Loss 1.1899, Average Classification Loss: 2.8221
2019-01-14 06:06:13,897 - root - INFO - Epoch: 157, Step: 200, Average Loss: 3.9020, Average Regression Loss 1.1378, Average Classification Loss: 2.7642
2019-01-14 06:06:42,542 - root - INFO - Epoch: 157, Step: 300, Average Loss: 4.0005, Average Regression Loss 1.1885, Average Classification Loss: 2.8120
2019-01-14 06:07:11,146 - root - INFO - Epoch: 157, Step: 400, Average Loss: 3.9746, Average Regression Loss 1.1815, Average Classification Loss: 2.7931
2019-01-14 06:07:39,756 - root - INFO - Epoch: 157, Step: 500, Average Loss: 3.8878, Average Regression Loss 1.1357, Average Classification Loss: 2.7521
2019-01-14 06:08:08,392 - root - INFO - Epoch: 157, Step: 600, Average Loss: 3.9703, Average Regression Loss 1.1906, Average Classification Loss: 2.7797
2019-01-14 06:09:03,327 - root - INFO - Epoch: 158, Step: 100, Average Loss: 3.9933, Average Regression Loss 1.1686, Average Classification Loss: 2.8247
2019-01-14 06:09:31,863 - root - INFO - Epoch: 158, Step: 200, Average Loss: 3.9334, Average Regression Loss 1.1675, Average Classification Loss: 2.7660
2019-01-14 06:10:00,290 - root - INFO - Epoch: 158, Step: 300, Average Loss: 3.8939, Average Regression Loss 1.1561, Average Classification Loss: 2.7378
2019-01-14 06:10:28,720 - root - INFO - Epoch: 158, Step: 400, Average Loss: 3.8704, Average Regression Loss 1.1387, Average Classification Loss: 2.7317
2019-01-14 06:10:57,286 - root - INFO - Epoch: 158, Step: 500, Average Loss: 3.9661, Average Regression Loss 1.1709, Average Classification Loss: 2.7952
2019-01-14 06:11:25,848 - root - INFO - Epoch: 158, Step: 600, Average Loss: 3.9850, Average Regression Loss 1.1901, Average Classification Loss: 2.7948
2019-01-14 06:12:20,909 - root - INFO - Epoch: 159, Step: 100, Average Loss: 3.9673, Average Regression Loss 1.1667, Average Classification Loss: 2.8007
2019-01-14 06:12:49,526 - root - INFO - Epoch: 159, Step: 200, Average Loss: 3.9497, Average Regression Loss 1.1678, Average Classification Loss: 2.7819
2019-01-14 06:13:18,175 - root - INFO - Epoch: 159, Step: 300, Average Loss: 3.9402, Average Regression Loss 1.1746, Average Classification Loss: 2.7656
2019-01-14 06:13:46,780 - root - INFO - Epoch: 159, Step: 400, Average Loss: 3.8962, Average Regression Loss 1.1452, Average Classification Loss: 2.7509
2019-01-14 06:14:15,357 - root - INFO - Epoch: 159, Step: 500, Average Loss: 3.9051, Average Regression Loss 1.1624, Average Classification Loss: 2.7428
2019-01-14 06:14:43,962 - root - INFO - Epoch: 159, Step: 600, Average Loss: 3.9672, Average Regression Loss 1.1838, Average Classification Loss: 2.7834
2019-01-14 06:15:38,926 - root - INFO - Epoch: 160, Step: 100, Average Loss: 4.0104, Average Regression Loss 1.1965, Average Classification Loss: 2.8139
2019-01-14 06:16:07,428 - root - INFO - Epoch: 160, Step: 200, Average Loss: 3.8629, Average Regression Loss 1.1363, Average Classification Loss: 2.7266
2019-01-14 06:16:35,928 - root - INFO - Epoch: 160, Step: 300, Average Loss: 3.9196, Average Regression Loss 1.1581, Average Classification Loss: 2.7615
2019-01-14 06:17:04,436 - root - INFO - Epoch: 160, Step: 400, Average Loss: 3.9241, Average Regression Loss 1.1654, Average Classification Loss: 2.7586
2019-01-14 06:17:32,926 - root - INFO - Epoch: 160, Step: 500, Average Loss: 3.9240, Average Regression Loss 1.1614, Average Classification Loss: 2.7626
2019-01-14 06:18:01,471 - root - INFO - Epoch: 160, Step: 600, Average Loss: 3.9590, Average Regression Loss 1.1729, Average Classification Loss: 2.7861
2019-01-14 06:18:46,120 - root - INFO - Epoch: 160, Validation Loss: 3.7813, Validation Regression Loss 1.1841, Validation Classification Loss: 2.5972
2019-01-14 06:18:46,242 - root - INFO - Saved model models/inception-Epoch-160-Loss-3.7812739017505.pth
2019-01-14 06:19:15,758 - root - INFO - Epoch: 161, Step: 100, Average Loss: 3.9771, Average Regression Loss 1.1664, Average Classification Loss: 2.8107
2019-01-14 06:19:44,265 - root - INFO - Epoch: 161, Step: 200, Average Loss: 3.9053, Average Regression Loss 1.1485, Average Classification Loss: 2.7568
2019-01-14 06:20:12,709 - root - INFO - Epoch: 161, Step: 300, Average Loss: 3.8427, Average Regression Loss 1.1253, Average Classification Loss: 2.7175
2019-01-14 06:20:41,154 - root - INFO - Epoch: 161, Step: 400, Average Loss: 3.8910, Average Regression Loss 1.1519, Average Classification Loss: 2.7391
2019-01-14 06:21:09,674 - root - INFO - Epoch: 161, Step: 500, Average Loss: 3.9341, Average Regression Loss 1.1789, Average Classification Loss: 2.7553
2019-01-14 06:21:38,201 - root - INFO - Epoch: 161, Step: 600, Average Loss: 3.9499, Average Regression Loss 1.1911, Average Classification Loss: 2.7588
2019-01-14 06:22:33,455 - root - INFO - Epoch: 162, Step: 100, Average Loss: 3.9740, Average Regression Loss 1.1810, Average Classification Loss: 2.7930
2019-01-14 06:23:02,064 - root - INFO - Epoch: 162, Step: 200, Average Loss: 3.9143, Average Regression Loss 1.1525, Average Classification Loss: 2.7618
2019-01-14 06:23:30,704 - root - INFO - Epoch: 162, Step: 300, Average Loss: 3.9136, Average Regression Loss 1.1760, Average Classification Loss: 2.7376
2019-01-14 06:23:59,278 - root - INFO - Epoch: 162, Step: 400, Average Loss: 3.9485, Average Regression Loss 1.1828, Average Classification Loss: 2.7657
2019-01-14 06:24:27,859 - root - INFO - Epoch: 162, Step: 500, Average Loss: 3.8912, Average Regression Loss 1.1528, Average Classification Loss: 2.7383
2019-01-14 06:24:56,433 - root - INFO - Epoch: 162, Step: 600, Average Loss: 3.9302, Average Regression Loss 1.1524, Average Classification Loss: 2.7777
2019-01-14 06:25:51,547 - root - INFO - Epoch: 163, Step: 100, Average Loss: 3.9477, Average Regression Loss 1.1680, Average Classification Loss: 2.7797
2019-01-14 06:26:20,088 - root - INFO - Epoch: 163, Step: 200, Average Loss: 3.9982, Average Regression Loss 1.1896, Average Classification Loss: 2.8086
2019-01-14 06:26:48,616 - root - INFO - Epoch: 163, Step: 300, Average Loss: 3.9459, Average Regression Loss 1.1758, Average Classification Loss: 2.7701
2019-01-14 06:27:17,085 - root - INFO - Epoch: 163, Step: 400, Average Loss: 3.9769, Average Regression Loss 1.1719, Average Classification Loss: 2.8050
2019-01-14 06:27:45,598 - root - INFO - Epoch: 163, Step: 500, Average Loss: 3.8535, Average Regression Loss 1.1331, Average Classification Loss: 2.7204
2019-01-14 06:28:14,132 - root - INFO - Epoch: 163, Step: 600, Average Loss: 3.8933, Average Regression Loss 1.1553, Average Classification Loss: 2.7380
2019-01-14 06:29:09,174 - root - INFO - Epoch: 164, Step: 100, Average Loss: 3.9431, Average Regression Loss 1.1698, Average Classification Loss: 2.7733
2019-01-14 06:29:37,682 - root - INFO - Epoch: 164, Step: 200, Average Loss: 3.8889, Average Regression Loss 1.1555, Average Classification Loss: 2.7333
2019-01-14 06:30:06,307 - root - INFO - Epoch: 164, Step: 300, Average Loss: 3.9082, Average Regression Loss 1.1583, Average Classification Loss: 2.7498
2019-01-14 06:30:34,964 - root - INFO - Epoch: 164, Step: 400, Average Loss: 3.9224, Average Regression Loss 1.1598, Average Classification Loss: 2.7626
2019-01-14 06:31:03,547 - root - INFO - Epoch: 164, Step: 500, Average Loss: 3.9573, Average Regression Loss 1.1722, Average Classification Loss: 2.7851
2019-01-14 06:31:32,106 - root - INFO - Epoch: 164, Step: 600, Average Loss: 3.9900, Average Regression Loss 1.1940, Average Classification Loss: 2.7960
2019-01-14 06:32:27,222 - root - INFO - Epoch: 165, Step: 100, Average Loss: 3.9905, Average Regression Loss 1.2021, Average Classification Loss: 2.7884
2019-01-14 06:32:55,677 - root - INFO - Epoch: 165, Step: 200, Average Loss: 3.8990, Average Regression Loss 1.1540, Average Classification Loss: 2.7450
2019-01-14 06:33:24,164 - root - INFO - Epoch: 165, Step: 300, Average Loss: 3.9523, Average Regression Loss 1.1858, Average Classification Loss: 2.7665
2019-01-14 06:33:52,616 - root - INFO - Epoch: 165, Step: 400, Average Loss: 3.9207, Average Regression Loss 1.1530, Average Classification Loss: 2.7677
2019-01-14 06:34:21,129 - root - INFO - Epoch: 165, Step: 500, Average Loss: 3.9106, Average Regression Loss 1.1542, Average Classification Loss: 2.7563
2019-01-14 06:34:49,650 - root - INFO - Epoch: 165, Step: 600, Average Loss: 3.9524, Average Regression Loss 1.1686, Average Classification Loss: 2.7838
2019-01-14 06:35:34,214 - root - INFO - Epoch: 165, Validation Loss: 3.7826, Validation Regression Loss 1.1854, Validation Classification Loss: 2.5972
2019-01-14 06:35:34,294 - root - INFO - Saved model models/inception-Epoch-165-Loss-3.7825759033074124.pth
2019-01-14 06:36:03,969 - root - INFO - Epoch: 166, Step: 100, Average Loss: 4.0056, Average Regression Loss 1.1933, Average Classification Loss: 2.8122
2019-01-14 06:36:32,378 - root - INFO - Epoch: 166, Step: 200, Average Loss: 3.8928, Average Regression Loss 1.1543, Average Classification Loss: 2.7385
2019-01-14 06:37:00,842 - root - INFO - Epoch: 166, Step: 300, Average Loss: 3.8550, Average Regression Loss 1.1395, Average Classification Loss: 2.7155
2019-01-14 06:37:29,320 - root - INFO - Epoch: 166, Step: 400, Average Loss: 3.9515, Average Regression Loss 1.1862, Average Classification Loss: 2.7653
2019-01-14 06:37:57,817 - root - INFO - Epoch: 166, Step: 500, Average Loss: 3.9427, Average Regression Loss 1.1865, Average Classification Loss: 2.7562
2019-01-14 06:38:26,306 - root - INFO - Epoch: 166, Step: 600, Average Loss: 3.8973, Average Regression Loss 1.1522, Average Classification Loss: 2.7450
2019-01-14 06:39:21,370 - root - INFO - Epoch: 167, Step: 100, Average Loss: 3.9763, Average Regression Loss 1.1895, Average Classification Loss: 2.7868
2019-01-14 06:39:49,852 - root - INFO - Epoch: 167, Step: 200, Average Loss: 3.8894, Average Regression Loss 1.1630, Average Classification Loss: 2.7264
2019-01-14 06:40:18,349 - root - INFO - Epoch: 167, Step: 300, Average Loss: 3.9033, Average Regression Loss 1.1595, Average Classification Loss: 2.7439
2019-01-14 06:40:46,846 - root - INFO - Epoch: 167, Step: 400, Average Loss: 3.8729, Average Regression Loss 1.1491, Average Classification Loss: 2.7238
2019-01-14 06:41:15,343 - root - INFO - Epoch: 167, Step: 500, Average Loss: 3.9663, Average Regression Loss 1.1765, Average Classification Loss: 2.7898
2019-01-14 06:41:43,850 - root - INFO - Epoch: 167, Step: 600, Average Loss: 3.9744, Average Regression Loss 1.1672, Average Classification Loss: 2.8073
2019-01-14 06:42:38,901 - root - INFO - Epoch: 168, Step: 100, Average Loss: 3.9545, Average Regression Loss 1.1755, Average Classification Loss: 2.7790
2019-01-14 06:43:07,595 - root - INFO - Epoch: 168, Step: 200, Average Loss: 3.8857, Average Regression Loss 1.1470, Average Classification Loss: 2.7387
2019-01-14 06:43:36,299 - root - INFO - Epoch: 168, Step: 300, Average Loss: 3.9314, Average Regression Loss 1.1871, Average Classification Loss: 2.7443
2019-01-14 06:44:04,863 - root - INFO - Epoch: 168, Step: 400, Average Loss: 3.9475, Average Regression Loss 1.1611, Average Classification Loss: 2.7864
2019-01-14 06:44:33,443 - root - INFO - Epoch: 168, Step: 500, Average Loss: 3.9097, Average Regression Loss 1.1668, Average Classification Loss: 2.7429
2019-01-14 06:45:02,066 - root - INFO - Epoch: 168, Step: 600, Average Loss: 3.8869, Average Regression Loss 1.1496, Average Classification Loss: 2.7373
2019-01-14 06:45:57,279 - root - INFO - Epoch: 169, Step: 100, Average Loss: 3.9476, Average Regression Loss 1.1677, Average Classification Loss: 2.7799
2019-01-14 06:46:25,783 - root - INFO - Epoch: 169, Step: 200, Average Loss: 3.9343, Average Regression Loss 1.1617, Average Classification Loss: 2.7727
2019-01-14 06:46:54,251 - root - INFO - Epoch: 169, Step: 300, Average Loss: 3.8707, Average Regression Loss 1.1332, Average Classification Loss: 2.7375
2019-01-14 06:47:22,727 - root - INFO - Epoch: 169, Step: 400, Average Loss: 3.8805, Average Regression Loss 1.1585, Average Classification Loss: 2.7220
2019-01-14 06:47:51,241 - root - INFO - Epoch: 169, Step: 500, Average Loss: 3.9617, Average Regression Loss 1.1734, Average Classification Loss: 2.7883
2019-01-14 06:48:19,778 - root - INFO - Epoch: 169, Step: 600, Average Loss: 3.9408, Average Regression Loss 1.1782, Average Classification Loss: 2.7626
2019-01-14 06:49:14,961 - root - INFO - Epoch: 170, Step: 100, Average Loss: 3.9824, Average Regression Loss 1.1669, Average Classification Loss: 2.8155
2019-01-14 06:49:43,452 - root - INFO - Epoch: 170, Step: 200, Average Loss: 3.9399, Average Regression Loss 1.1708, Average Classification Loss: 2.7690
2019-01-14 06:50:11,924 - root - INFO - Epoch: 170, Step: 300, Average Loss: 3.9023, Average Regression Loss 1.1540, Average Classification Loss: 2.7483
2019-01-14 06:50:40,380 - root - INFO - Epoch: 170, Step: 400, Average Loss: 3.9450, Average Regression Loss 1.1741, Average Classification Loss: 2.7709
2019-01-14 06:51:08,842 - root - INFO - Epoch: 170, Step: 500, Average Loss: 3.9107, Average Regression Loss 1.1578, Average Classification Loss: 2.7529
2019-01-14 06:51:37,398 - root - INFO - Epoch: 170, Step: 600, Average Loss: 3.9006, Average Regression Loss 1.1554, Average Classification Loss: 2.7452
2019-01-14 06:52:22,162 - root - INFO - Epoch: 170, Validation Loss: 3.7736, Validation Regression Loss 1.1817, Validation Classification Loss: 2.5919
2019-01-14 06:52:22,243 - root - INFO - Saved model models/inception-Epoch-170-Loss-3.773555555205414.pth
2019-01-14 06:52:51,796 - root - INFO - Epoch: 171, Step: 100, Average Loss: 3.9489, Average Regression Loss 1.1815, Average Classification Loss: 2.7674
2019-01-14 06:53:20,253 - root - INFO - Epoch: 171, Step: 200, Average Loss: 3.9245, Average Regression Loss 1.1546, Average Classification Loss: 2.7699
2019-01-14 06:53:48,742 - root - INFO - Epoch: 171, Step: 300, Average Loss: 3.8931, Average Regression Loss 1.1570, Average Classification Loss: 2.7361
2019-01-14 06:54:17,266 - root - INFO - Epoch: 171, Step: 400, Average Loss: 3.9535, Average Regression Loss 1.1718, Average Classification Loss: 2.7816
2019-01-14 06:54:45,694 - root - INFO - Epoch: 171, Step: 500, Average Loss: 3.9273, Average Regression Loss 1.1790, Average Classification Loss: 2.7483
2019-01-14 06:55:14,206 - root - INFO - Epoch: 171, Step: 600, Average Loss: 3.9050, Average Regression Loss 1.1656, Average Classification Loss: 2.7394
2019-01-14 06:56:09,126 - root - INFO - Epoch: 172, Step: 100, Average Loss: 3.9882, Average Regression Loss 1.1855, Average Classification Loss: 2.8027
2019-01-14 06:56:37,521 - root - INFO - Epoch: 172, Step: 200, Average Loss: 3.9241, Average Regression Loss 1.1724, Average Classification Loss: 2.7517
2019-01-14 06:57:06,018 - root - INFO - Epoch: 172, Step: 300, Average Loss: 3.9100, Average Regression Loss 1.1537, Average Classification Loss: 2.7563
2019-01-14 06:57:34,473 - root - INFO - Epoch: 172, Step: 400, Average Loss: 3.9160, Average Regression Loss 1.1555, Average Classification Loss: 2.7605
2019-01-14 06:58:02,999 - root - INFO - Epoch: 172, Step: 500, Average Loss: 3.9306, Average Regression Loss 1.1551, Average Classification Loss: 2.7755
2019-01-14 06:58:31,501 - root - INFO - Epoch: 172, Step: 600, Average Loss: 3.8445, Average Regression Loss 1.1467, Average Classification Loss: 2.6978
2019-01-14 06:59:26,491 - root - INFO - Epoch: 173, Step: 100, Average Loss: 3.9552, Average Regression Loss 1.1722, Average Classification Loss: 2.7830
2019-01-14 06:59:54,996 - root - INFO - Epoch: 173, Step: 200, Average Loss: 3.9551, Average Regression Loss 1.1812, Average Classification Loss: 2.7740
2019-01-14 07:00:23,503 - root - INFO - Epoch: 173, Step: 300, Average Loss: 3.9205, Average Regression Loss 1.1576, Average Classification Loss: 2.7629
2019-01-14 07:00:51,994 - root - INFO - Epoch: 173, Step: 400, Average Loss: 3.8890, Average Regression Loss 1.1444, Average Classification Loss: 2.7445
2019-01-14 07:01:20,509 - root - INFO - Epoch: 173, Step: 500, Average Loss: 3.9405, Average Regression Loss 1.1850, Average Classification Loss: 2.7555
2019-01-14 07:01:49,022 - root - INFO - Epoch: 173, Step: 600, Average Loss: 3.8736, Average Regression Loss 1.1509, Average Classification Loss: 2.7227
2019-01-14 07:02:43,846 - root - INFO - Epoch: 174, Step: 100, Average Loss: 4.0172, Average Regression Loss 1.1994, Average Classification Loss: 2.8178
2019-01-14 07:03:12,345 - root - INFO - Epoch: 174, Step: 200, Average Loss: 3.9105, Average Regression Loss 1.1611, Average Classification Loss: 2.7494
2019-01-14 07:03:40,794 - root - INFO - Epoch: 174, Step: 300, Average Loss: 3.8757, Average Regression Loss 1.1541, Average Classification Loss: 2.7216
2019-01-14 07:04:09,268 - root - INFO - Epoch: 174, Step: 400, Average Loss: 3.8946, Average Regression Loss 1.1534, Average Classification Loss: 2.7412
2019-01-14 07:04:37,868 - root - INFO - Epoch: 174, Step: 500, Average Loss: 3.9284, Average Regression Loss 1.1620, Average Classification Loss: 2.7665
2019-01-14 07:05:06,415 - root - INFO - Epoch: 174, Step: 600, Average Loss: 3.9085, Average Regression Loss 1.1610, Average Classification Loss: 2.7475
2019-01-14 07:06:01,399 - root - INFO - Epoch: 175, Step: 100, Average Loss: 3.9150, Average Regression Loss 1.1589, Average Classification Loss: 2.7561
2019-01-14 07:06:29,891 - root - INFO - Epoch: 175, Step: 200, Average Loss: 3.9096, Average Regression Loss 1.1688, Average Classification Loss: 2.7408
2019-01-14 07:06:58,366 - root - INFO - Epoch: 175, Step: 300, Average Loss: 3.9170, Average Regression Loss 1.1819, Average Classification Loss: 2.7351
2019-01-14 07:07:26,931 - root - INFO - Epoch: 175, Step: 400, Average Loss: 3.9308, Average Regression Loss 1.1493, Average Classification Loss: 2.7815
2019-01-14 07:07:55,469 - root - INFO - Epoch: 175, Step: 500, Average Loss: 3.9247, Average Regression Loss 1.1730, Average Classification Loss: 2.7517
2019-01-14 07:08:23,954 - root - INFO - Epoch: 175, Step: 600, Average Loss: 3.9447, Average Regression Loss 1.1726, Average Classification Loss: 2.7721
2019-01-14 07:09:08,760 - root - INFO - Epoch: 175, Validation Loss: 3.7769, Validation Regression Loss 1.1826, Validation Classification Loss: 2.5943
2019-01-14 07:09:08,881 - root - INFO - Saved model models/inception-Epoch-175-Loss-3.776902119318644.pth
2019-01-14 07:09:38,674 - root - INFO - Epoch: 176, Step: 100, Average Loss: 4.0014, Average Regression Loss 1.2007, Average Classification Loss: 2.8007
2019-01-14 07:10:07,145 - root - INFO - Epoch: 176, Step: 200, Average Loss: 3.9504, Average Regression Loss 1.1681, Average Classification Loss: 2.7823
2019-01-14 07:10:35,595 - root - INFO - Epoch: 176, Step: 300, Average Loss: 3.9000, Average Regression Loss 1.1468, Average Classification Loss: 2.7532
2019-01-14 07:11:04,104 - root - INFO - Epoch: 176, Step: 400, Average Loss: 3.9366, Average Regression Loss 1.1666, Average Classification Loss: 2.7700
2019-01-14 07:11:32,610 - root - INFO - Epoch: 176, Step: 500, Average Loss: 3.9262, Average Regression Loss 1.1757, Average Classification Loss: 2.7505
2019-01-14 07:12:01,066 - root - INFO - Epoch: 176, Step: 600, Average Loss: 3.8513, Average Regression Loss 1.1255, Average Classification Loss: 2.7258
2019-01-14 07:12:56,093 - root - INFO - Epoch: 177, Step: 100, Average Loss: 3.9188, Average Regression Loss 1.1590, Average Classification Loss: 2.7598
2019-01-14 07:13:24,672 - root - INFO - Epoch: 177, Step: 200, Average Loss: 3.9276, Average Regression Loss 1.1691, Average Classification Loss: 2.7585
2019-01-14 07:13:53,210 - root - INFO - Epoch: 177, Step: 300, Average Loss: 3.8747, Average Regression Loss 1.1506, Average Classification Loss: 2.7240
2019-01-14 07:14:21,799 - root - INFO - Epoch: 177, Step: 400, Average Loss: 3.8976, Average Regression Loss 1.1465, Average Classification Loss: 2.7511
2019-01-14 07:14:50,466 - root - INFO - Epoch: 177, Step: 500, Average Loss: 3.9382, Average Regression Loss 1.1848, Average Classification Loss: 2.7534
2019-01-14 07:15:19,087 - root - INFO - Epoch: 177, Step: 600, Average Loss: 3.9099, Average Regression Loss 1.1686, Average Classification Loss: 2.7413
2019-01-14 07:16:14,327 - root - INFO - Epoch: 178, Step: 100, Average Loss: 3.9533, Average Regression Loss 1.1736, Average Classification Loss: 2.7796
2019-01-14 07:16:42,992 - root - INFO - Epoch: 178, Step: 200, Average Loss: 3.9878, Average Regression Loss 1.1836, Average Classification Loss: 2.8043
2019-01-14 07:17:11,623 - root - INFO - Epoch: 178, Step: 300, Average Loss: 3.9314, Average Regression Loss 1.1773, Average Classification Loss: 2.7541
2019-01-14 07:17:40,158 - root - INFO - Epoch: 178, Step: 400, Average Loss: 3.9326, Average Regression Loss 1.1675, Average Classification Loss: 2.7651
2019-01-14 07:18:08,764 - root - INFO - Epoch: 178, Step: 500, Average Loss: 3.9383, Average Regression Loss 1.1651, Average Classification Loss: 2.7732
2019-01-14 07:18:37,393 - root - INFO - Epoch: 178, Step: 600, Average Loss: 3.9212, Average Regression Loss 1.1707, Average Classification Loss: 2.7505
2019-01-14 07:19:32,591 - root - INFO - Epoch: 179, Step: 100, Average Loss: 3.8947, Average Regression Loss 1.1387, Average Classification Loss: 2.7560
2019-01-14 07:20:01,229 - root - INFO - Epoch: 179, Step: 200, Average Loss: 3.9367, Average Regression Loss 1.1556, Average Classification Loss: 2.7811
2019-01-14 07:20:29,753 - root - INFO - Epoch: 179, Step: 300, Average Loss: 3.9079, Average Regression Loss 1.1597, Average Classification Loss: 2.7482
2019-01-14 07:20:58,394 - root - INFO - Epoch: 179, Step: 400, Average Loss: 3.8990, Average Regression Loss 1.1539, Average Classification Loss: 2.7450
2019-01-14 07:21:27,000 - root - INFO - Epoch: 179, Step: 500, Average Loss: 3.9818, Average Regression Loss 1.1828, Average Classification Loss: 2.7990
2019-01-14 07:21:55,623 - root - INFO - Epoch: 179, Step: 600, Average Loss: 3.8737, Average Regression Loss 1.1490, Average Classification Loss: 2.7247
2019-01-14 07:22:50,862 - root - INFO - Epoch: 180, Step: 100, Average Loss: 4.0271, Average Regression Loss 1.1921, Average Classification Loss: 2.8350
2019-01-14 07:23:19,335 - root - INFO - Epoch: 180, Step: 200, Average Loss: 3.8804, Average Regression Loss 1.1649, Average Classification Loss: 2.7155
2019-01-14 07:23:47,827 - root - INFO - Epoch: 180, Step: 300, Average Loss: 3.9536, Average Regression Loss 1.1585, Average Classification Loss: 2.7950
2019-01-14 07:24:16,317 - root - INFO - Epoch: 180, Step: 400, Average Loss: 3.8998, Average Regression Loss 1.1735, Average Classification Loss: 2.7263
2019-01-14 07:24:44,816 - root - INFO - Epoch: 180, Step: 500, Average Loss: 3.8538, Average Regression Loss 1.1285, Average Classification Loss: 2.7253
2019-01-14 07:25:13,331 - root - INFO - Epoch: 180, Step: 600, Average Loss: 3.8944, Average Regression Loss 1.1640, Average Classification Loss: 2.7304
2019-01-14 07:25:58,074 - root - INFO - Epoch: 180, Validation Loss: 3.7757, Validation Regression Loss 1.1828, Validation Classification Loss: 2.5929
2019-01-14 07:25:58,152 - root - INFO - Saved model models/inception-Epoch-180-Loss-3.7757040590479756.pth
2019-01-14 07:26:27,840 - root - INFO - Epoch: 181, Step: 100, Average Loss: 3.9621, Average Regression Loss 1.1717, Average Classification Loss: 2.7904
2019-01-14 07:26:56,384 - root - INFO - Epoch: 181, Step: 200, Average Loss: 3.8786, Average Regression Loss 1.1405, Average Classification Loss: 2.7381
2019-01-14 07:27:24,852 - root - INFO - Epoch: 181, Step: 300, Average Loss: 3.9480, Average Regression Loss 1.1839, Average Classification Loss: 2.7641
2019-01-14 07:27:53,343 - root - INFO - Epoch: 181, Step: 400, Average Loss: 3.9193, Average Regression Loss 1.1746, Average Classification Loss: 2.7446
2019-01-14 07:28:21,834 - root - INFO - Epoch: 181, Step: 500, Average Loss: 3.9446, Average Regression Loss 1.1782, Average Classification Loss: 2.7665
2019-01-14 07:28:50,359 - root - INFO - Epoch: 181, Step: 600, Average Loss: 3.9225, Average Regression Loss 1.1642, Average Classification Loss: 2.7584
2019-01-14 07:29:45,261 - root - INFO - Epoch: 182, Step: 100, Average Loss: 3.9818, Average Regression Loss 1.1789, Average Classification Loss: 2.8029
2019-01-14 07:30:13,762 - root - INFO - Epoch: 182, Step: 200, Average Loss: 3.9155, Average Regression Loss 1.1581, Average Classification Loss: 2.7575
2019-01-14 07:30:42,284 - root - INFO - Epoch: 182, Step: 300, Average Loss: 3.9329, Average Regression Loss 1.1740, Average Classification Loss: 2.7589
2019-01-14 07:31:10,789 - root - INFO - Epoch: 182, Step: 400, Average Loss: 3.9441, Average Regression Loss 1.1791, Average Classification Loss: 2.7650
2019-01-14 07:31:39,285 - root - INFO - Epoch: 182, Step: 500, Average Loss: 3.8752, Average Regression Loss 1.1588, Average Classification Loss: 2.7164
2019-01-14 07:32:07,784 - root - INFO - Epoch: 182, Step: 600, Average Loss: 3.8962, Average Regression Loss 1.1429, Average Classification Loss: 2.7533
2019-01-14 07:33:02,926 - root - INFO - Epoch: 183, Step: 100, Average Loss: 4.0781, Average Regression Loss 1.2116, Average Classification Loss: 2.8665
2019-01-14 07:33:31,412 - root - INFO - Epoch: 183, Step: 200, Average Loss: 3.8359, Average Regression Loss 1.1395, Average Classification Loss: 2.6964
2019-01-14 07:33:59,906 - root - INFO - Epoch: 183, Step: 300, Average Loss: 3.9842, Average Regression Loss 1.1868, Average Classification Loss: 2.7974
2019-01-14 07:34:28,423 - root - INFO - Epoch: 183, Step: 400, Average Loss: 3.9006, Average Regression Loss 1.1553, Average Classification Loss: 2.7453
2019-01-14 07:34:56,941 - root - INFO - Epoch: 183, Step: 500, Average Loss: 3.9491, Average Regression Loss 1.1605, Average Classification Loss: 2.7885
2019-01-14 07:35:25,477 - root - INFO - Epoch: 183, Step: 600, Average Loss: 3.8802, Average Regression Loss 1.1385, Average Classification Loss: 2.7418
2019-01-14 07:36:20,534 - root - INFO - Epoch: 184, Step: 100, Average Loss: 3.9338, Average Regression Loss 1.1681, Average Classification Loss: 2.7657
2019-01-14 07:36:48,985 - root - INFO - Epoch: 184, Step: 200, Average Loss: 3.9059, Average Regression Loss 1.1461, Average Classification Loss: 2.7598
2019-01-14 07:37:17,481 - root - INFO - Epoch: 184, Step: 300, Average Loss: 3.9434, Average Regression Loss 1.1820, Average Classification Loss: 2.7614
2019-01-14 07:37:45,946 - root - INFO - Epoch: 184, Step: 400, Average Loss: 3.9709, Average Regression Loss 1.1938, Average Classification Loss: 2.7771
2019-01-14 07:38:14,403 - root - INFO - Epoch: 184, Step: 500, Average Loss: 3.9562, Average Regression Loss 1.1782, Average Classification Loss: 2.7780
2019-01-14 07:38:42,850 - root - INFO - Epoch: 184, Step: 600, Average Loss: 3.8945, Average Regression Loss 1.1662, Average Classification Loss: 2.7282
2019-01-14 07:39:37,829 - root - INFO - Epoch: 185, Step: 100, Average Loss: 4.0201, Average Regression Loss 1.2087, Average Classification Loss: 2.8114
2019-01-14 07:40:06,330 - root - INFO - Epoch: 185, Step: 200, Average Loss: 3.8342, Average Regression Loss 1.1378, Average Classification Loss: 2.6964
2019-01-14 07:40:34,919 - root - INFO - Epoch: 185, Step: 300, Average Loss: 3.9460, Average Regression Loss 1.1658, Average Classification Loss: 2.7802
2019-01-14 07:41:03,446 - root - INFO - Epoch: 185, Step: 400, Average Loss: 3.9550, Average Regression Loss 1.1694, Average Classification Loss: 2.7857
2019-01-14 07:41:31,957 - root - INFO - Epoch: 185, Step: 500, Average Loss: 3.8906, Average Regression Loss 1.1436, Average Classification Loss: 2.7470
2019-01-14 07:42:00,482 - root - INFO - Epoch: 185, Step: 600, Average Loss: 3.8819, Average Regression Loss 1.1448, Average Classification Loss: 2.7371
2019-01-14 07:42:45,190 - root - INFO - Epoch: 185, Validation Loss: 3.7753, Validation Regression Loss 1.1816, Validation Classification Loss: 2.5936
2019-01-14 07:42:45,285 - root - INFO - Saved model models/inception-Epoch-185-Loss-3.7752739991542796.pth
2019-01-14 07:43:14,887 - root - INFO - Epoch: 186, Step: 100, Average Loss: 3.9635, Average Regression Loss 1.1668, Average Classification Loss: 2.7967
2019-01-14 07:43:43,429 - root - INFO - Epoch: 186, Step: 200, Average Loss: 3.9041, Average Regression Loss 1.1784, Average Classification Loss: 2.7257
2019-01-14 07:44:11,970 - root - INFO - Epoch: 186, Step: 300, Average Loss: 3.8980, Average Regression Loss 1.1596, Average Classification Loss: 2.7384
2019-01-14 07:44:40,484 - root - INFO - Epoch: 186, Step: 400, Average Loss: 3.9462, Average Regression Loss 1.1789, Average Classification Loss: 2.7673
2019-01-14 07:45:09,056 - root - INFO - Epoch: 186, Step: 500, Average Loss: 3.9268, Average Regression Loss 1.1753, Average Classification Loss: 2.7515
2019-01-14 07:45:37,603 - root - INFO - Epoch: 186, Step: 600, Average Loss: 3.8952, Average Regression Loss 1.1526, Average Classification Loss: 2.7426
2019-01-14 07:46:32,609 - root - INFO - Epoch: 187, Step: 100, Average Loss: 3.9290, Average Regression Loss 1.1539, Average Classification Loss: 2.7751
2019-01-14 07:47:01,112 - root - INFO - Epoch: 187, Step: 200, Average Loss: 3.8460, Average Regression Loss 1.1353, Average Classification Loss: 2.7107
2019-01-14 07:47:29,626 - root - INFO - Epoch: 187, Step: 300, Average Loss: 3.8790, Average Regression Loss 1.1446, Average Classification Loss: 2.7344
2019-01-14 07:47:58,160 - root - INFO - Epoch: 187, Step: 400, Average Loss: 3.9555, Average Regression Loss 1.1723, Average Classification Loss: 2.7832
2019-01-14 07:48:26,661 - root - INFO - Epoch: 187, Step: 500, Average Loss: 3.9290, Average Regression Loss 1.1583, Average Classification Loss: 2.7707
2019-01-14 07:48:55,152 - root - INFO - Epoch: 187, Step: 600, Average Loss: 3.9063, Average Regression Loss 1.1556, Average Classification Loss: 2.7507
2019-01-14 07:49:50,333 - root - INFO - Epoch: 188, Step: 100, Average Loss: 4.0412, Average Regression Loss 1.2079, Average Classification Loss: 2.8333
2019-01-14 07:50:18,968 - root - INFO - Epoch: 188, Step: 200, Average Loss: 3.8788, Average Regression Loss 1.1541, Average Classification Loss: 2.7247
2019-01-14 07:50:47,552 - root - INFO - Epoch: 188, Step: 300, Average Loss: 3.9918, Average Regression Loss 1.1886, Average Classification Loss: 2.8032
2019-01-14 07:51:16,250 - root - INFO - Epoch: 188, Step: 400, Average Loss: 3.9172, Average Regression Loss 1.1482, Average Classification Loss: 2.7689
2019-01-14 07:51:44,959 - root - INFO - Epoch: 188, Step: 500, Average Loss: 3.9054, Average Regression Loss 1.1615, Average Classification Loss: 2.7439
2019-01-14 07:52:13,657 - root - INFO - Epoch: 188, Step: 600, Average Loss: 4.0279, Average Regression Loss 1.1945, Average Classification Loss: 2.8335
2019-01-14 07:53:08,947 - root - INFO - Epoch: 189, Step: 100, Average Loss: 3.9949, Average Regression Loss 1.1866, Average Classification Loss: 2.8083
2019-01-14 07:53:37,620 - root - INFO - Epoch: 189, Step: 200, Average Loss: 3.8205, Average Regression Loss 1.1209, Average Classification Loss: 2.6996
2019-01-14 07:54:06,352 - root - INFO - Epoch: 189, Step: 300, Average Loss: 3.9116, Average Regression Loss 1.1469, Average Classification Loss: 2.7646
2019-01-14 07:54:35,026 - root - INFO - Epoch: 189, Step: 400, Average Loss: 3.8952, Average Regression Loss 1.1293, Average Classification Loss: 2.7658
2019-01-14 07:55:03,664 - root - INFO - Epoch: 189, Step: 500, Average Loss: 3.9123, Average Regression Loss 1.1699, Average Classification Loss: 2.7425
2019-01-14 07:55:32,309 - root - INFO - Epoch: 189, Step: 600, Average Loss: 3.9329, Average Regression Loss 1.1710, Average Classification Loss: 2.7618
2019-01-14 07:56:27,471 - root - INFO - Epoch: 190, Step: 100, Average Loss: 3.9629, Average Regression Loss 1.1837, Average Classification Loss: 2.7792
2019-01-14 07:56:55,994 - root - INFO - Epoch: 190, Step: 200, Average Loss: 3.9215, Average Regression Loss 1.1540, Average Classification Loss: 2.7675
2019-01-14 07:57:24,510 - root - INFO - Epoch: 190, Step: 300, Average Loss: 3.8845, Average Regression Loss 1.1650, Average Classification Loss: 2.7195
2019-01-14 07:57:53,055 - root - INFO - Epoch: 190, Step: 400, Average Loss: 3.9124, Average Regression Loss 1.1701, Average Classification Loss: 2.7423
2019-01-14 07:58:21,580 - root - INFO - Epoch: 190, Step: 500, Average Loss: 3.9229, Average Regression Loss 1.1613, Average Classification Loss: 2.7616
2019-01-14 07:58:50,107 - root - INFO - Epoch: 190, Step: 600, Average Loss: 3.9403, Average Regression Loss 1.1886, Average Classification Loss: 2.7517
2019-01-14 07:59:34,793 - root - INFO - Epoch: 190, Validation Loss: 3.7731, Validation Regression Loss 1.1817, Validation Classification Loss: 2.5914
2019-01-14 07:59:34,888 - root - INFO - Saved model models/inception-Epoch-190-Loss-3.7731317034090197.pth
2019-01-14 08:00:04,576 - root - INFO - Epoch: 191, Step: 100, Average Loss: 3.9445, Average Regression Loss 1.1810, Average Classification Loss: 2.7635
2019-01-14 08:00:33,104 - root - INFO - Epoch: 191, Step: 200, Average Loss: 3.9184, Average Regression Loss 1.1513, Average Classification Loss: 2.7670
2019-01-14 08:01:01,545 - root - INFO - Epoch: 191, Step: 300, Average Loss: 3.9226, Average Regression Loss 1.1511, Average Classification Loss: 2.7715
2019-01-14 08:01:30,071 - root - INFO - Epoch: 191, Step: 400, Average Loss: 3.9524, Average Regression Loss 1.1797, Average Classification Loss: 2.7727
2019-01-14 08:01:58,613 - root - INFO - Epoch: 191, Step: 500, Average Loss: 3.9296, Average Regression Loss 1.1781, Average Classification Loss: 2.7514
2019-01-14 08:02:27,150 - root - INFO - Epoch: 191, Step: 600, Average Loss: 3.9114, Average Regression Loss 1.1658, Average Classification Loss: 2.7455
2019-01-14 08:03:22,226 - root - INFO - Epoch: 192, Step: 100, Average Loss: 3.9733, Average Regression Loss 1.1618, Average Classification Loss: 2.8116
2019-01-14 08:03:50,860 - root - INFO - Epoch: 192, Step: 200, Average Loss: 3.8888, Average Regression Loss 1.1474, Average Classification Loss: 2.7414
2019-01-14 08:04:19,507 - root - INFO - Epoch: 192, Step: 300, Average Loss: 3.9474, Average Regression Loss 1.1686, Average Classification Loss: 2.7788
2019-01-14 08:04:48,121 - root - INFO - Epoch: 192, Step: 400, Average Loss: 3.8964, Average Regression Loss 1.1494, Average Classification Loss: 2.7471
2019-01-14 08:05:16,736 - root - INFO - Epoch: 192, Step: 500, Average Loss: 3.9447, Average Regression Loss 1.1689, Average Classification Loss: 2.7759
2019-01-14 08:05:45,362 - root - INFO - Epoch: 192, Step: 600, Average Loss: 3.9109, Average Regression Loss 1.1531, Average Classification Loss: 2.7578
2019-01-14 08:06:40,553 - root - INFO - Epoch: 193, Step: 100, Average Loss: 3.9697, Average Regression Loss 1.1786, Average Classification Loss: 2.7910
2019-01-14 08:07:09,069 - root - INFO - Epoch: 193, Step: 200, Average Loss: 3.9119, Average Regression Loss 1.1489, Average Classification Loss: 2.7631
2019-01-14 08:07:37,538 - root - INFO - Epoch: 193, Step: 300, Average Loss: 3.8727, Average Regression Loss 1.1416, Average Classification Loss: 2.7312
2019-01-14 08:08:06,022 - root - INFO - Epoch: 193, Step: 400, Average Loss: 3.9709, Average Regression Loss 1.2043, Average Classification Loss: 2.7667
2019-01-14 08:08:34,579 - root - INFO - Epoch: 193, Step: 500, Average Loss: 3.8664, Average Regression Loss 1.1448, Average Classification Loss: 2.7215
2019-01-14 08:09:03,053 - root - INFO - Epoch: 193, Step: 600, Average Loss: 3.9180, Average Regression Loss 1.1518, Average Classification Loss: 2.7662
2019-01-14 08:09:57,997 - root - INFO - Epoch: 194, Step: 100, Average Loss: 3.9366, Average Regression Loss 1.1796, Average Classification Loss: 2.7570
2019-01-14 08:10:26,560 - root - INFO - Epoch: 194, Step: 200, Average Loss: 3.9135, Average Regression Loss 1.1679, Average Classification Loss: 2.7456
2019-01-14 08:10:55,142 - root - INFO - Epoch: 194, Step: 300, Average Loss: 3.9386, Average Regression Loss 1.1530, Average Classification Loss: 2.7857
2019-01-14 08:11:23,679 - root - INFO - Epoch: 194, Step: 400, Average Loss: 3.8951, Average Regression Loss 1.1706, Average Classification Loss: 2.7245
2019-01-14 08:11:52,213 - root - INFO - Epoch: 194, Step: 500, Average Loss: 3.9223, Average Regression Loss 1.1622, Average Classification Loss: 2.7601
2019-01-14 08:12:20,743 - root - INFO - Epoch: 194, Step: 600, Average Loss: 3.9135, Average Regression Loss 1.1425, Average Classification Loss: 2.7710
2019-01-14 08:13:15,938 - root - INFO - Epoch: 195, Step: 100, Average Loss: 3.9612, Average Regression Loss 1.1638, Average Classification Loss: 2.7974
2019-01-14 08:13:44,600 - root - INFO - Epoch: 195, Step: 200, Average Loss: 3.9012, Average Regression Loss 1.1572, Average Classification Loss: 2.7439
2019-01-14 08:14:13,246 - root - INFO - Epoch: 195, Step: 300, Average Loss: 3.9020, Average Regression Loss 1.1642, Average Classification Loss: 2.7378
2019-01-14 08:14:41,896 - root - INFO - Epoch: 195, Step: 400, Average Loss: 3.9413, Average Regression Loss 1.1529, Average Classification Loss: 2.7884
2019-01-14 08:15:10,549 - root - INFO - Epoch: 195, Step: 500, Average Loss: 3.8955, Average Regression Loss 1.1714, Average Classification Loss: 2.7242
2019-01-14 08:15:39,154 - root - INFO - Epoch: 195, Step: 600, Average Loss: 3.8749, Average Regression Loss 1.1660, Average Classification Loss: 2.7089
2019-01-14 08:16:23,734 - root - INFO - Epoch: 195, Validation Loss: 3.7809, Validation Regression Loss 1.1854, Validation Classification Loss: 2.5955
2019-01-14 08:16:23,812 - root - INFO - Saved model models/inception-Epoch-195-Loss-3.7808558606871085.pth
2019-01-14 08:16:53,444 - root - INFO - Epoch: 196, Step: 100, Average Loss: 3.9776, Average Regression Loss 1.1773, Average Classification Loss: 2.8003
2019-01-14 08:17:21,932 - root - INFO - Epoch: 196, Step: 200, Average Loss: 3.8629, Average Regression Loss 1.1410, Average Classification Loss: 2.7219
2019-01-14 08:17:50,466 - root - INFO - Epoch: 196, Step: 300, Average Loss: 3.9196, Average Regression Loss 1.1699, Average Classification Loss: 2.7496
2019-01-14 08:18:18,931 - root - INFO - Epoch: 196, Step: 400, Average Loss: 3.9326, Average Regression Loss 1.1677, Average Classification Loss: 2.7649
2019-01-14 08:18:47,406 - root - INFO - Epoch: 196, Step: 500, Average Loss: 3.8821, Average Regression Loss 1.1294, Average Classification Loss: 2.7527
2019-01-14 08:19:15,891 - root - INFO - Epoch: 196, Step: 600, Average Loss: 3.9235, Average Regression Loss 1.1507, Average Classification Loss: 2.7728
2019-01-14 08:20:11,032 - root - INFO - Epoch: 197, Step: 100, Average Loss: 3.9041, Average Regression Loss 1.1521, Average Classification Loss: 2.7520
2019-01-14 08:20:39,645 - root - INFO - Epoch: 197, Step: 200, Average Loss: 3.8826, Average Regression Loss 1.1535, Average Classification Loss: 2.7291
2019-01-14 08:21:08,251 - root - INFO - Epoch: 197, Step: 300, Average Loss: 3.8776, Average Regression Loss 1.1490, Average Classification Loss: 2.7286
2019-01-14 08:21:36,964 - root - INFO - Epoch: 197, Step: 400, Average Loss: 3.9200, Average Regression Loss 1.1627, Average Classification Loss: 2.7574
2019-01-14 08:22:05,541 - root - INFO - Epoch: 197, Step: 500, Average Loss: 3.8924, Average Regression Loss 1.1455, Average Classification Loss: 2.7469
2019-01-14 08:22:34,132 - root - INFO - Epoch: 197, Step: 600, Average Loss: 3.9234, Average Regression Loss 1.1763, Average Classification Loss: 2.7471
2019-01-14 08:23:29,172 - root - INFO - Epoch: 198, Step: 100, Average Loss: 3.9936, Average Regression Loss 1.1972, Average Classification Loss: 2.7964
2019-01-14 08:23:57,685 - root - INFO - Epoch: 198, Step: 200, Average Loss: 3.9015, Average Regression Loss 1.1422, Average Classification Loss: 2.7593
2019-01-14 08:24:26,263 - root - INFO - Epoch: 198, Step: 300, Average Loss: 3.9230, Average Regression Loss 1.1566, Average Classification Loss: 2.7664
2019-01-14 08:24:54,747 - root - INFO - Epoch: 198, Step: 400, Average Loss: 3.9402, Average Regression Loss 1.1588, Average Classification Loss: 2.7814
2019-01-14 08:25:23,251 - root - INFO - Epoch: 198, Step: 500, Average Loss: 3.9385, Average Regression Loss 1.1566, Average Classification Loss: 2.7819
2019-01-14 08:25:51,750 - root - INFO - Epoch: 198, Step: 600, Average Loss: 3.8674, Average Regression Loss 1.1332, Average Classification Loss: 2.7342
2019-01-14 08:26:46,773 - root - INFO - Epoch: 199, Step: 100, Average Loss: 3.9488, Average Regression Loss 1.1831, Average Classification Loss: 2.7657
2019-01-14 08:27:15,334 - root - INFO - Epoch: 199, Step: 200, Average Loss: 3.9123, Average Regression Loss 1.1597, Average Classification Loss: 2.7525
2019-01-14 08:27:43,795 - root - INFO - Epoch: 199, Step: 300, Average Loss: 3.9123, Average Regression Loss 1.1604, Average Classification Loss: 2.7519
2019-01-14 08:28:12,323 - root - INFO - Epoch: 199, Step: 400, Average Loss: 3.9273, Average Regression Loss 1.1665, Average Classification Loss: 2.7607
2019-01-14 08:28:40,776 - root - INFO - Epoch: 199, Step: 500, Average Loss: 3.9026, Average Regression Loss 1.1523, Average Classification Loss: 2.7503
2019-01-14 08:29:09,299 - root - INFO - Epoch: 199, Step: 600, Average Loss: 3.9606, Average Regression Loss 1.1700, Average Classification Loss: 2.7906
2019-01-14 08:29:54,097 - root - INFO - Epoch: 199, Validation Loss: 3.7735, Validation Regression Loss 1.1811, Validation Classification Loss: 2.5924
2019-01-14 08:29:54,232 - root - INFO - Saved model models/inception-Epoch-199-Loss-3.773506200255979.pth
